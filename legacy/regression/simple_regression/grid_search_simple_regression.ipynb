{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ae6861",
   "metadata": {},
   "source": [
    "# MPRA regression with K-fold cross validation\n",
    "\n",
    "### Environment \n",
    "The next chunk contains the commands necessary to install the environment required to run this jupyter notebook\n",
    "Skip this chunk if the installation was previously done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a1d3c9",
   "metadata": {},
   "source": [
    "### Library imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff43395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:40:37.401891: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-08 17:40:37.433664: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-08 17:40:37.433704: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-08 17:40:37.433726: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-08 17:40:37.440014: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import getopt\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Layer, Lambda, concatenate, Bidirectional, Dense, Dropout, Flatten, Conv1D,BatchNormalization,  MaxPooling1D, Bidirectional, GRU, TimeDistributed\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.initializers import Constant\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b63fd8",
   "metadata": {},
   "source": [
    "### Input ingestion\n",
    "\n",
    "Here we define the methods to read and ingest data and we initialize the random seed.\n",
    "\n",
    "Since we are processing the entire sequence the vocabulary is comprised of upper case nucleotides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368fda03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:40:39.342309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1291 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337) # for reproducibility\n",
    "\n",
    "# Lower case vocabulary\n",
    "vocab = [\"A\", \"G\", \"C\", \"T\"]\n",
    "\n",
    "# These are the defaults of the data reader method \n",
    "# (each column in the ingested csv must be initialized with the right data type, otherwise the data ingestion fails )\n",
    "indices = tf.range(len(vocab), dtype = tf.int64)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab,indices)\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, 1)\n",
    "defs = [0.] * 1 + [tf.constant([], dtype = \"string\")]\n",
    "\n",
    "# Nadav dataset\n",
    "\n",
    "def data_reader(file, batch_size=100, n_parse_threads=4):\n",
    "    \"\"\"Method for reading the data in an optimized way, can be used inside model.fit()\n",
    "    \n",
    "    Args:\n",
    "        file (_type_): path to csv file\n",
    "        batch_size (int, optional): _description_. Defaults to 100.\n",
    "        n_parse_threads (int, optional): _description_. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        dataset.batch: batch dataset object \n",
    "    \"\"\"\n",
    "    dataset = tf.data.TextLineDataset(file).skip(1)\n",
    "    dataset=dataset.map(preprocess, num_parallel_calls = n_parse_threads)\n",
    "    return dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "def preprocess(record):\n",
    "    \"\"\"Preprocessing method of a dataset object, one-hot-encodes the data\n",
    "\n",
    "    Args:\n",
    "        record (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        X (2D np.array): one-hot-encoded input sequence\n",
    "        Y (1D np.array): MPRA measurements\n",
    "\n",
    "    \"\"\"\n",
    "    fields = tf.io.decode_csv(record, record_defaults=defs)\n",
    "    chars = tf.strings.bytes_split(fields[1])\n",
    "    chars_indeces = table.lookup(chars)\n",
    "    X = tf.one_hot(chars_indeces, depth = len(vocab))\n",
    "    Y = fields[0]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41502a80",
   "metadata": {},
   "source": [
    "### k-fold cross validation split\n",
    "Here we take the initial csv file and we split it in 3 partitions k times\n",
    "\n",
    "It is possible to randomize the sequences and augment, since the masking of the model motifs was a better choice\n",
    "for understanding the background this strategy is here commented out and not used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6395a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1811458/1817506747.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"seq\"] = train['seq'].str.upper()\n",
      "/tmp/ipykernel_1811458/1817506747.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"seq\"] = test['seq'].str.upper()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_3E</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>0.053119</td>\n",
       "      <td>AGGACCGGATCAACTGGTGCTGCCGTCACAACGCACTGTGCTTGTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>-0.077200</td>\n",
       "      <td>AGGACCGGATCAACTGTACAGTTATAAGGTAATCTTGTTCGATAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>0.011841</td>\n",
       "      <td>AGGACCGGATCAACTCGACCGGGGTCACCAGGATATTATCAGATGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>-0.103969</td>\n",
       "      <td>AGGACCGGATCAACTAATTGATATTGGCGCGTGTATCCCGAATTTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>0.036170</td>\n",
       "      <td>AGGACCGGATCAACTACTTGTGTTCAGGCACGATTTCTATCGTCGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>0.151705</td>\n",
       "      <td>AGGACCGGATCAACTGGTGGTAGCCACCTAGGGATAGCATAGGAGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>-0.000154</td>\n",
       "      <td>AGGACCGGATCAACTGTCAGAACTGCTTTGCCGACCGCGCTTTCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>0.039057</td>\n",
       "      <td>AGGACCGGATCAACTACGTAGTGCTTTATACCATCGAACCACTGCG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8448</th>\n",
       "      <td>0.091301</td>\n",
       "      <td>AGGACCGGATCAACTTTTGTGTAACGCTGTACGGGGCTGGAGATTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8071</th>\n",
       "      <td>0.072050</td>\n",
       "      <td>AGGACCGGATCAACTTTCAATGATCAGCACTAAAAACGGTTCTGGT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6791 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      State_3E                                                seq\n",
       "5786  0.053119  AGGACCGGATCAACTGGTGCTGCCGTCACAACGCACTGTGCTTGTT...\n",
       "5873 -0.077200  AGGACCGGATCAACTGTACAGTTATAAGGTAATCTTGTTCGATAAA...\n",
       "3331  0.011841  AGGACCGGATCAACTCGACCGGGGTCACCAGGATATTATCAGATGG...\n",
       "539  -0.103969  AGGACCGGATCAACTAATTGATATTGGCGCGTGTATCCCGAATTTC...\n",
       "1122  0.036170  AGGACCGGATCAACTACTTGTGTTCAGGCACGATTTCTATCGTCGG...\n",
       "...        ...                                                ...\n",
       "5792  0.151705  AGGACCGGATCAACTGGTGGTAGCCACCTAGGGATAGCATAGGAGG...\n",
       "5980 -0.000154  AGGACCGGATCAACTGTCAGAACTGCTTTGCCGACCGCGCTTTCTT...\n",
       "955   0.039057  AGGACCGGATCAACTACGTAGTGCTTTATACCATCGAACCACTGCG...\n",
       "8448  0.091301  AGGACCGGATCAACTTTTGTGTAACGCTGTACGGGGCTGGAGATTT...\n",
       "8071  0.072050  AGGACCGGATCAACTTTCAATGATCAGCACTAAAAACGGTTCTGGT...\n",
       "\n",
       "[6791 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CROSS VALIDATION (10 fold)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# Split the data in three partitions\n",
    "whole_data = pd.read_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3.csv\")\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 2008)\n",
    "\n",
    "o=1\n",
    "# For each fold we split again to get the third partition\n",
    "for i in kf.split(whole_data):\n",
    "    # Get train/test split and upper case all nucleotides\n",
    "    train = whole_data.iloc[i[0]]\n",
    "    train[\"seq\"] = train['seq'].str.upper() \n",
    "    \n",
    "    test =  whole_data.iloc[i[1]]\n",
    "    test[\"seq\"] = test['seq'].str.upper() \n",
    "\n",
    "    train, validation = train_test_split(train, test_size=0.11, random_state=42)\n",
    "    \n",
    "    train.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_train.csv\", index=False)\n",
    "    test.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_test.csv\", index=False)\n",
    "    validation.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_validation.csv\", index=False)\n",
    "    o+=1\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7928e",
   "metadata": {},
   "source": [
    "### Deep Learning model\n",
    "\n",
    "Here we run the model which is based on this paper : \n",
    "\n",
    "https://doi.org/10.1101/2023.03.05.531189\n",
    "\n",
    "I have added a Normalization layer parametrized with two parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d1457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "df_test_10folds  = pd.DataFrame(columns=['State_3E', \"seq\", \"prediction\"])\n",
    "corr_list = []\n",
    "\n",
    "# We define a custom normalization layer to then compile on the model\n",
    "class CustomNormalization(Layer):\n",
    "    \"\"\"Custom normalization layer that normalizes the output of the neural network\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CustomNormalization, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Add trainable variables for mean and standard deviation\n",
    "        self.mean = self.add_weight(\"mean\", shape=(1,), initializer=\"zeros\", trainable=True)\n",
    "        self.stddev = self.add_weight(\"stddev\", shape=(1,), initializer=\"ones\", trainable=True)\n",
    "        super(CustomNormalization, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Normalize the inputs using the learned mean and standard deviation\n",
    "        return (inputs - self.mean) / (self.stddev + 1e-8)\n",
    "\n",
    "# We define the method to compute the pearson correlation between prediction and ground truth\n",
    "def pearson_correlation(x, y):\n",
    "    \"\"\"Computes Pearson Correlation between x and y\n",
    "    Args:\n",
    "        x (np.array): vector of predictions values\n",
    "        y (np.array): vector of ground truth values\n",
    "\n",
    "    Returns:\n",
    "        (float): pearson correlation\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    \n",
    "    # Calculate the mean of x and y\n",
    "    mean_x = sum(x) / n\n",
    "    mean_y = sum(y) / n\n",
    "    \n",
    "    # Calculate the numerator and denominators of the correlation coefficient\n",
    "    numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "    denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "    denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "    \n",
    "    # Calculate the correlation coefficient\n",
    "    correlation = numerator / (denominator_x * denominator_y)\n",
    "    return correlation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Define plotting function of loss\n",
    "def create_plots(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1f870",
   "metadata": {},
   "source": [
    "#### Model training\n",
    "Here we iterate through the folds and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4155f147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 Complete [00h 01m 17s]\n",
      "val_mse: 0.013419228605926037\n",
      "\n",
      "Best val_mse So Far: 0.011838812381029129\n",
      "Total elapsed time: 00h 24m 48s\n",
      "\n",
      "The hyperparameter search is complete thse are the best hps \n",
      ":\n",
      "{'conv1_units': 196, 'conv1_kernel': 5, 'conv1_dropout': 0.5, 'conv2_units': 164, 'conv2_kernel': 9, 'maxpool1_dropout': 0.5, 'conv3_units': 292, 'conv3_kernel': 2, 'conv3_dropout': 0.2, 'conv4_units': 82, 'conv4_kernel': 3, 'maxpool2_dropout': 0.1, 'dense1_units': 310, 'dense1_dropout': 0.1, 'dense2_units': 342, 'learning_rate': 0.0001, 'tuner/epochs': 20, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:50:12.990743: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 189.36MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     31/Unknown - 4s 25ms/step - loss: 0.1365 - mae: 0.2757 - mse: 0.1365"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:50:14.662391: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 182.27MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 5s 60ms/step - loss: 0.1271 - mae: 0.2636 - mse: 0.1271 - val_loss: 0.0303 - val_mae: 0.1452 - val_mse: 0.0303\n",
      "Epoch 2/20\n",
      " 4/34 [==>...........................] - ETA: 0s - loss: 0.0317 - mae: 0.1471 - mse: 0.0317"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-08 17:50:15.431879: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 3411780013948306515\n",
      "2023-11-08 17:50:15.431947: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6093231065930492830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0254 - mae: 0.1186 - mse: 0.0254 - val_loss: 0.0209 - val_mae: 0.1032 - val_mse: 0.0209\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0230 - mae: 0.1108 - mse: 0.0230 - val_loss: 0.0208 - val_mae: 0.0994 - val_mse: 0.0208\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0226 - mae: 0.1098 - mse: 0.0226 - val_loss: 0.0209 - val_mae: 0.0988 - val_mse: 0.0209\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0221 - mae: 0.1087 - mse: 0.0221 - val_loss: 0.0209 - val_mae: 0.0987 - val_mse: 0.0209\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0202 - mae: 0.1063 - mse: 0.0202 - val_loss: 0.0211 - val_mae: 0.0981 - val_mse: 0.0211\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.0194 - mae: 0.1054 - mse: 0.0194 - val_loss: 0.0209 - val_mae: 0.0988 - val_mse: 0.0209\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0185 - mae: 0.1031 - mse: 0.0185 - val_loss: 0.0213 - val_mae: 0.0980 - val_mse: 0.0213\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0180 - mae: 0.1017 - mse: 0.0180 - val_loss: 0.0211 - val_mae: 0.0982 - val_mse: 0.0211\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.0172 - mae: 0.0998 - mse: 0.0172 - val_loss: 0.0213 - val_mae: 0.0980 - val_mse: 0.0213\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.0162 - mae: 0.0971 - mse: 0.0162 - val_loss: 0.0211 - val_mae: 0.0981 - val_mse: 0.0211\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0160 - mae: 0.0967 - mse: 0.0160 - val_loss: 0.0210 - val_mae: 0.0982 - val_mse: 0.0210\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0152 - mae: 0.0948 - mse: 0.0152 - val_loss: 0.0213 - val_mae: 0.0979 - val_mse: 0.0213\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.0148 - mae: 0.0931 - mse: 0.0148 - val_loss: 0.0213 - val_mae: 0.0977 - val_mse: 0.0213\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 1s 29ms/step - loss: 0.0144 - mae: 0.0916 - mse: 0.0144 - val_loss: 0.0212 - val_mae: 0.0975 - val_mse: 0.0212\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0142 - mae: 0.0908 - mse: 0.0142 - val_loss: 0.0208 - val_mae: 0.0969 - val_mse: 0.0208\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0141 - mae: 0.0906 - mse: 0.0141 - val_loss: 0.0204 - val_mae: 0.0961 - val_mse: 0.0204\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0136 - mae: 0.0890 - mse: 0.0136 - val_loss: 0.0196 - val_mae: 0.0949 - val_mse: 0.0196\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 1s 30ms/step - loss: 0.0133 - mae: 0.0881 - mse: 0.0133 - val_loss: 0.0191 - val_mae: 0.0935 - val_mse: 0.0191\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 1s 31ms/step - loss: 0.0130 - mae: 0.0873 - mse: 0.0130 - val_loss: 0.0174 - val_mae: 0.0912 - val_mse: 0.0174\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i=1\n",
    "# Define inputs\n",
    "input_path_train = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_train.csv\"\n",
    "input_path_valid = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_validation.csv\"\n",
    "input_path_test = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_test.csv\"\n",
    "\n",
    "# We load train and valid data as a np array to be able to feed it to the keras tuner\n",
    "train_data = data_reader(input_path_train,batch_size=100)\n",
    "y_train = np.empty(shape=[0,1])\n",
    "X_train = np.empty(shape=[0,262,4])\n",
    "\n",
    "for batch in train_data:\n",
    "    y_train =np.append(y_train, batch[1])\n",
    "    X_train = np.concatenate((X_train, batch[0]), axis=0)\n",
    "\n",
    "val_data = data_reader(input_path_valid,batch_size=100)\n",
    "y_val = np.empty(shape=[0,1])\n",
    "X_val = np.empty(shape=[0,262,4])\n",
    "\n",
    "for batch in val_data:\n",
    "    y_val =np.append(y_val, batch[1])\n",
    "    X_val = np.concatenate((X_val, batch[0]), axis=0)\n",
    "\n",
    "# Read test data to then predict\n",
    "df_test = pd.read_csv(input_path_test)\n",
    "\n",
    "# Get first item of the dataset to get the shape of the input data\n",
    "for element in data_reader(input_path_train):\n",
    "    input_shape = element[0].shape\n",
    "\n",
    "# Define and compile model\n",
    "def build_model(hp):\n",
    "    inputs = Input(shape=(input_shape[1], input_shape[2]), name=\"inputs\")\n",
    "    layer = Conv1D(hp.Int('conv1_units', min_value=100, max_value=300, step=32), kernel_size=hp.Int('conv1_kernel', min_value=3, max_value=10, step=2), activation=\"relu\", name=\"conv1\")(inputs)\n",
    "    layer = Dropout(hp.Float('conv1_dropout', min_value=0.1, max_value=0.5, step=0.1))(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Conv1D(hp.Int('conv2_units', min_value=100, max_value=300, step=32), hp.Int('conv2_kernel', min_value=3, max_value=10, step=2), activation=\"softmax\", name=\"conv2\")(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "    layer = Dropout(hp.Float('maxpool1_dropout', min_value=0.1, max_value=0.5, step=0.1))(layer)\n",
    "    layer = Conv1D(hp.Int('conv3_units', min_value=100, max_value=300, step=32), hp.Int('conv3_kernel', min_value=2, max_value=5, step=2), activation=\"softmax\", name=\"conv3\")(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Dropout(hp.Float('conv3_dropout', min_value=0.1, max_value=0.5, step=0.1))(layer)\n",
    "    layer = Conv1D(hp.Int('conv4_units', min_value=50, max_value=250, step=32), hp.Int('conv4_kernel', min_value=1, max_value=3, step=2), activation=\"softmax\", name=\"conv4\")(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "    layer = Dropout(hp.Float('maxpool2_dropout', min_value=0.1, max_value=0.5, step=0.1))(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(hp.Int('dense1_units', min_value=150, max_value=300, step=32), activation=\"sigmoid\")(layer)\n",
    "    layer = Dropout(hp.Float('dense1_dropout', min_value=0.1, max_value=0.5, step=0.1))(layer)\n",
    "    layer = Dense(hp.Int('dense2_units', min_value=150, max_value=300, step=32), activation=\"sigmoid\")(layer)\n",
    "    predictions = Dense(1, activation='linear')(layer)\n",
    "    norm_predictions = CustomNormalization()(predictions)  # Assuming \"predictions\" is your existing output\n",
    "    model = Model(inputs=inputs, outputs=norm_predictions)\n",
    "    \n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=['mae', \"mse\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "\t\tbuild_model,\n",
    "\t\tobjective=\"val_mse\",\n",
    "\t\tmax_epochs=20,\n",
    "\t\tfactor=3,\n",
    "\t\tseed=42)\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(x=X_train,\n",
    "             y=y_train,\n",
    "             validation_data=(X_val,y_val),\n",
    "             epochs=20,\n",
    "             callbacks=[stop_early]\n",
    "             )  # You can adjust the number of epochs\n",
    "\n",
    "\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete thse are the best hps \\n:\n",
    "{best_hps.values}\"\"\")\n",
    "\n",
    "final_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Run model\n",
    "history=final_model.fit(data_reader(input_path_train, batch_size=200),\n",
    "                        epochs=20,\n",
    "                        validation_data=data_reader(input_path_valid,batch_size=100),\n",
    "                        callbacks=None,\n",
    "                        verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53553d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 10ms/step\n",
      "[0.6250821511914249, 0.6250821511914249]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_3E</th>\n",
       "      <th>seq</th>\n",
       "      <th>prediction</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007714</td>\n",
       "      <td>AGGACCGGATCAACTAAACAACTCAAACAAGGGCTAATATAACCCA...</td>\n",
       "      <td>0.018103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.137953</td>\n",
       "      <td>AGGACCGGATCAACTAAACACTAGTCATACTTAAAAATTGCAAGGA...</td>\n",
       "      <td>0.029765</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.048706</td>\n",
       "      <td>AGGACCGGATCAACTAAACAGGTTCTGACGTATGCTCCTCTATGGA...</td>\n",
       "      <td>0.031707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052804</td>\n",
       "      <td>AGGACCGGATCAACTAAACCCGAGCCTGCCTAGCCCTAGCTTCTCT...</td>\n",
       "      <td>0.030516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.213652</td>\n",
       "      <td>AGGACCGGATCAACTAAACGGAGCAGAGTTAGTGTCAGGTCAAAAA...</td>\n",
       "      <td>0.018286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>0.080956</td>\n",
       "      <td>AGGACCGGATCAACTTTTGTATTGCGTGGGCAGCCGTGGTGGACTC...</td>\n",
       "      <td>0.035952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>-0.048439</td>\n",
       "      <td>AGGACCGGATCAACTTTTTATTGGACTCAATTGAAGGTCGTGGCGT...</td>\n",
       "      <td>0.043022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>0.063280</td>\n",
       "      <td>AGGACCGGATCAACTTTTTCATCACATGCGGGCGAATAGGACTATA...</td>\n",
       "      <td>0.064511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>0.232320</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTCTCCTCCGATACTGTACGTTACTCTT...</td>\n",
       "      <td>0.047724</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>-0.034994</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTGATGCGTAAAGTCTAGAACGCTGGAA...</td>\n",
       "      <td>0.022478</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1696 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      State_3E                                                seq  prediction  \\\n",
       "0    -0.007714  AGGACCGGATCAACTAAACAACTCAAACAAGGGCTAATATAACCCA...    0.018103   \n",
       "1     0.137953  AGGACCGGATCAACTAAACACTAGTCATACTTAAAAATTGCAAGGA...    0.029765   \n",
       "2    -0.048706  AGGACCGGATCAACTAAACAGGTTCTGACGTATGCTCCTCTATGGA...    0.031707   \n",
       "3    -0.052804  AGGACCGGATCAACTAAACCCGAGCCTGCCTAGCCCTAGCTTCTCT...    0.030516   \n",
       "4     0.213652  AGGACCGGATCAACTAAACGGAGCAGAGTTAGTGTCAGGTCAAAAA...    0.018286   \n",
       "...        ...                                                ...         ...   \n",
       "1691  0.080956  AGGACCGGATCAACTTTTGTATTGCGTGGGCAGCCGTGGTGGACTC...    0.035952   \n",
       "1692 -0.048439  AGGACCGGATCAACTTTTTATTGGACTCAATTGAAGGTCGTGGCGT...    0.043022   \n",
       "1693  0.063280  AGGACCGGATCAACTTTTTCATCACATGCGGGCGAATAGGACTATA...    0.064511   \n",
       "1694  0.232320  AGGACCGGATCAACTTTTTTCTCCTCCGATACTGTACGTTACTCTT...    0.047724   \n",
       "1695 -0.034994  AGGACCGGATCAACTTTTTTGATGCGTAAAGTCTAGAACGCTGGAA...    0.022478   \n",
       "\n",
       "     fold  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "...   ...  \n",
       "1691    1  \n",
       "1692    1  \n",
       "1693    1  \n",
       "1694    1  \n",
       "1695    1  \n",
       "\n",
       "[1696 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#After training we save the model weights to then run the contribution scores\n",
    "model_path = '/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/Model_CV'+str(i)+\"_LibA_wide_pivot_state3_hyperparam_tunning.h5\"\n",
    "final_model.save_weights(model_path, save_format='h5')\n",
    "\n",
    "# We predict the test data\n",
    "predicted = final_model.predict(data_reader(input_path_test,\n",
    "                                            batch_size=100))\n",
    "\n",
    "# We fill the dataframe with predictions and fold annotation\n",
    "test_data = data_reader(input_path_test,batch_size=100)\n",
    "test_tensor = np.empty(shape=[0,1])\n",
    "for batch in test_data:\n",
    "    test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "# Append fold to previous folds\n",
    "df_test[\"prediction\"] = predicted\n",
    "df_test[\"fold\"] = str(i)\n",
    "df_test_10folds = pd.concat([df_test_10folds, df_test], ignore_index=True)    \n",
    "\n",
    "# Append correlation coefficient and append to previous        \n",
    "corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)\n",
    "corr_list.append(corr_coefficient)\n",
    "\n",
    "df_test_10folds.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/LibA_wide_pivot_state3_test_predicted_hyperparam_tunning.csv\", index=False)\n",
    "print(corr_list)\n",
    "df_test_10folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b10f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 258, 196)          4116      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 258, 196)          0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 258, 196)          784       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 250, 164)          289460    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 250, 164)          656       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 125, 164)          0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 125, 164)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 124, 292)          96068     \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 124, 292)          1168      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 124, 292)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 122, 82)           71914     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 122, 82)           328       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 122, 82)           0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 122, 82)           0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 10004)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 310)               3101550   \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 310)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 342)               106362    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 343       \n",
      "                                                                 \n",
      " custom_normalization_1 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3672751 (14.01 MB)\n",
      "Trainable params: 3671283 (14.00 MB)\n",
      "Non-trainable params: 1468 (5.73 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7772ea68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_plots(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
