{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1f9e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import getopt\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math \n",
    "import matplotlib\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Masking, Lambda, concatenate, Bidirectional, Dense, Dropout, Flatten, Conv1D,BatchNormalization,  MaxPooling1D, Bidirectional, GRU, TimeDistributed\n",
    "from tensorflow.keras.initializers import Constant\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89f9e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input data for deep explainer\n",
    "df_test = pd.read_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/background_LibA_wide_pivot_state3_test_predicted_cv10fold.csv\")\n",
    "df_train = pd.read_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/background_LibA_wide_pivot_state3_train_predicted_cv10fold.csv\")\n",
    "df_valid = pd.read_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/background_LibA_wide_pivot_state3_valid_predicted_cv10fold.csv\")\n",
    "df = df_train.append(df_test).append(df_valid)\n",
    "\n",
    "def one_hot_encode_sequences(sequences, vocab):\n",
    "    num_sequences = len(sequences)\n",
    "    max_seq_length = max(len(seq) for seq in sequences)\n",
    "    encoding = np.zeros((num_sequences, max_seq_length, len(vocab)), dtype=int)\n",
    "\n",
    "    # Create a dictionary to map characters to their corresponding indices in the vocab\n",
    "    char_to_index = {char: i for i, char in enumerate(vocab)}\n",
    "\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j, base in enumerate(sequence):\n",
    "            if base in char_to_index:\n",
    "                index = char_to_index[base]\n",
    "                encoding[i, j, index] = 1\n",
    "            else:\n",
    "                # Set the entire vector to [0, 0, 0, 0] for unexpected characters\n",
    "                encoding[i, j, :] = [0, 0, 0, 0]\n",
    "\n",
    "    return encoding\n",
    "\n",
    "vocab = [\"a\", \"c\", \"g\", \"t\"]\n",
    "X = one_hot_encode_sequences(df.seq.values, vocab)\n",
    "y = df.State_3E.values\n",
    "ids = df.CRS.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "700f0140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method CustomNormalization.call of <__main__.CustomNormalization object at 0x7f39ebd599b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Name constructor takes either 0 or 4 mandatory arguments\n",
      "WARNING: Entity <bound method CustomNormalization.call of <__main__.CustomNormalization object at 0x7f39ebd599b0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Name constructor takes either 0 or 4 mandatory arguments\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 262, 4)]          0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 256, 250)          7250      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256, 250)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 250)          1000      \n",
      "_________________________________________________________________\n",
      "conv2 (Conv1D)               (None, 249, 250)          500250    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 249, 250)          1000      \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling1D)      (None, 124, 250)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 124, 250)          0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv1D)               (None, 122, 250)          187750    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 122, 250)          1000      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 122, 250)          0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv1D)               (None, 121, 100)          50100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 121, 100)          400       \n",
      "_________________________________________________________________\n",
      "maxpool2 (MaxPooling1D)      (None, 121, 100)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 121, 100)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12100)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               3630300   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 201       \n",
      "_________________________________________________________________\n",
      "custom_normalization (Custom (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 4,439,453\n",
      "Trainable params: 4,437,753\n",
      "Non-trainable params: 1,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class CustomNormalization(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CustomNormalization, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Add trainable variables for mean and standard deviation\n",
    "        self.mean = self.add_weight(\"mean\", shape=(1,), initializer=\"zeros\", trainable=True)\n",
    "        self.stddev = self.add_weight(\"stddev\", shape=(1,), initializer=\"ones\", trainable=True)\n",
    "        super(CustomNormalization, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Normalize the inputs using the learned mean and standard deviation\n",
    "        return (inputs - self.mean) / (self.stddev + 1e-8)\n",
    "\n",
    "inputs = Input(shape=(X.shape[1], X.shape[2]), name=\"inputs\")\n",
    "#inputs = Masking()(inputs)\n",
    "layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "predictions = Dense(1, activation='linear')(layer)\n",
    "norm_predictions = CustomNormalization()(predictions)  # Assuming \"predictions\" is your existing output\n",
    "\n",
    "model = Model(inputs=inputs, outputs=norm_predictions)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=norm_predictions)\n",
    "model.summary()\n",
    "model.load_weights(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/test_background.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80f8e837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_a(ax, base, left_edge, height, color):\n",
    "    a_polygon_coords = [\n",
    "        np.array([\n",
    "           [0.0, 0.0],\n",
    "           [0.5, 1.0],\n",
    "           [0.5, 0.8],\n",
    "           [0.2, 0.0],\n",
    "        ]),\n",
    "        np.array([\n",
    "           [1.0, 0.0],\n",
    "           [0.5, 1.0],\n",
    "           [0.5, 0.8],\n",
    "           [0.8, 0.0],\n",
    "        ]),\n",
    "        np.array([\n",
    "           [0.225, 0.45],\n",
    "           [0.775, 0.45],\n",
    "           [0.85, 0.3],\n",
    "           [0.15, 0.3],\n",
    "        ])\n",
    "    ]\n",
    "    for polygon_coords in a_polygon_coords:\n",
    "        ax.add_patch(matplotlib.patches.Polygon((np.array([1,height])[None,:]*polygon_coords\n",
    "                                                 + np.array([left_edge,base])[None,:]),\n",
    "                                                facecolor=color, edgecolor=color))\n",
    "\n",
    "def plot_c(ax, base, left_edge, height, color):\n",
    "    ax.add_patch(matplotlib.patches.Ellipse(xy=[left_edge+0.65, base+0.5*height], width=1.3, height=height,\n",
    "                                            facecolor=color, edgecolor=color))\n",
    "    ax.add_patch(matplotlib.patches.Ellipse(xy=[left_edge+0.65, base+0.5*height], width=0.7*1.3, height=0.7*height,\n",
    "                                            facecolor='white', edgecolor='white'))\n",
    "    ax.add_patch(matplotlib.patches.Rectangle(xy=[left_edge+1, base], width=1.0, height=height,\n",
    "                                            facecolor='white', edgecolor='white', fill=True))\n",
    "\n",
    "def plot_g(ax, base, left_edge, height, color):\n",
    "    ax.add_patch(matplotlib.patches.Ellipse(xy=[left_edge+0.65, base+0.5*height], width=1.3, height=height,\n",
    "                                            facecolor=color, edgecolor=color))\n",
    "    ax.add_patch(matplotlib.patches.Ellipse(xy=[left_edge+0.65, base+0.5*height], width=0.7*1.3, height=0.7*height,\n",
    "                                            facecolor='white', edgecolor='white'))\n",
    "    ax.add_patch(matplotlib.patches.Rectangle(xy=[left_edge+1, base], width=1.0, height=height,\n",
    "                                            facecolor='white', edgecolor='white', fill=True))\n",
    "    ax.add_patch(matplotlib.patches.Rectangle(xy=[left_edge+0.825, base+0.085*height], width=0.174, height=0.415*height,\n",
    "                                            facecolor=color, edgecolor=color, fill=True))\n",
    "    ax.add_patch(matplotlib.patches.Rectangle(xy=[left_edge+0.625, base+0.35*height], width=0.374, height=0.15*height,\n",
    "                                            facecolor=color, edgecolor=color, fill=True))\n",
    "\n",
    "def plot_t(ax, base, left_edge, height, color):\n",
    "    ax.add_patch(matplotlib.patches.Rectangle(xy=[left_edge+0.4, base],\n",
    "                  width=0.2, height=height, facecolor=color, edgecolor=color, fill=True))\n",
    "    ax.add_patch(matplotlib.patches.Rectangle(xy=[left_edge, base+0.8*height],\n",
    "                  width=1.0, height=0.2*height, facecolor=color, edgecolor=color, fill=True))\n",
    "\n",
    "default_colors = {0:'green', 1:'blue', 2:'orange', 3:'red'}\n",
    "default_plot_funcs = {0:plot_a, 1:plot_c, 2:plot_g, 3:plot_t}\n",
    "\n",
    "default_colors = {0:'green', 1:'blue', 2:'orange', 3:'red'}\n",
    "default_plot_funcs = {0:plot_a, 1:plot_c, 2:plot_g, 3:plot_t}\n",
    "\n",
    "def plot_weights_given_ax(ax, array,\n",
    "                 height_padding_factor,\n",
    "                 length_padding,\n",
    "                 subticks_frequency,\n",
    "                 highlight,\n",
    "                 colors=default_colors,\n",
    "                 plot_funcs=default_plot_funcs):\n",
    "    if len(array.shape)==3:\n",
    "        array = np.squeeze(array)\n",
    "    assert len(array.shape)==2, array.shape\n",
    "    if (array.shape[0]==4 and array.shape[1] != 4):\n",
    "        array = array.transpose(1,0)\n",
    "    assert array.shape[1]==4\n",
    "    max_pos_height = 0.0\n",
    "    min_neg_height = 0.0\n",
    "    heights_at_positions = []\n",
    "    depths_at_positions = []\n",
    "    for i in range(array.shape[0]):\n",
    "        acgt_vals = sorted(enumerate(array[i,:]), key=lambda x: abs(x[1]))\n",
    "        positive_height_so_far = 0.0\n",
    "        negative_height_so_far = 0.0\n",
    "        for letter in acgt_vals:\n",
    "            plot_func = plot_funcs[letter[0]]\n",
    "            color=colors[letter[0]]\n",
    "            if (letter[1] > 0):\n",
    "                height_so_far = positive_height_so_far\n",
    "                positive_height_so_far += letter[1]                \n",
    "            else:\n",
    "                height_so_far = negative_height_so_far\n",
    "                negative_height_so_far += letter[1]\n",
    "            plot_func(ax=ax, base=height_so_far, left_edge=i, height=letter[1], color=color)\n",
    "        max_pos_height = max(max_pos_height, positive_height_so_far)\n",
    "        min_neg_height = min(min_neg_height, negative_height_so_far)\n",
    "        heights_at_positions.append(positive_height_so_far)\n",
    "        depths_at_positions.append(negative_height_so_far)\n",
    "    for color in highlight:\n",
    "        for start_pos, end_pos in highlight[color]:\n",
    "            assert start_pos >= 0.0 and end_pos <= array.shape[0]\n",
    "            min_depth = np.min(depths_at_positions[start_pos:end_pos])\n",
    "            max_height = np.max(heights_at_positions[start_pos:end_pos])\n",
    "            ax.add_patch(\n",
    "                matplotlib.patches.Rectangle(xy=[start_pos,min_depth],\n",
    "                    width=end_pos-start_pos,\n",
    "                    height=max_height-min_depth,\n",
    "                    edgecolor=color, fill=False))\n",
    "            \n",
    "    ax.set_xlim(-length_padding, array.shape[0]+length_padding)\n",
    "    ax.xaxis.set_ticks(np.arange(0.0, array.shape[0]+1, subticks_frequency))\n",
    "    height_padding = max(abs(min_neg_height)*(height_padding_factor),\n",
    "                         abs(max_pos_height)*(height_padding_factor))\n",
    "    ax.set_ylim(min_neg_height-height_padding, max_pos_height+height_padding)\n",
    "    return ax\n",
    "\n",
    "def plot_weights_modified(array, fig, n,n1,n2, title='', ylab='',\n",
    "                              figsize=(20,2),\n",
    "                 height_padding_factor=0.2,\n",
    "                 length_padding=1.0,\n",
    "                 subticks_frequency=20,\n",
    "                 colors=default_colors,\n",
    "                 plot_funcs=default_plot_funcs,\n",
    "                 highlight={}):\n",
    "    ax = fig.add_subplot(n,n1,n2) \n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(ylab)\n",
    "    y = plot_weights_given_ax(ax=ax, array=array,\n",
    "        height_padding_factor=height_padding_factor,\n",
    "        length_padding=length_padding,\n",
    "        subticks_frequency=subticks_frequency,\n",
    "        colors=colors,\n",
    "        plot_funcs=plot_funcs,\n",
    "        highlight=highlight)\n",
    "    return fig,ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb1e6a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/shap/explainers/deep/deep_tf.py:118: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "rn=np.random.choice([X,  X[:,::-1,::-1]][0].shape[0], 1000, replace=False)\n",
    "explainer = shap.DeepExplainer((model.inputs, model.layers[-1].output), X[rn])\n",
    "\n",
    "if os.path.exists(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/deep_explainer_background/\") is False:\n",
    "    os.mkdir(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/deep_explainer_background/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63f29633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/felix/anaconda3/envs/DeepFlyBrain_conda_env_gpu/lib/python3.6/site-packages/shap/explainers/deep/deep_tf.py:458: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "shap_values, indexes = explainer.shap_values(X, ranked_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbcb9b6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "repeating_array = np.arange(1, 101)\n",
    "\n",
    "# Calculate how many times the array needs to be repeated\n",
    "repeat_count = ( ids.shape[0] + len(repeating_array) - 1) // len(repeating_array)\n",
    "\n",
    "# Repeat the array to match the target length\n",
    "str_array = np.tile(repeating_array.astype(str), repeat_count)\n",
    "\n",
    "# Trim the excess elements to match the target length\n",
    "str_array = str_array[: ids.shape[0]]\n",
    "#ids = np.core.defchararray.add(ids.astype(str), \"_\")\n",
    "#ids = np.core.defchararray.add(ids, str_array)\n",
    "\n",
    "for i in range(0, X.shape[0]):\n",
    "    ntrack=2\n",
    "    fig = plt.figure(figsize=(80,10))\n",
    "    _, ax1 =plot_weights_modified(shap_values[0][0]*X[i],fig,ntrack,1,1,title=i, subticks_frequency=10,ylab=\"DeepExplainer\")\n",
    "\n",
    "    plt.savefig(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/deep_explainer_background/\"+ids[i] +'_deep_explainer.png')\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44cd259b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shap_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1521a24f4fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshap_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'shap_values' is not defined"
     ]
    }
   ],
   "source": [
    "shap_values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffa280e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
