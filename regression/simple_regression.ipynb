{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1f9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import getopt\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Lambda, concatenate, Bidirectional, Dense, Dropout, Flatten, Conv1D,BatchNormalization,  MaxPooling1D, Bidirectional, GRU, TimeDistributed\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n",
    "vocab = [\"A\", \"G\", \"C\", \"T\"]\n",
    "indices = tf.range(len(vocab), dtype = tf.int64)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab,indices)\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, 1)\n",
    "defs = [0.] * 1 + [tf.constant([], dtype = \"string\")]\n",
    "\n",
    "# Nadav dataset\n",
    "\n",
    "def data_reader(file, batch_size=100, n_parse_threads = 4):\n",
    "    dataset = tf.data.TextLineDataset(file).skip(1)\n",
    "    dataset=dataset.map(preprocess, num_parallel_calls = n_parse_threads)\n",
    "    return dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "def preprocess(record):\n",
    "    fields = tf.io.decode_csv(record, record_defaults=defs)\n",
    "    chars = tf.strings.bytes_split(fields[1])\n",
    "    chars_indeces = table.lookup(chars)\n",
    "    X = tf.one_hot(chars_indeces, depth = len(vocab))\n",
    "    Y = fields[0]\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaa2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data in three partitions\n",
    "file=\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3.csv\"\n",
    "whole_data = pd.read_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3.csv\")\n",
    "\n",
    "df_train, df_test = train_test_split(whole_data, test_size=0.2, random_state=42)\n",
    "df_validation, df_test = train_test_split(df_test, test_size=0.5, random_state=42)\n",
    "\n",
    "df_train.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3_train.csv\", index=False)\n",
    "df_test.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3_test.csv\", index=False)\n",
    "df_validation.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3_validation.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0250f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path_train = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3_train.csv\"\n",
    "input_path_valid = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3_validation.csv\"\n",
    "input_path_test = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3_test.csv\"\n",
    "\n",
    "corr_list = []\n",
    "df_repetition = pd.DataFrame()\n",
    "\n",
    "for i in range(0,10):\n",
    "    # Get first item of the dataset to get the shape of the input data\n",
    "    for element in data_reader(file):\n",
    "        input_shape = element[0].shape\n",
    "\n",
    "    inputs = Input(shape=(input_shape[1],input_shape[2]), name=\"inputs\")\n",
    "    layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "    predictions = Dense(1, activation='linear')(layer)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "                )\n",
    "\n",
    "    history=model.fit(data_reader(input_path_train, batch_size=100),\n",
    "                            epochs=20,\n",
    "                            validation_data=data_reader(file,batch_size=100),\n",
    "                            callbacks=None,\n",
    "                            verbose=1)\n",
    "\n",
    "    predicted = model.predict(data_reader(input_path_test,\n",
    "                                                batch_size=100))\n",
    "\n",
    "    test_data = data_reader(input_path_test,batch_size=100)\n",
    "    test_tensor = X = np.empty(shape=[0,1])\n",
    "    for batch in test_data:\n",
    "        test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "    import math\n",
    "    def pearson_correlation(x, y):\n",
    "        n = len(x)\n",
    "        # Calculate the mean of x and y\n",
    "        mean_x = sum(x) / n\n",
    "        mean_y = sum(y) / n\n",
    "        \n",
    "        # Calculate the numerator and denominators of the correlation coefficient\n",
    "        numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "        denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "        denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "        \n",
    "        # Calculate the correlation coefficient\n",
    "        correlation = numerator / (denominator_x * denominator_y)\n",
    "        return correlation\n",
    "        \n",
    "    corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)\n",
    "    corr_list.append(corr_coefficient)\n",
    "    df_repetition[str(i)] =predicted.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f443be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_repetition\n",
    "df_repetition[\"col_mean\"] = df_repetition.mean(axis = 1)\n",
    "print(pearson_correlation(df_repetition.col_mean, test_tensor))\n",
    "print(df_repetition.corr().abs())\n",
    "df_repetition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b08e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231bf175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test[\"prediction\"] = predicted\n",
    "#df_test.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3_test_predicte.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53771072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data in three partitions\n",
    "file=\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ.csv\"\n",
    "whole_data = pd.read_csv(file)\n",
    "\n",
    "df_train, df_test = train_test_split(whole_data, test_size=0.2, random_state=42)\n",
    "df_validation, df_test = train_test_split(df_test, test_size=0.5, random_state=42)\n",
    "\n",
    "df_train[[\"meanVal\", \"sequence\"]].to_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_train.csv\", index=False)\n",
    "df_test[[\"meanVal\", \"sequence\"]].to_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_test.csv\", index=False)\n",
    "df_validation[[\"meanVal\", \"sequence\"]].to_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1992403",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_path_train = \"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_train.csv\"\n",
    "input_path_test = \"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_test.csv\"\n",
    "input_path_valid = \"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_validation.csv\"\n",
    "\n",
    "# Get first item of the dataset to get the shape of the input data\n",
    "for element in data_reader(input_path_train):\n",
    "    input_shape = element[0].shape\n",
    "\n",
    "inputs = Input(shape=(input_shape[1],input_shape[2]), name=\"inputs\")\n",
    "layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "predictions = Dense(1, activation='linear')(layer)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"mean_squared_error\",\n",
    "              metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "              )\n",
    "\n",
    "history=model.fit(data_reader(input_path_train, batch_size=100),\n",
    "                        epochs=15,\n",
    "                        validation_data=data_reader(input_path_valid,batch_size=100),\n",
    "                        callbacks=None,\n",
    "                        verbose=1)\n",
    "\n",
    "predicted = model.predict(data_reader(input_path_test,\n",
    "                                            batch_size=100))\n",
    "\n",
    "test_data = data_reader(input_path_test,batch_size=100)\n",
    "test_tensor = X = np.empty(shape=[0,1])\n",
    "for batch in test_data:\n",
    "    test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "import math\n",
    "def pearson_correlation(x, y):\n",
    "    n = len(x)\n",
    "    # Calculate the mean of x and y\n",
    "    mean_x = sum(x) / n\n",
    "    mean_y = sum(y) / n\n",
    "    \n",
    "    # Calculate the numerator and denominators of the correlation coefficient\n",
    "    numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "    denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "    denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "    \n",
    "    # Calculate the correlation coefficient\n",
    "    correlation = numerator / (denominator_x * denominator_y)\n",
    "    return correlation\n",
    "    \n",
    "corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1dd2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation: \"+str(corr_coefficient))\n",
    "print(\"Test Data : \\n\"+str(test_tensor[:10]))\n",
    "print(\"Predictions :\\n\" +str(predicted[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8183fb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b903c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def create_plots(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "create_plots(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd865d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data\n",
    "import shap\n",
    "_dataset = data_reader(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_2col_test.csv\", batch_size=10000)\n",
    "shuffled_dataset = _dataset.shuffle(5000)\n",
    "iterator = shuffled_dataset.as_numpy_iterator()\n",
    "random_sample = next(iterator)\n",
    "X = random_sample[0]\n",
    "\n",
    "rn=np.random.choice([X,  X[:,::-1,::-1]][0].shape[0], 1000, replace=False)\n",
    "explainer = shap.DeepExplainer((model.inputs, model.layers[-1].output), X[rn])\n",
    "explainer.shap_values(X[0:10], ranked_outputs=1)\n",
    "\n",
    "#shap_values_top, indexes = explainer.shap_values(X, ranked_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b5378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data\n",
    "import shap\n",
    "_dataset = data_reader(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_2col_test.csv\", batch_size=10000)\n",
    "shuffled_dataset = _dataset.shuffle(5000)\n",
    "iterator = shuffled_dataset.as_numpy_iterator()\n",
    "random_sample = next(iterator)\n",
    "X = random_sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4d9541",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "rn=np.random.choice([X,  X[:,::-1,::-1]][0].shape[0], 1000, replace=False)\n",
    "X[rn].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn=np.random.choice([X,  X[:,::-1,::-1]][0].shape[0], 200, replace=False)\n",
    "rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc42a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_to_dna_sequence(one_hot_sequence, vocab):\n",
    "    \"\"\"\n",
    "    Convert a one-hot-encoded DNA sequence back to a DNA sequence using the provided vocabulary.\n",
    "    Args:\n",
    "    - one_hot_sequence: A tensor containing the one-hot-encoded DNA sequence.\n",
    "    - vocab: A list of vocabulary characters (e.g., [\"A\", \"G\", \"C\", \"T\"]).\n",
    "\n",
    "    Returns:\n",
    "    - dna_sequence: A tensor containing the decoded DNA sequence.\n",
    "    \"\"\"\n",
    "    # Get the index of the maximum value along the one-hot encoding axis\n",
    "    decoded_indices = tf.argmax(one_hot_sequence, axis=-1)\n",
    "\n",
    "    # Use the indices to map back to DNA characters\n",
    "    dna_sequence = tf.gather(vocab, decoded_indices)\n",
    "\n",
    "    return dna_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e27517",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6395a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# Split the data in three partitions\n",
    "file=\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3.csv\"\n",
    "whole_data = pd.read_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3.csv\")\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 2008)\n",
    "result = next(kf.split(whole_data), None)\n",
    "\n",
    "o=1\n",
    "for i in kf.split(whole_data):\n",
    "    train = whole_data.iloc[i[0]]\n",
    "    test =  whole_data.iloc[i[1]]\n",
    "    \n",
    "    train, validation = train_test_split(whole_data, test_size=0.10, random_state=42)\n",
    "    \n",
    "    train.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_train.csv\", index=False)\n",
    "    test.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_test.csv\", index=False)\n",
    "    validation.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_validation.csv\", index=False)\n",
    "    o+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d1457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [State_3E, seq, prediction]\n",
      "Index: []\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 256, 250)          1000      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 249, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 122, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 121, 100)          400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12100)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:26:49.597694: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-10-17 15:26:49.639767: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-10-17 15:26:49.741324: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-10-17 15:26:51.129318: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fca64918ac0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-17 15:26:51.129349: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-10-17 15:26:51.133924: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-17 15:26:51.259724: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 8s 32ms/step - loss: 0.0859 - mse: 0.0859 - mae: 0.2041 - mape: 55690.4688 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0954 - val_mape: 316.1502\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0207 - mse: 0.0207 - mae: 0.1110 - mape: 6295.9746 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0966 - val_mape: 352.6797\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0155 - mse: 0.0155 - mae: 0.0942 - mape: 3703.2922 - val_loss: 0.0185 - val_mse: 0.0185 - val_mae: 0.1021 - val_mape: 464.9964\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0843 - mape: 6587.1001 - val_loss: 0.0189 - val_mse: 0.0189 - val_mae: 0.1041 - val_mape: 496.8221\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0780 - mape: 1347.6101 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.1078 - val_mape: 551.0288\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0744 - mape: 9584.7979 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1171 - val_mape: 668.4852\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0697 - mape: 1590.8589 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.1137 - val_mape: 643.5422\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0681 - mape: 13920.6309 - val_loss: 0.0171 - val_mse: 0.0171 - val_mae: 0.1012 - val_mape: 541.6211\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0653 - mape: 3317.9998 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.1026 - val_mape: 621.0121\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0688 - mape: 8958.3623 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1287 - val_mape: 860.5611\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0689 - mape: 2579.9351 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0864 - val_mape: 298.8849\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0757 - mape: 9263.0742 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0769 - val_mape: 344.5715\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0722 - mape: 17689.9980 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.1045 - val_mape: 453.8068\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0631 - mape: 3326.0439 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0746 - val_mape: 282.2874\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0605 - mape: 4234.8726 - val_loss: 0.0154 - val_mse: 0.0154 - val_mae: 0.0970 - val_mape: 554.7416\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0573 - mape: 1354.7032 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0803 - val_mape: 385.7571\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0540 - mape: 2843.6309 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0762 - val_mape: 298.5437\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0534 - mape: 9068.8643 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0778 - val_mape: 327.0709\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0573 - mape: 1736.6559 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0794 - val_mape: 310.6198\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0623 - mape: 7199.1079 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0888 - val_mape: 350.2804\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_718338/2433276998.py:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 256, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 249, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 122, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 121, 100)          400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 4s 25ms/step - loss: 0.0387 - mse: 0.0387 - mae: 0.1477 - mape: 23113.6719 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0952 - val_mape: 310.4602\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0168 - mse: 0.0168 - mae: 0.0974 - mape: 19862.1387 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0953 - val_mape: 314.3411\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0838 - mape: 3813.1240 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0968 - val_mape: 356.4233\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0776 - mape: 2385.8579 - val_loss: 0.0180 - val_mse: 0.0180 - val_mae: 0.0995 - val_mape: 417.5449\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0775 - mape: 21641.5430 - val_loss: 0.0181 - val_mse: 0.0181 - val_mae: 0.1001 - val_mape: 430.9929\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0711 - mape: 8122.6113 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.1096 - val_mape: 579.5052\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0687 - mape: 13935.5498 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0995 - val_mape: 466.3443\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0673 - mape: 5016.4546 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0942 - val_mape: 461.8293\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0736 - mape: 13735.0479 - val_loss: 0.0139 - val_mse: 0.0139 - val_mae: 0.0876 - val_mape: 205.0245\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0640 - mape: 4105.9683 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0789 - val_mape: 219.0544\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0591 - mape: 1317.2917 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0762 - val_mape: 294.5112\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0565 - mape: 3962.9771 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0736 - val_mape: 356.6624\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0546 - mape: 731.2817 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0758 - val_mape: 359.9932\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0538 - mape: 10624.2334 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0754 - val_mape: 309.2961\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 20ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0516 - mape: 7367.9019 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0741 - val_mape: 283.0717\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0520 - mape: 5977.3813 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0730 - val_mape: 297.6495\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0514 - mape: 7973.1802 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0750 - val_mape: 309.8356\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0509 - mape: 5811.8008 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0798 - val_mape: 278.7715\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0523 - mape: 8025.3447 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0730 - val_mape: 246.9630\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0548 - mape: 4707.4902 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0737 - val_mape: 235.6414\n",
      "9/9 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_718338/2433276998.py:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 256, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 249, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 4s 24ms/step - loss: 0.0646 - mse: 0.0646 - mae: 0.1842 - mape: 14767.5439 - val_loss: 0.0180 - val_mse: 0.0180 - val_mae: 0.0937 - val_mape: 170.0339\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0195 - mse: 0.0195 - mae: 0.1069 - mape: 5639.1396 - val_loss: 0.0174 - val_mse: 0.0174 - val_mae: 0.0944 - val_mape: 277.7109\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0900 - mape: 4411.2793 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0938 - val_mape: 236.0757\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0805 - mape: 14558.8477 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0956 - val_mape: 324.2521\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0754 - mape: 6577.2461 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0937 - val_mape: 236.3743\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0736 - mape: 3237.8899 - val_loss: 0.0184 - val_mse: 0.0184 - val_mae: 0.1019 - val_mape: 467.9393\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0695 - mape: 6698.6865 - val_loss: 0.0165 - val_mse: 0.0165 - val_mae: 0.0926 - val_mape: 306.3239\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0676 - mape: 2566.8562 - val_loss: 0.0146 - val_mse: 0.0146 - val_mae: 0.0870 - val_mape: 245.7818\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0688 - mape: 16715.8047 - val_loss: 0.0184 - val_mse: 0.0184 - val_mae: 0.1041 - val_mape: 367.5110\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0826 - mape: 11699.5146 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0967 - val_mape: 362.5746\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0689 - mape: 7127.8057 - val_loss: 0.0141 - val_mse: 0.0141 - val_mae: 0.0913 - val_mape: 337.3775\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0649 - mape: 3497.6450 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0866 - val_mape: 492.4897\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0646 - mape: 10363.8242 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0836 - val_mape: 419.7922\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0586 - mape: 4755.3877 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0893 - val_mape: 510.9363\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0562 - mape: 1784.4976 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0780 - val_mape: 335.8528\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0537 - mape: 2047.8333 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0752 - val_mape: 305.9583\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0542 - mape: 7530.4121 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0762 - val_mape: 342.1535\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0540 - mape: 7270.4180 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0766 - val_mape: 325.1084\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0570 - mape: 5711.3857 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0768 - val_mape: 300.7519\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0586 - mape: 2299.5735 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0763 - val_mape: 285.3821\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:28:43.959299: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5422068039076722902\n",
      "/tmp/ipykernel_718338/2433276998.py:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 5s 29ms/step - loss: 0.0834 - mse: 0.0834 - mae: 0.2023 - mape: 17444.1816 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0960 - val_mape: 333.9604\n",
      "Epoch 2/20\n",
      " 4/77 [>.............................] - ETA: 1s - loss: 0.0235 - mse: 0.0235 - mae: 0.1192 - mape: 403.9457"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:28:49.748144: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5422068039076722902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0201 - mse: 0.0201 - mae: 0.1080 - mape: 5450.2437 - val_loss: 0.0182 - val_mse: 0.0182 - val_mae: 0.1003 - val_mape: 433.9836\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0151 - mse: 0.0151 - mae: 0.0932 - mape: 5356.9043 - val_loss: 0.0181 - val_mse: 0.0181 - val_mae: 0.0999 - val_mape: 425.0341\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0825 - mape: 5745.3501 - val_loss: 0.0183 - val_mse: 0.0183 - val_mae: 0.1007 - val_mape: 441.8535\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0757 - mape: 5231.7603 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.1150 - val_mape: 640.6551\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0730 - mape: 10414.4951 - val_loss: 0.0258 - val_mse: 0.0258 - val_mae: 0.1313 - val_mape: 809.8181\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0700 - mape: 3123.5068 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.1130 - val_mape: 638.8022\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0677 - mape: 756.9552 - val_loss: 0.0144 - val_mse: 0.0144 - val_mae: 0.0891 - val_mape: 352.6562\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0679 - mape: 8008.9683 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0839 - val_mape: 371.7188\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0717 - mape: 4890.5386 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0779 - val_mape: 278.5986\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0671 - mape: 10793.9941 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0770 - val_mape: 258.6902\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0597 - mape: 1377.9790 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0776 - val_mape: 292.8288\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0556 - mape: 3703.0811 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0808 - val_mape: 343.0411\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0537 - mape: 13813.5439 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0776 - val_mape: 272.1762\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0518 - mape: 7384.1265 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0800 - val_mape: 301.8276\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0527 - mape: 8397.8613 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0756 - val_mape: 266.3799\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0519 - mape: 2931.9456 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0772 - val_mape: 266.8477\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0504 - mape: 1668.6144 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0818 - val_mape: 324.3544\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0527 - mape: 2089.2700 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0854 - val_mape: 379.8249\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0536 - mape: 8221.5342 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0759 - val_mape: 226.3586\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_718338/2433276998.py:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 4s 24ms/step - loss: 0.0422 - mse: 0.0422 - mae: 0.1544 - mape: 3150.0178 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.1084 - val_mape: 557.1468\n",
      "Epoch 2/20\n",
      " 4/77 [>.............................] - ETA: 1s - loss: 0.0245 - mse: 0.0245 - mae: 0.1227 - mape: 609.7484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:29:27.958231: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5422068039076722902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0177 - mse: 0.0177 - mae: 0.1005 - mape: 1320.6792 - val_loss: 0.0178 - val_mse: 0.0178 - val_mae: 0.0980 - val_mape: 385.5536\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0829 - mape: 4298.9624 - val_loss: 0.0192 - val_mse: 0.0192 - val_mae: 0.1055 - val_mape: 517.7083\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0106 - mse: 0.0106 - mae: 0.0772 - mape: 10337.1709 - val_loss: 0.0234 - val_mse: 0.0234 - val_mae: 0.1224 - val_mape: 722.1279\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0769 - mape: 18475.6699 - val_loss: 0.0273 - val_mse: 0.0273 - val_mae: 0.1363 - val_mape: 853.2267\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0716 - mape: 6223.1860 - val_loss: 0.0245 - val_mse: 0.0245 - val_mae: 0.1266 - val_mape: 767.4125\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0697 - mape: 6650.0068 - val_loss: 0.0183 - val_mse: 0.0183 - val_mae: 0.1036 - val_mape: 526.7408\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0709 - mape: 5738.7490 - val_loss: 0.0139 - val_mse: 0.0139 - val_mae: 0.0839 - val_mape: 228.1378\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0639 - mape: 6876.2168 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0802 - val_mape: 172.3572\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0612 - mape: 12361.0078 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0795 - val_mape: 217.5202\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0603 - mape: 2023.5942 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0767 - val_mape: 257.9963\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0582 - mape: 1217.3501 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0782 - val_mape: 277.3345\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0560 - mape: 3233.9409 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0783 - val_mape: 277.1686\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0050 - mse: 0.0050 - mae: 0.0549 - mape: 6805.5688 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0808 - val_mape: 321.2278\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0599 - mape: 1036.1696 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0851 - val_mape: 360.9148\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0622 - mape: 1004.7459 - val_loss: 0.0152 - val_mse: 0.0152 - val_mae: 0.0955 - val_mape: 469.8766\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0687 - mape: 9550.2520 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0803 - val_mape: 304.9211\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0738 - mape: 6768.7485 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0832 - val_mape: 258.8695\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0668 - mape: 16371.3428 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0779 - val_mape: 212.0370\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0601 - mape: 1336.6923 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0769 - val_mape: 230.6846\n",
      "9/9 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:30:00.426929: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5422068039076722902\n",
      "/tmp/ipykernel_718338/2433276998.py:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 4s 25ms/step - loss: 0.0402 - mse: 0.0402 - mae: 0.1507 - mape: 2290.2058 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0958 - val_mape: 329.1696\n",
      "Epoch 2/20\n",
      " 4/77 [>.............................] - ETA: 1s - loss: 0.0234 - mse: 0.0234 - mae: 0.1160 - mape: 403.3793"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:30:06.026739: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 27961498287980307\n",
      "2023-10-17 15:30:06.026819: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5422068039076722902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0169 - mse: 0.0169 - mae: 0.0973 - mape: 7190.2021 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0952 - val_mape: 309.9921\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0851 - mape: 3857.9216 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0960 - val_mape: 336.1583\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0820 - mape: 10908.1299 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0965 - val_mape: 349.1705\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0762 - mape: 15216.4521 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1135 - val_mape: 623.7964\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0717 - mape: 6200.3906 - val_loss: 0.0263 - val_mse: 0.0263 - val_mae: 0.1328 - val_mape: 824.8154\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0712 - mape: 3781.7163 - val_loss: 0.0169 - val_mse: 0.0169 - val_mae: 0.0956 - val_mape: 387.8935\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0094 - mse: 0.0094 - mae: 0.0750 - mape: 11264.1719 - val_loss: 0.0149 - val_mse: 0.0149 - val_mae: 0.0866 - val_mape: 150.0005\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0669 - mape: 12574.9434 - val_loss: 0.0152 - val_mse: 0.0152 - val_mae: 0.0927 - val_mape: 249.7119\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0616 - mape: 5011.5884 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0795 - val_mape: 304.7027\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0592 - mape: 1690.5110 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0761 - val_mape: 341.2533\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0568 - mape: 2085.3845 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0770 - val_mape: 351.3922\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0553 - mape: 10011.6055 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0776 - val_mape: 356.2541\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0547 - mape: 4704.7183 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0819 - val_mape: 307.7119\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0538 - mape: 2278.8953 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0771 - val_mape: 354.9669\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0522 - mape: 10914.6445 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0763 - val_mape: 304.3570\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0519 - mape: 7898.9165 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0762 - val_mape: 368.2770\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0518 - mape: 5132.3223 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0767 - val_mape: 355.4379\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0539 - mape: 2112.0952 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0872 - val_mape: 462.8465\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0736 - mape: 1166.1132 - val_loss: 0.0311 - val_mse: 0.0311 - val_mae: 0.1495 - val_mape: 931.0325\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:30:38.418199: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5422068039076722902\n",
      "/tmp/ipykernel_718338/2433276998.py:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_27 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     76/Unknown - 4s 19ms/step - loss: 0.0932 - mse: 0.0932 - mae: 0.2105 - mape: 28848.9414"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:30:43.552833: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 27961498287980307\n",
      "2023-10-17 15:30:43.552907: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5422068039076722902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 4s 25ms/step - loss: 0.0929 - mse: 0.0929 - mae: 0.2101 - mape: 28736.5117 - val_loss: 0.0179 - val_mse: 0.0179 - val_mae: 0.0936 - val_mape: 177.5007\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0211 - mse: 0.0211 - mae: 0.1108 - mape: 3852.4370 - val_loss: 0.0192 - val_mse: 0.0192 - val_mae: 0.0961 - val_mape: 100.7330\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0154 - mse: 0.0154 - mae: 0.0944 - mape: 9915.1729 - val_loss: 0.0192 - val_mse: 0.0192 - val_mae: 0.0962 - val_mape: 101.0092\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0843 - mape: 11076.9248 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0987 - val_mape: 142.6039\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0773 - mape: 7047.1631 - val_loss: 0.0180 - val_mse: 0.0180 - val_mae: 0.0937 - val_mape: 164.0666\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0723 - mape: 930.0108 - val_loss: 0.0177 - val_mse: 0.0177 - val_mae: 0.0932 - val_mape: 176.8928\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0693 - mape: 6469.1997 - val_loss: 0.0178 - val_mse: 0.0178 - val_mae: 0.0928 - val_mape: 118.0961\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0673 - mape: 9363.1523 - val_loss: 0.0151 - val_mse: 0.0151 - val_mae: 0.0873 - val_mape: 145.2448\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0641 - mape: 4329.9316 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0802 - val_mape: 256.3935\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0625 - mape: 9999.1768 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0770 - val_mape: 239.0315\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0649 - mape: 3648.4541 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0793 - val_mape: 391.6172\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0668 - mape: 2600.9780 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0839 - val_mape: 399.9867\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0681 - mape: 9788.0732 - val_loss: 0.0242 - val_mse: 0.0242 - val_mae: 0.1298 - val_mape: 669.3530\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0825 - mape: 28363.9512 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0863 - val_mape: 369.1361\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0666 - mape: 3252.0674 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0826 - val_mape: 345.9398\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0599 - mape: 6527.6118 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0771 - val_mape: 291.8965\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0592 - mape: 13809.3252 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0757 - val_mape: 262.5931\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0610 - mape: 2629.9458 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0849 - val_mape: 423.2745\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0655 - mape: 15221.2393 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.1077 - val_mape: 655.9595\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0644 - mape: 10117.2148 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0903 - val_mape: 518.0980\n",
      "9/9 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_718338/2433276998.py:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_28 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_29 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_30 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_31 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     76/Unknown - 5s 19ms/step - loss: 0.0390 - mse: 0.0390 - mae: 0.1493 - mape: 15901.3867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:31:22.180267: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5422068039076722902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 5s 24ms/step - loss: 0.0390 - mse: 0.0390 - mae: 0.1491 - mape: 15839.9404 - val_loss: 0.0184 - val_mse: 0.0184 - val_mae: 0.1014 - val_mape: 453.6438\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0166 - mse: 0.0166 - mae: 0.0969 - mape: 12169.5146 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0959 - val_mape: 332.6686\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0842 - mape: 2411.1704 - val_loss: 0.0181 - val_mse: 0.0181 - val_mae: 0.0999 - val_mape: 424.9244\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0808 - mape: 14273.0771 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0936 - val_mape: 222.6135\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0799 - mape: 2329.1594 - val_loss: 0.0189 - val_mse: 0.0189 - val_mae: 0.1041 - val_mape: 497.4399\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0768 - mape: 1239.1174 - val_loss: 0.0188 - val_mse: 0.0188 - val_mae: 0.1040 - val_mape: 505.7051\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0089 - mse: 0.0089 - mae: 0.0729 - mape: 6745.2983 - val_loss: 0.0170 - val_mse: 0.0170 - val_mae: 0.0910 - val_mape: 144.3527\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0682 - mape: 2662.6306 - val_loss: 0.0161 - val_mse: 0.0161 - val_mae: 0.0903 - val_mape: 133.8829\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0662 - mape: 11707.8447 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0954 - val_mape: 281.5985\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0651 - mape: 4151.5947 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0755 - val_mape: 326.8592\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0657 - mape: 1819.0839 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0884 - val_mape: 509.6184\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0648 - mape: 2729.1836 - val_loss: 0.0136 - val_mse: 0.0136 - val_mae: 0.0915 - val_mape: 496.4059\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0634 - mape: 9864.2432 - val_loss: 0.0116 - val_mse: 0.0116 - val_mae: 0.0821 - val_mape: 437.9542\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0604 - mape: 9826.7246 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0757 - val_mape: 350.9601\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0594 - mape: 8492.6143 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0755 - val_mape: 298.2398\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0599 - mape: 10345.4395 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0770 - val_mape: 242.0857\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0617 - mape: 2448.6201 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0886 - val_mape: 446.7646\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0585 - mape: 6649.9380 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0806 - val_mape: 352.5161\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0570 - mape: 15258.1729 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0802 - val_mape: 395.2506\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0577 - mape: 4652.9492 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0764 - val_mape: 321.1648\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:31:55.231983: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5422068039076722902\n",
      "/tmp/ipykernel_718338/2433276998.py:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_32 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_33 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_34 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_35 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 4s 24ms/step - loss: 0.0383 - mse: 0.0383 - mae: 0.1478 - mape: 27698.9844 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0939 - val_mape: 248.9394\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0169 - mse: 0.0169 - mae: 0.0983 - mape: 8076.3394 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.1076 - val_mape: 546.4181\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0854 - mape: 18766.2148 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1161 - val_mape: 653.6123\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0796 - mape: 13877.2285 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.1085 - val_mape: 559.1060\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0746 - mape: 12142.5312 - val_loss: 0.0179 - val_mse: 0.0179 - val_mae: 0.0989 - val_mape: 407.3240\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0700 - mape: 6238.6460 - val_loss: 0.0223 - val_mse: 0.0223 - val_mae: 0.1186 - val_mape: 686.4743\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0691 - mape: 3569.9209 - val_loss: 0.0275 - val_mse: 0.0275 - val_mae: 0.1377 - val_mape: 877.0629\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0697 - mape: 729.6943 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0852 - val_mape: 196.4994\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0688 - mape: 2632.1301 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.0951 - val_mape: 253.1939\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0621 - mape: 694.1248 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0780 - val_mape: 216.3972\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0602 - mape: 2680.7854 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0776 - val_mape: 206.5638\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0593 - mape: 6135.4604 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0768 - val_mape: 295.5254\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0608 - mape: 1695.4764 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0814 - val_mape: 228.4309\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0634 - mape: 3725.8472 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0778 - val_mape: 241.6223\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0730 - mape: 5452.0508 - val_loss: 0.0166 - val_mse: 0.0166 - val_mae: 0.1026 - val_mape: 552.6860\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0703 - mape: 3285.2859 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0785 - val_mape: 268.5415\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0611 - mape: 1845.0634 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0759 - val_mape: 251.7732\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0547 - mape: 2199.1750 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0761 - val_mape: 226.9936\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0526 - mape: 1151.2087 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0761 - val_mape: 284.7166\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0516 - mape: 5329.0195 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0770 - val_mape: 247.9162\n",
      "9/9 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_718338/2433276998.py:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_36 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_37 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_38 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_39 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 5s 25ms/step - loss: 0.0695 - mse: 0.0695 - mae: 0.1862 - mape: 12284.0400 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0936 - val_mape: 212.7098\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0197 - mse: 0.0197 - mae: 0.1064 - mape: 19624.9961 - val_loss: 0.0185 - val_mse: 0.0185 - val_mae: 0.1018 - val_mape: 460.9370\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0149 - mse: 0.0149 - mae: 0.0925 - mape: 12298.6201 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.1119 - val_mape: 602.6611\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0813 - mape: 13401.1514 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.1128 - val_mape: 614.3895\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0768 - mape: 3372.8352 - val_loss: 0.0226 - val_mse: 0.0226 - val_mae: 0.1195 - val_mape: 691.9500\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0730 - mape: 4657.9702 - val_loss: 0.0238 - val_mse: 0.0238 - val_mae: 0.1241 - val_mape: 741.5551\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0688 - mape: 10123.4307 - val_loss: 0.0273 - val_mse: 0.0273 - val_mae: 0.1373 - val_mape: 872.0107\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0678 - mape: 1609.6138 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.1133 - val_mape: 676.6620\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0696 - mape: 1829.4498 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0852 - val_mape: 360.1273\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0740 - mape: 5583.6729 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0777 - val_mape: 233.6727\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0647 - mape: 7876.1006 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0753 - val_mape: 284.9776\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0580 - mape: 2680.0615 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0832 - val_mape: 404.9563\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0563 - mape: 2065.7715 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0780 - val_mape: 304.5034\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0540 - mape: 6707.7021 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0794 - val_mape: 267.6191\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0541 - mape: 876.0098 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0852 - val_mape: 330.3846\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0567 - mape: 23110.1602 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0769 - val_mape: 318.1232\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0568 - mape: 11773.9893 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0778 - val_mape: 314.4044\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0586 - mape: 5566.2075 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0796 - val_mape: 312.8439\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0593 - mape: 2035.7440 - val_loss: 0.0150 - val_mse: 0.0150 - val_mae: 0.0956 - val_mape: 394.8624\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0671 - mape: 5991.4258 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0780 - val_mape: 284.0960\n",
      "9/9 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:33:11.557796: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5422068039076722902\n",
      "/tmp/ipykernel_718338/2433276998.py:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_test_overall  = pd.DataFrame(columns=['State_3E', \"seq\", \"prediction\"])\n",
    "print(df_test_overall)\n",
    "corr_list = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    \n",
    "    input_path_train = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_train.csv\"\n",
    "    input_path_valid = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_validation.csv\"\n",
    "    input_path_test = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_test.csv\"\n",
    "    df_test = pd.read_csv(input_path_test)\n",
    "\n",
    "    # Get first item of the dataset to get the shape of the input data\n",
    "    for element in data_reader(input_path_train):\n",
    "        input_shape = element[0].shape\n",
    "\n",
    "    inputs = Input(shape=(input_shape[1],input_shape[2]), name=\"inputs\")\n",
    "    layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "    predictions = Dense(1, activation='linear')(layer)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "                )\n",
    "\n",
    "    history=model.fit(data_reader(input_path_train, batch_size=100),\n",
    "                            epochs=20,\n",
    "                            validation_data=data_reader(input_path_valid,batch_size=100),\n",
    "                            callbacks=None,\n",
    "                            verbose=1)\n",
    "\n",
    "    predicted = model.predict(data_reader(input_path_test,\n",
    "                                                batch_size=100))\n",
    "\n",
    "    test_data = data_reader(input_path_test,batch_size=100)\n",
    "    test_tensor = X = np.empty(shape=[0,1])\n",
    "    for batch in test_data:\n",
    "        test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "    df_test[\"prediction\"] = predicted\n",
    "    df_test[\"fold\"] = str(i)\n",
    "    df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n",
    "\n",
    "    \n",
    "    def pearson_correlation(x, y):\n",
    "        n = len(x)\n",
    "        # Calculate the mean of x and y\n",
    "        mean_x = sum(x) / n\n",
    "        mean_y = sum(y) / n\n",
    "        \n",
    "        # Calculate the numerator and denominators of the correlation coefficient\n",
    "        numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "        denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "        denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "        \n",
    "        # Calculate the correlation coefficient\n",
    "        correlation = numerator / (denominator_x * denominator_y)\n",
    "        return correlation\n",
    "        \n",
    "    corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)\n",
    "    corr_list.append(corr_coefficient)\n",
    "\n",
    "df_test_overall.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/LibA_wide_pivot_state3_test_predicted_cv10fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390ef722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def create_plots(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "create_plots(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7951a63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_3E</th>\n",
       "      <th>seq</th>\n",
       "      <th>prediction</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007714</td>\n",
       "      <td>AGGACCGGATCAACTAAACAACTCAAACAAGGGCTAATATAACCCA...</td>\n",
       "      <td>-0.066135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.137953</td>\n",
       "      <td>AGGACCGGATCAACTAAACACTAGTCATACTTAAAAATTGCAAGGA...</td>\n",
       "      <td>0.010291</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.048706</td>\n",
       "      <td>AGGACCGGATCAACTAAACAGGTTCTGACGTATGCTCCTCTATGGA...</td>\n",
       "      <td>-0.075280</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052804</td>\n",
       "      <td>AGGACCGGATCAACTAAACCCGAGCCTGCCTAGCCCTAGCTTCTCT...</td>\n",
       "      <td>-0.063390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.213652</td>\n",
       "      <td>AGGACCGGATCAACTAAACGGAGCAGAGTTAGTGTCAGGTCAAAAA...</td>\n",
       "      <td>0.164081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8473</th>\n",
       "      <td>0.167100</td>\n",
       "      <td>AGGACCGGATCAACTTTTCCGCCTTTTATTATCAGGACTTCACGGG...</td>\n",
       "      <td>0.259291</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474</th>\n",
       "      <td>0.099489</td>\n",
       "      <td>AGGACCGGATCAACTTTTCGCTCATTAGTACAGGGTATAACGGAAG...</td>\n",
       "      <td>0.028705</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8475</th>\n",
       "      <td>-0.046939</td>\n",
       "      <td>AGGACCGGATCAACTTTTGGTCGGTTGACGGTCGCCTTGATTATTC...</td>\n",
       "      <td>-0.024755</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>0.093662</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTATCTGGTTATCATTCTAGTCTAGTGC...</td>\n",
       "      <td>0.038336</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8477</th>\n",
       "      <td>0.199862</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTCCCCGTCTGCCAACTTCGTGGCTATC...</td>\n",
       "      <td>0.201938</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8478 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      State_3E                                                seq  prediction  \\\n",
       "0    -0.007714  AGGACCGGATCAACTAAACAACTCAAACAAGGGCTAATATAACCCA...   -0.066135   \n",
       "1     0.137953  AGGACCGGATCAACTAAACACTAGTCATACTTAAAAATTGCAAGGA...    0.010291   \n",
       "2    -0.048706  AGGACCGGATCAACTAAACAGGTTCTGACGTATGCTCCTCTATGGA...   -0.075280   \n",
       "3    -0.052804  AGGACCGGATCAACTAAACCCGAGCCTGCCTAGCCCTAGCTTCTCT...   -0.063390   \n",
       "4     0.213652  AGGACCGGATCAACTAAACGGAGCAGAGTTAGTGTCAGGTCAAAAA...    0.164081   \n",
       "...        ...                                                ...         ...   \n",
       "8473  0.167100  AGGACCGGATCAACTTTTCCGCCTTTTATTATCAGGACTTCACGGG...    0.259291   \n",
       "8474  0.099489  AGGACCGGATCAACTTTTCGCTCATTAGTACAGGGTATAACGGAAG...    0.028705   \n",
       "8475 -0.046939  AGGACCGGATCAACTTTTGGTCGGTTGACGGTCGCCTTGATTATTC...   -0.024755   \n",
       "8476  0.093662  AGGACCGGATCAACTTTTTTATCTGGTTATCATTCTAGTCTAGTGC...    0.038336   \n",
       "8477  0.199862  AGGACCGGATCAACTTTTTTCCCCGTCTGCCAACTTCGTGGCTATC...    0.201938   \n",
       "\n",
       "     fold  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "...   ...  \n",
       "8473   10  \n",
       "8474   10  \n",
       "8475   10  \n",
       "8476   10  \n",
       "8477   10  \n",
       "\n",
       "[8478 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_overall.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/LibA_wide_pivot_state3_test_predicted_cv10fold.csv\", index=False)\n",
    "df_test_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3096cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c83df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_overall  = pd.DataFrame(columns=['State_3E', \"seq\", \"prediction\"])\n",
    "\n",
    "    \n",
    "input_path_train = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV1_LibA_wide_pivot_state3_train.csv\"\n",
    "input_path_valid = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV1_LibA_wide_pivot_state3_validation.csv\"\n",
    "input_path_test = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV1_LibA_wide_pivot_state3_test.csv\"\n",
    "df_test = pd.read_csv(input_path_test)\n",
    "\n",
    "# Get first item of the dataset to get the shape of the input data\n",
    "for element in data_reader(input_path_train):\n",
    "    input_shape = element[0].shape\n",
    "\n",
    "inputs = Input(shape=(input_shape[1],input_shape[2]), name=\"inputs\")\n",
    "layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "predictions = Dense(1, activation='linear')(layer)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "            loss=\"mean_squared_error\",\n",
    "            metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "            )\n",
    "\n",
    "history=model.fit(data_reader(input_path_train, batch_size=100),\n",
    "                        epochs=20,\n",
    "                        validation_data=data_reader(input_path_valid,batch_size=100),\n",
    "                        callbacks=None,\n",
    "                        verbose=1)\n",
    "\n",
    "predicted = model.predict(data_reader(input_path_test,\n",
    "                                            batch_size=100))\n",
    "\n",
    "test_data = data_reader(input_path_test,batch_size=100)\n",
    "test_tensor = X = np.empty(shape=[0,1])\n",
    "for batch in test_data:\n",
    "    test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "df_test[\"prediction\"] = predicted\n",
    "df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n",
    "\n",
    "\n",
    "def pearson_correlation(x, y):\n",
    "    n = len(x)\n",
    "    # Calculate the mean of x and y\n",
    "    mean_x = sum(x) / n\n",
    "    mean_y = sum(y) / n\n",
    "    \n",
    "    # Calculate the numerator and denominators of the correlation coefficient\n",
    "    numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "    denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "    denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "    \n",
    "    # Calculate the correlation coefficient\n",
    "    correlation = numerator / (denominator_x * denominator_y)\n",
    "    return correlation\n",
    "    \n",
    "corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0fb877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d268f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7571493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# Split the data in three partitions\n",
    "whole_data=pd.read_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ.csv\")\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 2008)\n",
    "result = next(kf.split(whole_data), None)\n",
    "\n",
    "o=1\n",
    "for i in kf.split(whole_data):\n",
    "    train = whole_data.iloc[i[0]]\n",
    "    test =  whole_data.iloc[i[1]]\n",
    "    \n",
    "    train, validation = train_test_split(whole_data, test_size=0.10, random_state=42)\n",
    "    \n",
    "    train[[\"meanVal\", \"sequence\"]].to_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/10fold_cv/CV\"+str(o)+\"_mean_with_sequence_ENCFF616IAQ_train.csv\", index=False)\n",
    "    test[[\"meanVal\", \"sequence\"]].to_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/10fold_cv/CV\"+str(o)+\"_mean_with_sequence_ENCFF616IAQ_test.csv\", index=False)\n",
    "    validation[[\"meanVal\", \"sequence\"]].to_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/10fold_cv/CV\"+str(o)+\"_mean_with_sequence_ENCFF616IAQ_validation.csv\", index=False)\n",
    "    o+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71949262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_overall  = pd.DataFrame(columns=[\"meanVal\", \"Sequence\"])\n",
    "print(df_test_overall)\n",
    "corr_list = []\n",
    "\n",
    "for i in range(1,10):\n",
    "    \n",
    "    input_path_train = \"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/10fold_cv/CV\"+str(i)+\"_mean_with_sequence_ENCFF616IAQ_train.csv\"\n",
    "    input_path_valid = \"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/10fold_cv/CV\"+str(i)+\"_mean_with_sequence_ENCFF616IAQ_validation.csv\"\n",
    "    input_path_test = \"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/10fold_cv/CV\"+str(i)+\"_mean_with_sequence_ENCFF616IAQ_test.csv\"\n",
    "   \n",
    "    df_test = pd.read_csv(input_path_test)\n",
    "\n",
    "    # Get first item of the dataset to get the shape of the input data\n",
    "    for element in data_reader(input_path_train):\n",
    "        input_shape = element[0].shape\n",
    "\n",
    "    inputs = Input(shape=(input_shape[1],input_shape[2]), name=\"inputs\")\n",
    "    layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "    predictions = Dense(1, activation='linear')(layer)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "                )\n",
    "\n",
    "    history=model.fit(data_reader(input_path_train, batch_size=1024),\n",
    "                            epochs=20,\n",
    "                            validation_data=data_reader(input_path_valid,batch_size=100),\n",
    "                            callbacks=None,\n",
    "                            verbose=1)\n",
    "\n",
    "    predicted = model.predict(data_reader(input_path_test,\n",
    "                                                batch_size=100))\n",
    "\n",
    "    test_data = data_reader(input_path_test,batch_size=100)\n",
    "    test_tensor = X = np.empty(shape=[0,1])\n",
    "    for batch in test_data:\n",
    "        test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "    df_test[\"prediction\"] = predicted\n",
    "    df_test[\"fold\"] = str(i)\n",
    "    df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n",
    "    \n",
    "    def pearson_correlation(x, y):\n",
    "        n = len(x)\n",
    "        # Calculate the mean of x and y\n",
    "        mean_x = sum(x) / n\n",
    "        mean_y = sum(y) / n\n",
    "        \n",
    "        # Calculate the numerator and denominators of the correlation coefficient\n",
    "        numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "        denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "        denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "        \n",
    "        # Calculate the correlation coefficient\n",
    "        correlation = numerator / (denominator_x * denominator_y)\n",
    "        return correlation\n",
    "        \n",
    "    corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)\n",
    "    corr_list.append(corr_coefficient)\n",
    "\n",
    "df_test_overall.to_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/10fold_cv/mean_with_sequence_ENCFF616IAQ_test_predicted_cv10fold.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
