{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c1f9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import getopt\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Lambda, concatenate, Bidirectional, Dense, Dropout, Flatten, Conv1D,BatchNormalization,  MaxPooling1D, Bidirectional, GRU, TimeDistributed\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n",
    "vocab = [\"A\", \"G\", \"C\", \"T\"]\n",
    "indices = tf.range(len(vocab), dtype = tf.int64)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab,indices)\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, 1)\n",
    "defs = [0.] * 1 + [tf.constant([], dtype = \"string\")]\n",
    "\n",
    "# Nadav dataset\n",
    "\n",
    "def data_reader(file, batch_size=100, n_parse_threads = 4):\n",
    "    dataset = tf.data.TextLineDataset(file).skip(1)\n",
    "    dataset=dataset.map(preprocess, num_parallel_calls = n_parse_threads)\n",
    "    return dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "def preprocess(record):\n",
    "    fields = tf.io.decode_csv(record, record_defaults=defs)\n",
    "    chars = tf.strings.bytes_split(fields[1])\n",
    "    chars_indeces = table.lookup(chars)\n",
    "    X = tf.one_hot(chars_indeces, depth = len(vocab))\n",
    "    Y = fields[0]\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9eaa2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data in three partitions\n",
    "file=\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3.csv\"\n",
    "whole_data = pd.read_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3.csv\")\n",
    "\n",
    "df_train, df_test = train_test_split(whole_data, test_size=0.2, random_state=42)\n",
    "df_validation, df_test = train_test_split(df_test, test_size=0.5, random_state=42)\n",
    "\n",
    "df_train.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3_train.csv\", index=False)\n",
    "df_test.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3_test.csv\", index=False)\n",
    "df_validation.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3_validation.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be0250f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "7/7 [==============================] - 4s 275ms/step - loss: 0.2998 - mse: 0.2998 - mae: 0.4688 - mape: 49724.5117 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1265 - val_mape: 15898.5029\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 14:02:49.904138: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6726460305429972793\n",
      "2023-10-16 14:02:49.904233: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 553158323905315772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 241ms/step - loss: 0.0933 - mse: 0.0933 - mae: 0.2567 - mape: 49036.4766 - val_loss: 0.0566 - val_mse: 0.0566 - val_mae: 0.1958 - val_mape: 18938.7520\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 2s 239ms/step - loss: 0.0576 - mse: 0.0576 - mae: 0.1875 - mape: 13385.5723 - val_loss: 0.0328 - val_mse: 0.0328 - val_mae: 0.1533 - val_mape: 21369.5801\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 2s 226ms/step - loss: 0.0405 - mse: 0.0405 - mae: 0.1597 - mape: 44409.5234 - val_loss: 0.0386 - val_mse: 0.0386 - val_mae: 0.1480 - val_mape: 11794.4434\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 2s 236ms/step - loss: 0.0336 - mse: 0.0336 - mae: 0.1417 - mape: 14764.5156 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.1073 - val_mape: 10528.7275\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 2s 236ms/step - loss: 0.0285 - mse: 0.0285 - mae: 0.1302 - mape: 12499.4150 - val_loss: 0.0231 - val_mse: 0.0231 - val_mae: 0.1025 - val_mape: 1549.1666\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 2s 230ms/step - loss: 0.0259 - mse: 0.0259 - mae: 0.1258 - mape: 9976.8447 - val_loss: 0.0222 - val_mse: 0.0222 - val_mae: 0.1004 - val_mape: 519.5851\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 2s 231ms/step - loss: 0.0236 - mse: 0.0236 - mae: 0.1177 - mape: 24640.8184 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0971 - val_mape: 4248.1074\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 2s 238ms/step - loss: 0.0219 - mse: 0.0219 - mae: 0.1155 - mape: 17893.1445 - val_loss: 0.0224 - val_mse: 0.0224 - val_mae: 0.1008 - val_mape: 728.7455\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 2s 223ms/step - loss: 0.0194 - mse: 0.0194 - mae: 0.1084 - mape: 5252.1904 - val_loss: 0.0228 - val_mse: 0.0228 - val_mae: 0.1017 - val_mape: 1194.5654\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 1s 212ms/step - loss: 0.0188 - mse: 0.0188 - mae: 0.1073 - mape: 9327.7656 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.0981 - val_mape: 1307.8491\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 2s 233ms/step - loss: 0.0174 - mse: 0.0174 - mae: 0.1029 - mape: 19270.3047 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.0988 - val_mape: 672.0521\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 2s 238ms/step - loss: 0.0163 - mse: 0.0163 - mae: 0.0994 - mape: 8280.6055 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.1009 - val_mape: 768.0638\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 2s 242ms/step - loss: 0.0153 - mse: 0.0153 - mae: 0.0964 - mape: 4056.8477 - val_loss: 0.0229 - val_mse: 0.0229 - val_mae: 0.1018 - val_mape: 1236.2535\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 2s 240ms/step - loss: 0.0145 - mse: 0.0145 - mae: 0.0942 - mape: 3110.8435 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1014 - val_mape: 1046.4635\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 2s 241ms/step - loss: 0.0140 - mse: 0.0140 - mae: 0.0923 - mape: 20900.3809 - val_loss: 0.0229 - val_mse: 0.0229 - val_mae: 0.1019 - val_mape: 1286.0348\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 2s 242ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0881 - mape: 1750.4740 - val_loss: 0.0248 - val_mse: 0.0248 - val_mae: 0.1070 - val_mape: 3204.9480\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 2s 229ms/step - loss: 0.0115 - mse: 0.0115 - mae: 0.0842 - mape: 7360.9272 - val_loss: 0.0254 - val_mse: 0.0254 - val_mae: 0.1087 - val_mape: 3732.7007\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 2s 242ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0820 - mape: 11221.8105 - val_loss: 0.0267 - val_mse: 0.0267 - val_mae: 0.1125 - val_mape: 4809.8042\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 2s 241ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0807 - mape: 13871.7031 - val_loss: 0.0274 - val_mse: 0.0274 - val_mae: 0.1144 - val_mape: 5301.4917\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "input_path_train = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3_train.csv\"\n",
    "input_path_valid = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3_validation.csv\"\n",
    "input_path_test = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3_test.csv\"\n",
    "\n",
    "# Get first item of the dataset to get the shape of the input data\n",
    "for element in data_reader(file):\n",
    "    input_shape = element[0].shape\n",
    "\n",
    "inputs = Input(shape=(input_shape[1],input_shape[2]), name=\"inputs\")\n",
    "layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "predictions = Dense(1, activation='linear')(layer)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"mean_squared_error\",\n",
    "              metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "              )\n",
    "\n",
    "history=model.fit(data_reader(input_path_train, batch_size=1024),\n",
    "                        epochs=20,\n",
    "                        validation_data=data_reader(file,batch_size=100),\n",
    "                        callbacks=None,\n",
    "                        verbose=1)\n",
    "\n",
    "predicted = model.predict(data_reader(input_path_test,\n",
    "                                            batch_size=100))\n",
    "\n",
    "test_data = data_reader(input_path_test,batch_size=100)\n",
    "test_tensor = X = np.empty(shape=[0,1])\n",
    "for batch in test_data:\n",
    "    test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "import math\n",
    "def pearson_correlation(x, y):\n",
    "    n = len(x)\n",
    "    # Calculate the mean of x and y\n",
    "    mean_x = sum(x) / n\n",
    "    mean_y = sum(y) / n\n",
    "    \n",
    "    # Calculate the numerator and denominators of the correlation coefficient\n",
    "    numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "    denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "    denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "    \n",
    "    # Calculate the correlation coefficient\n",
    "    correlation = numerator / (denominator_x * denominator_y)\n",
    "    return correlation\n",
    "    \n",
    "corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb17cf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.43623343891527105\n",
      "Test Data : \n",
      "[ 0.07387622 -0.02064122 -0.01574964 -0.14560808  0.02438584 -0.00905595\n",
      "  0.02555897 -0.01925485  0.1474456   0.00337036]\n",
      "Predictions :\n",
      "[[0.04586424]\n",
      " [0.04586142]\n",
      " [0.04586267]\n",
      " [0.0458631 ]\n",
      " [0.04586616]\n",
      " [0.04586191]\n",
      " [0.04586439]\n",
      " [0.0458629 ]\n",
      " [0.04586322]\n",
      " [0.04586347]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Correlation: \"+str(corr_coefficient))\n",
    "print(\"Test Data : \\n\"+str(test_tensor[:10]))\n",
    "print(\"Predictions :\\n\" +str(predicted[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "231bf175",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"prediction\"] = predicted\n",
    "df_test.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3_test_predicte.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53771072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data in three partitions\n",
    "file=\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ.csv\"\n",
    "whole_data = pd.read_csv(file)\n",
    "\n",
    "df_train, df_test = train_test_split(whole_data, test_size=0.2, random_state=42)\n",
    "df_validation, df_test = train_test_split(df_test, test_size=0.5, random_state=42)\n",
    "\n",
    "df_train[[\"meanVal\", \"sequence\"]].to_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_train.csv\", index=False)\n",
    "df_test[[\"meanVal\", \"sequence\"]].to_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_test.csv\", index=False)\n",
    "df_validation[[\"meanVal\", \"sequence\"]].to_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1992403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 200, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 194, 250)          7250      \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 194, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 194, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 187, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 187, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 93, 250)           0         \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 93, 250)           0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 91, 250)           187750    \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 91, 250)           1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 91, 250)           0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 90, 100)           50100     \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 90, 100)           400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 90, 100)           0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 90, 100)           0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 9000)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 300)               2700300   \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3509451 (13.39 MB)\n",
      "Trainable params: 3507751 (13.38 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "    177/Unknown - 18s 86ms/step - loss: 0.2300 - mse: 0.2300 - mae: 0.3686 - mape: 16881.7852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 13:24:18.672193: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6726460305429972793\n",
      "2023-10-16 13:24:18.672272: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 553158323905315772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 20s 97ms/step - loss: 0.2299 - mse: 0.2299 - mae: 0.3685 - mape: 16853.4922 - val_loss: 0.2727 - val_mse: 0.2727 - val_mae: 0.3933 - val_mape: 1382.4210\n",
      "Epoch 2/15\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.1743 - mse: 0.1743 - mae: 0.3196 - mape: 18018.6973 - val_loss: 0.2746 - val_mse: 0.2746 - val_mae: 0.3924 - val_mape: 734.6246\n",
      "Epoch 3/15\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.1621 - mse: 0.1621 - mae: 0.3076 - mape: 15719.6982 - val_loss: 0.2665 - val_mse: 0.2665 - val_mae: 0.3867 - val_mape: 550.0858\n",
      "Epoch 4/15\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.1535 - mse: 0.1535 - mae: 0.2993 - mape: 18624.5156 - val_loss: 0.2015 - val_mse: 0.2015 - val_mae: 0.3344 - val_mape: 2385.3145\n",
      "Epoch 5/15\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.1489 - mse: 0.1489 - mae: 0.2950 - mape: 11971.6855 - val_loss: 0.1598 - val_mse: 0.1598 - val_mae: 0.2941 - val_mape: 7801.4077\n",
      "Epoch 6/15\n",
      "178/178 [==============================] - 17s 98ms/step - loss: 0.1441 - mse: 0.1441 - mae: 0.2900 - mape: 17236.7148 - val_loss: 0.1521 - val_mse: 0.1521 - val_mae: 0.2879 - val_mape: 8081.5391\n",
      "Epoch 7/15\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.1412 - mse: 0.1412 - mae: 0.2869 - mape: 15214.2607 - val_loss: 0.1671 - val_mse: 0.1671 - val_mae: 0.3015 - val_mape: 10547.4082\n",
      "Epoch 8/15\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.1382 - mse: 0.1382 - mae: 0.2838 - mape: 17412.6367 - val_loss: 0.1271 - val_mse: 0.1271 - val_mae: 0.2652 - val_mape: 7389.6567\n",
      "Epoch 9/15\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.1362 - mse: 0.1362 - mae: 0.2819 - mape: 18613.9277 - val_loss: 0.1663 - val_mse: 0.1663 - val_mae: 0.3002 - val_mape: 11570.0723\n",
      "Epoch 10/15\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.1343 - mse: 0.1343 - mae: 0.2799 - mape: 12421.9785 - val_loss: 0.1473 - val_mse: 0.1473 - val_mae: 0.2815 - val_mape: 9637.2070\n",
      "Epoch 11/15\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.1327 - mse: 0.1327 - mae: 0.2782 - mape: 17507.1797 - val_loss: 0.1554 - val_mse: 0.1554 - val_mae: 0.2908 - val_mape: 9612.2939\n",
      "Epoch 12/15\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.1315 - mse: 0.1315 - mae: 0.2769 - mape: 17663.4648 - val_loss: 0.1355 - val_mse: 0.1355 - val_mae: 0.2715 - val_mape: 7901.4287\n",
      "Epoch 13/15\n",
      "178/178 [==============================] - 17s 96ms/step - loss: 0.1300 - mse: 0.1300 - mae: 0.2753 - mape: 15796.8145 - val_loss: 0.1495 - val_mse: 0.1495 - val_mae: 0.2848 - val_mape: 8518.7656\n",
      "Epoch 14/15\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.1284 - mse: 0.1284 - mae: 0.2737 - mape: 20697.4355 - val_loss: 0.1343 - val_mse: 0.1343 - val_mae: 0.2706 - val_mape: 5995.7632\n",
      "Epoch 15/15\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.1274 - mse: 0.1274 - mae: 0.2723 - mape: 14041.9531 - val_loss: 0.1532 - val_mse: 0.1532 - val_mae: 0.2884 - val_mape: 7874.4272\n",
      "227/227 [==============================] - 2s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_path_train = \"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_train.csv\"\n",
    "input_path_test = \"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_test.csv\"\n",
    "input_path_valid = \"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_validation.csv\"\n",
    "\n",
    "# Get first item of the dataset to get the shape of the input data\n",
    "for element in data_reader(input_path_train):\n",
    "    input_shape = element[0].shape\n",
    "\n",
    "inputs = Input(shape=(input_shape[1],input_shape[2]), name=\"inputs\")\n",
    "layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "predictions = Dense(1, activation='linear')(layer)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"mean_squared_error\",\n",
    "              metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "              )\n",
    "\n",
    "history=model.fit(data_reader(input_path_train, batch_size=1024),\n",
    "                        epochs=15,\n",
    "                        validation_data=data_reader(input_path_valid,batch_size=100),\n",
    "                        callbacks=None,\n",
    "                        verbose=1)\n",
    "\n",
    "predicted = model.predict(data_reader(input_path_test,\n",
    "                                            batch_size=100))\n",
    "\n",
    "test_data = data_reader(input_path_test,batch_size=100)\n",
    "test_tensor = X = np.empty(shape=[0,1])\n",
    "for batch in test_data:\n",
    "    test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "import math\n",
    "def pearson_correlation(x, y):\n",
    "    n = len(x)\n",
    "    # Calculate the mean of x and y\n",
    "    mean_x = sum(x) / n\n",
    "    mean_y = sum(y) / n\n",
    "    \n",
    "    # Calculate the numerator and denominators of the correlation coefficient\n",
    "    numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "    denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "    denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "    \n",
    "    # Calculate the correlation coefficient\n",
    "    correlation = numerator / (denominator_x * denominator_y)\n",
    "    return correlation\n",
    "    \n",
    "corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d1dd2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation: 0.741615309417504\n",
      "Test Data : \n",
      "[-0.48159999 -0.29210001 -0.1759     -0.013      -0.1503     -0.83139998\n",
      "  0.21950001 -0.37349999 -0.76859999 -0.4903    ]\n",
      "Predictions :\n",
      "[[ 0.11326885]\n",
      " [-0.35315323]\n",
      " [-0.13910185]\n",
      " [-0.08272813]\n",
      " [-0.45598155]\n",
      " [-0.58133066]\n",
      " [ 0.1547365 ]\n",
      " [-0.38562232]\n",
      " [-0.4525873 ]\n",
      " [-0.33103788]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Correlation: \"+str(corr_coefficient))\n",
    "print(\"Test Data : \\n\"+str(test_tensor[:10]))\n",
    "print(\"Predictions :\\n\" +str(predicted[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b903c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def create_plots(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "create_plots(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dd865d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:809\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 809\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    810\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:772\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 772\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    773\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    774\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    775\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    777\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3028\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3028\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3029\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5888\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5887\u001b[0m e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m-> 5888\u001b[0m \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} End of sequence [Op:IteratorGetNext] name: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/simple_regression.ipynb Cell 11\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/simple_regression.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m shuffled_dataset \u001b[39m=\u001b[39m _dataset\u001b[39m.\u001b[39mshuffle(\u001b[39m5000\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/simple_regression.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m iterator \u001b[39m=\u001b[39m shuffled_dataset\u001b[39m.\u001b[39mas_numpy_iterator()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/simple_regression.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m random_sample \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(iterator)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/simple_regression.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m X \u001b[39m=\u001b[39m random_sample[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/simple_regression.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m rn\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice([X,  X[:,::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1000\u001b[39m, replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:4691\u001b[0m, in \u001b[0;36mNumpyIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4688\u001b[0m     numpy\u001b[39m.\u001b[39msetflags(write\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   4689\u001b[0m   \u001b[39mreturn\u001b[39;00m numpy\n\u001b[0;32m-> 4691\u001b[0m \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mmap_structure(to_numpy, \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator))\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:811\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    809\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_internal()\n\u001b[1;32m    810\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[0;32m--> 811\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Read Data\n",
    "import shap\n",
    "_dataset = data_reader(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_2col_test.csv\", batch_size=10000)\n",
    "shuffled_dataset = _dataset.shuffle(5000)\n",
    "iterator = shuffled_dataset.as_numpy_iterator()\n",
    "random_sample = next(iterator)\n",
    "X = random_sample[0]\n",
    "\n",
    "rn=np.random.choice([X,  X[:,::-1,::-1]][0].shape[0], 1000, replace=False)\n",
    "explainer = shap.DeepExplainer((model.inputs, model.layers[-1].output), X[rn])\n",
    "explainer.shap_values(X[0:10], ranked_outputs=1)\n",
    "\n",
    "#shap_values_top, indexes = explainer.shap_values(X, ranked_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b5378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data\n",
    "import shap\n",
    "_dataset = data_reader(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_2col_test.csv\", batch_size=10000)\n",
    "shuffled_dataset = _dataset.shuffle(5000)\n",
    "iterator = shuffled_dataset.as_numpy_iterator()\n",
    "random_sample = next(iterator)\n",
    "X = random_sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4d9541",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "rn=np.random.choice([X,  X[:,::-1,::-1]][0].shape[0], 1000, replace=False)\n",
    "X[rn].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn=np.random.choice([X,  X[:,::-1,::-1]][0].shape[0], 200, replace=False)\n",
    "rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc42a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_to_dna_sequence(one_hot_sequence, vocab):\n",
    "    \"\"\"\n",
    "    Convert a one-hot-encoded DNA sequence back to a DNA sequence using the provided vocabulary.\n",
    "    Args:\n",
    "    - one_hot_sequence: A tensor containing the one-hot-encoded DNA sequence.\n",
    "    - vocab: A list of vocabulary characters (e.g., [\"A\", \"G\", \"C\", \"T\"]).\n",
    "\n",
    "    Returns:\n",
    "    - dna_sequence: A tensor containing the decoded DNA sequence.\n",
    "    \"\"\"\n",
    "    # Get the index of the maximum value along the one-hot encoding axis\n",
    "    decoded_indices = tf.argmax(one_hot_sequence, axis=-1)\n",
    "\n",
    "    # Use the indices to map back to DNA characters\n",
    "    dna_sequence = tf.gather(vocab, decoded_indices)\n",
    "\n",
    "    return dna_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53e27517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_3E</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.189065</td>\n",
       "      <td>AGGACCGGATCAACTAAAAAAATTTTCCACGCTTTCTGCTTAGCAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.075877</td>\n",
       "      <td>AGGACCGGATCAACTAAAAAAGTGGGGCTTATAGTGTCCCTACCAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.016712</td>\n",
       "      <td>AGGACCGGATCAACTAAAAAGAGCCCGAGTAGTGTTCGTCTGTCGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083258</td>\n",
       "      <td>AGGACCGGATCAACTAAAAATAACCGACCGCCAGGTGATCTTCCCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.010862</td>\n",
       "      <td>AGGACCGGATCAACTAAAAATACCAGCTCAACGCATCAGGCCCCGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8473</th>\n",
       "      <td>0.232320</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTCTCCTCCGATACTGTACGTTACTCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474</th>\n",
       "      <td>-0.034994</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTGATGCGTAAAGTCTAGAACGCTGGAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8475</th>\n",
       "      <td>-0.003203</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTGCTAACATGCCAAATGCGGTAACAGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>0.356185</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTTATTTCAGTTTGGTATTCCGAACGAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8477</th>\n",
       "      <td>0.474446</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTTCAAAACTAGCGCTATGCCGTACTAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8478 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      State_3E                                                seq\n",
       "0     0.189065  AGGACCGGATCAACTAAAAAAATTTTCCACGCTTTCTGCTTAGCAC...\n",
       "1     0.075877  AGGACCGGATCAACTAAAAAAGTGGGGCTTATAGTGTCCCTACCAG...\n",
       "2    -0.016712  AGGACCGGATCAACTAAAAAGAGCCCGAGTAGTGTTCGTCTGTCGA...\n",
       "3     0.083258  AGGACCGGATCAACTAAAAATAACCGACCGCCAGGTGATCTTCCCT...\n",
       "4    -0.010862  AGGACCGGATCAACTAAAAATACCAGCTCAACGCATCAGGCCCCGA...\n",
       "...        ...                                                ...\n",
       "8473  0.232320  AGGACCGGATCAACTTTTTTCTCCTCCGATACTGTACGTTACTCTT...\n",
       "8474 -0.034994  AGGACCGGATCAACTTTTTTGATGCGTAAAGTCTAGAACGCTGGAA...\n",
       "8475 -0.003203  AGGACCGGATCAACTTTTTTGCTAACATGCCAAATGCGGTAACAGA...\n",
       "8476  0.356185  AGGACCGGATCAACTTTTTTTATTTCAGTTTGGTATTCCGAACGAC...\n",
       "8477  0.474446  AGGACCGGATCAACTTTTTTTCAAAACTAGCGCTATGCCGTACTAC...\n",
       "\n",
       "[8478 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a6395a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# Split the data in three partitions\n",
    "file=\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3.csv\"\n",
    "whole_data = pd.read_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3.csv\")\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 2008)\n",
    "result = next(kf.split(whole_data), None)\n",
    "\n",
    "o=1\n",
    "for i in kf.split(whole_data):\n",
    "    train = whole_data.iloc[i[0]]\n",
    "    test =  whole_data.iloc[i[1]]\n",
    "    \n",
    "    train, validation = train_test_split(whole_data, test_size=0.10, random_state=42)\n",
    "    \n",
    "    train.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_train.csv\", index=False)\n",
    "    test.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_test.csv\", index=False)\n",
    "    validation.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_validation.csv\", index=False)\n",
    "    o+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "03d1457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [State_3E, seq, prediction]\n",
      "Index: []\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_165 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_132 (B  (None, 256, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_133 (B  (None, 249, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_166 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_134 (B  (None, 122, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_167 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_135 (B  (None, 121, 100)          400       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_168 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_169 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 5s 253ms/step - loss: 0.1173 - mse: 0.1173 - mae: 0.2780 - mape: 78076.1172 - val_loss: 0.0689 - val_mse: 0.0689 - val_mae: 0.2401 - val_mape: 35437.7969\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:05:37.442983: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6726460305429972793\n",
      "2023-10-16 16:05:37.443076: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 553158323905315772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 228ms/step - loss: 0.0612 - mse: 0.0612 - mae: 0.1971 - mape: 11188.1738 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.1085 - val_mape: 10966.0527\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.0383 - mse: 0.0383 - mae: 0.1532 - mape: 9272.3408 - val_loss: 0.0273 - val_mse: 0.0273 - val_mae: 0.1142 - val_mape: 5253.1997\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.1392 - mape: 2738.0203 - val_loss: 0.0250 - val_mse: 0.0250 - val_mae: 0.1076 - val_mape: 3408.8870\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0289 - mse: 0.0289 - mae: 0.1320 - mape: 14265.9707 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0971 - val_mape: 2736.1873\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 0.0241 - mse: 0.0241 - mae: 0.1201 - mape: 10216.8916 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0972 - val_mape: 4588.0132\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 2s 216ms/step - loss: 0.0205 - mse: 0.0205 - mae: 0.1114 - mape: 37930.9570 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.0975 - val_mape: 5061.7949\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.0182 - mse: 0.0182 - mae: 0.1050 - mape: 4746.7485 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.0977 - val_mape: 5312.4224\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.0165 - mse: 0.0165 - mae: 0.1003 - mape: 1077.7443 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0970 - val_mape: 3836.9277\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0946 - mape: 7381.6626 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0970 - val_mape: 4045.9788\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.0130 - mse: 0.0130 - mae: 0.0895 - mape: 13518.7344 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0971 - val_mape: 4197.3911\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0845 - mape: 17399.4375 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0969 - val_mape: 3497.8445\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 2s 216ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0781 - mape: 14163.8154 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0980 - val_mape: 5684.1997\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0730 - mape: 5805.7764 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0972 - val_mape: 4487.3301\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 2s 216ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0687 - mape: 10047.3184 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0971 - val_mape: 4355.4858\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0654 - mape: 10491.3760 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.0974 - val_mape: 4918.5156\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0621 - mape: 8405.4189 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0970 - val_mape: 3205.3113\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0613 - mape: 12262.1680 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0970 - val_mape: 3708.0791\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0588 - mape: 8836.6211 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0969 - val_mape: 3679.1013\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0570 - mape: 8863.0205 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0969 - val_mape: 3477.4519\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_170 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_136 (B  (None, 256, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_137 (B  (None, 249, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_171 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_138 (B  (None, 122, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_172 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_139 (B  (None, 121, 100)          400       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_173 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_34 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_174 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "      8/Unknown - 3s 108ms/step - loss: 0.1457 - mse: 0.1457 - mae: 0.3205 - mape: 6115.9741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:06:16.524906: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6726460305429972793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 5s 263ms/step - loss: 0.1457 - mse: 0.1457 - mae: 0.3205 - mape: 6115.9741 - val_loss: 0.0430 - val_mse: 0.0430 - val_mae: 0.1605 - val_mape: 13770.3867\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:06:17.558934: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6726460305429972793\n",
      "2023-10-16 16:06:17.559029: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 553158323905315772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0508 - mse: 0.0508 - mae: 0.1809 - mape: 5351.1328 - val_loss: 0.0410 - val_mse: 0.0410 - val_mae: 0.1549 - val_mape: 12906.8838\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 0.0440 - mse: 0.0440 - mae: 0.1637 - mape: 8331.1270 - val_loss: 0.0226 - val_mse: 0.0226 - val_mae: 0.1170 - val_mape: 13537.3564\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.0302 - mse: 0.0302 - mae: 0.1327 - mape: 14819.7207 - val_loss: 0.0244 - val_mse: 0.0244 - val_mae: 0.1243 - val_mape: 15397.9629\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 0.0265 - mse: 0.0265 - mae: 0.1252 - mape: 22770.1348 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.1024 - val_mape: 8526.3906\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.0217 - mse: 0.0217 - mae: 0.1135 - mape: 29116.3867 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0970 - val_mape: 2934.9158\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.0194 - mse: 0.0194 - mae: 0.1075 - mape: 6330.3198 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0972 - val_mape: 2482.5950\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.0183 - mse: 0.0183 - mae: 0.1055 - mape: 4765.7051 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0972 - val_mape: 2549.8291\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.0161 - mse: 0.0161 - mae: 0.0988 - mape: 4846.5488 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.0975 - val_mape: 2001.5393\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.0153 - mse: 0.0153 - mae: 0.0956 - mape: 1283.0291 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0976 - val_mape: 1772.7802\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0914 - mape: 2654.9973 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.0988 - val_mape: 695.9819\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0900 - mape: 4545.0454 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0976 - val_mape: 1795.1858\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0839 - mape: 23720.0273 - val_loss: 0.0210 - val_mse: 0.0210 - val_mae: 0.0980 - val_mape: 1422.6996\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.0109 - mse: 0.0109 - mae: 0.0815 - mape: 11989.3691 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.0974 - val_mape: 2098.9185\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0779 - mape: 3096.6863 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0969 - val_mape: 3675.9614\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0743 - mape: 7556.0527 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.0969 - val_mape: 3522.1306\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0712 - mape: 7051.0684 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.0975 - val_mape: 5027.3115\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0654 - mape: 2544.6853 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0984 - val_mape: 6082.2568\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0636 - mape: 10489.5205 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0986 - val_mape: 6240.8931\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0612 - mape: 2812.8794 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.1003 - val_mape: 7415.7329\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_175 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_140 (B  (None, 256, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_141 (B  (None, 249, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_176 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_142 (B  (None, 122, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_177 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_143 (B  (None, 121, 100)          400       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_178 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_35 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_179 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 4s 254ms/step - loss: 0.1515 - mse: 0.1515 - mae: 0.3171 - mape: 108372.2734 - val_loss: 0.1326 - val_mse: 0.1326 - val_mae: 0.3453 - val_mape: 50416.1641\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.0767 - mse: 0.0767 - mae: 0.2262 - mape: 37348.8438 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.1071 - val_mape: 10478.7578\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 0.0457 - mse: 0.0457 - mae: 0.1700 - mape: 38216.5820 - val_loss: 0.0370 - val_mse: 0.0370 - val_mae: 0.1434 - val_mape: 11017.8320\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.0372 - mse: 0.0372 - mae: 0.1510 - mape: 7488.8491 - val_loss: 0.0240 - val_mse: 0.0240 - val_mae: 0.1048 - val_mape: 2437.7681\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.0314 - mse: 0.0314 - mae: 0.1383 - mape: 1678.0432 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.1003 - val_mape: 7411.1978\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.0256 - mse: 0.0256 - mae: 0.1234 - mape: 3371.0671 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.1015 - val_mape: 8034.6885\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 0.0219 - mse: 0.0219 - mae: 0.1153 - mape: 14695.1963 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0993 - val_mape: 6750.9531\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0196 - mse: 0.0196 - mae: 0.1099 - mape: 1380.1046 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0984 - val_mape: 6035.1230\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.0179 - mse: 0.0179 - mae: 0.1045 - mape: 16214.7793 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0971 - val_mape: 4208.7539\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.0167 - mse: 0.0167 - mae: 0.1011 - mape: 20774.8828 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0970 - val_mape: 3220.5784\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.0154 - mse: 0.0154 - mae: 0.0970 - mape: 6275.0474 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0969 - val_mape: 3639.3755\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0907 - mape: 5832.5581 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.0976 - val_mape: 5146.1948\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0853 - mape: 3068.4536 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0988 - val_mape: 6362.5312\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0789 - mape: 1618.9952 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.0977 - val_mape: 5329.2207\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 2s 229ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0739 - mape: 2724.6448 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.1014 - val_mape: 7985.7617\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0699 - mape: 6204.8550 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.1003 - val_mape: 7419.0864\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0661 - mape: 8548.9775 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0986 - val_mape: 6198.5225\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0650 - mape: 7834.7871 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.1007 - val_mape: 7628.1450\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.0064 - mse: 0.0064 - mae: 0.0620 - mape: 1248.7524 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.1016 - val_mape: 8115.8271\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0603 - mape: 1889.7628 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.1005 - val_mape: 7491.8628\n",
      "9/9 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:07:32.181079: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6726460305429972793\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_180 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_144 (B  (None, 256, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_145 (B  (None, 249, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_181 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_146 (B  (None, 122, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_182 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_147 (B  (None, 121, 100)          400       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_183 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_36 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_184 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "      8/Unknown - 3s 108ms/step - loss: 0.1124 - mse: 0.1124 - mae: 0.2814 - mape: 59497.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:07:37.005051: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 553158323905315772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 5s 264ms/step - loss: 0.1124 - mse: 0.1124 - mae: 0.2814 - mape: 59497.4375 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1186 - val_mape: 13956.7666\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:07:38.040888: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6726460305429972793\n",
      "2023-10-16 16:07:38.040970: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 553158323905315772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 224ms/step - loss: 0.0494 - mse: 0.0494 - mae: 0.1766 - mape: 23962.1602 - val_loss: 0.0268 - val_mse: 0.0268 - val_mae: 0.1126 - val_mape: 4833.4370\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 2s 224ms/step - loss: 0.0371 - mse: 0.0371 - mae: 0.1498 - mape: 17208.3516 - val_loss: 0.0332 - val_mse: 0.0332 - val_mae: 0.1320 - val_mape: 9017.2266\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.1388 - mape: 3610.1614 - val_loss: 0.0261 - val_mse: 0.0261 - val_mae: 0.1108 - val_mape: 4334.5454\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 0.0285 - mse: 0.0285 - mae: 0.1313 - mape: 15606.0654 - val_loss: 0.0224 - val_mse: 0.0224 - val_mae: 0.1008 - val_mape: 754.4680\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0252 - mse: 0.0252 - mae: 0.1239 - mape: 12859.1377 - val_loss: 0.0224 - val_mse: 0.0224 - val_mae: 0.1007 - val_mape: 696.6161\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.0213 - mse: 0.0213 - mae: 0.1133 - mape: 4300.4546 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.0998 - val_mape: 168.6312\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 0.0193 - mse: 0.0193 - mae: 0.1089 - mape: 5307.5322 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.0992 - val_mape: 388.0712\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.0170 - mse: 0.0170 - mae: 0.1018 - mape: 5488.3354 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0978 - val_mape: 1583.6058\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.0150 - mse: 0.0150 - mae: 0.0954 - mape: 10210.6367 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0971 - val_mape: 2594.8420\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0900 - mape: 13379.3184 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0970 - val_mape: 3219.4329\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0862 - mape: 7590.3848 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0970 - val_mape: 3009.0706\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0813 - mape: 6721.3569 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0970 - val_mape: 3273.2312\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0764 - mape: 7776.8745 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.0974 - val_mape: 4832.0371\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0733 - mape: 3655.6689 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0971 - val_mape: 4321.8184\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0686 - mape: 882.0427 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0978 - val_mape: 5416.0327\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0664 - mape: 7976.3711 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0981 - val_mape: 5779.3242\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0634 - mape: 1130.4335 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0981 - val_mape: 5706.6040\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 2s 223ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0614 - mape: 16411.2207 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0985 - val_mape: 6159.9639\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0592 - mape: 15207.2363 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.1018 - val_mape: 8208.7129\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_185 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_148 (B  (None, 256, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_149 (B  (None, 249, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_186 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_150 (B  (None, 122, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_187 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_151 (B  (None, 121, 100)          400       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_188 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_189 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "      8/Unknown - 3s 105ms/step - loss: 0.1368 - mse: 0.1368 - mae: 0.3094 - mape: 6771.1895"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:08:17.017096: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6726460305429972793\n",
      "2023-10-16 16:08:17.017165: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 553158323905315772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 5s 254ms/step - loss: 0.1368 - mse: 0.1368 - mae: 0.3094 - mape: 6771.1895 - val_loss: 0.0400 - val_mse: 0.0400 - val_mae: 0.1740 - val_mape: 25053.4316\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 2s 194ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1702 - mape: 10081.4492 - val_loss: 0.0342 - val_mse: 0.0342 - val_mae: 0.1575 - val_mape: 22147.8066\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 0.0390 - mse: 0.0390 - mae: 0.1546 - mape: 26704.9746 - val_loss: 0.0250 - val_mse: 0.0250 - val_mae: 0.1075 - val_mape: 3366.3298\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 0.0293 - mse: 0.0293 - mae: 0.1335 - mape: 9726.6709 - val_loss: 0.0282 - val_mse: 0.0282 - val_mae: 0.1168 - val_mape: 5876.2065\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 0.0258 - mse: 0.0258 - mae: 0.1234 - mape: 20137.7715 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0970 - val_mape: 3114.4365\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 1s 180ms/step - loss: 0.0225 - mse: 0.0225 - mae: 0.1150 - mape: 2978.1367 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0985 - val_mape: 6117.9854\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 2s 195ms/step - loss: 0.0193 - mse: 0.0193 - mae: 0.1078 - mape: 13723.5479 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0971 - val_mape: 4361.5146\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.0175 - mse: 0.0175 - mae: 0.1028 - mape: 15277.7734 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0971 - val_mape: 2578.8149\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 0.0161 - mse: 0.0161 - mae: 0.0987 - mape: 15902.3428 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.0982 - val_mape: 1222.3568\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.0941 - mape: 9039.1641 - val_loss: 0.0214 - val_mse: 0.0214 - val_mae: 0.0986 - val_mape: 838.4299\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 0.0132 - mse: 0.0132 - mae: 0.0891 - mape: 15039.1992 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.0995 - val_mape: 188.1405\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 2s 202ms/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0866 - mape: 16873.6387 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1014 - val_mape: 1053.9248\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0821 - mape: 1377.3927 - val_loss: 0.0243 - val_mse: 0.0243 - val_mae: 0.1055 - val_mape: 2694.1292\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 2s 206ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0763 - mape: 10409.2617 - val_loss: 0.0248 - val_mse: 0.0248 - val_mae: 0.1071 - val_mape: 3234.1243\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0718 - mape: 3652.2253 - val_loss: 0.0258 - val_mse: 0.0258 - val_mae: 0.1097 - val_mape: 4023.7178\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0688 - mape: 8649.2578 - val_loss: 0.0261 - val_mse: 0.0261 - val_mae: 0.1106 - val_mape: 4301.8760\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0664 - mape: 14316.4160 - val_loss: 0.0273 - val_mse: 0.0273 - val_mae: 0.1142 - val_mape: 5254.2104\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0643 - mape: 12832.7803 - val_loss: 0.0286 - val_mse: 0.0286 - val_mae: 0.1180 - val_mape: 6153.2070\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 2s 197ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0617 - mape: 11098.1963 - val_loss: 0.0270 - val_mse: 0.0270 - val_mae: 0.1134 - val_mape: 5042.7690\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0594 - mape: 10607.5127 - val_loss: 0.0286 - val_mse: 0.0286 - val_mae: 0.1180 - val_mape: 6168.5122\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_190 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_152 (B  (None, 256, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_153 (B  (None, 249, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_191 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_154 (B  (None, 122, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_192 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_155 (B  (None, 121, 100)          400       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_193 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_38 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_194 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_116 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 5s 258ms/step - loss: 0.7951 - mse: 0.7951 - mae: 0.7803 - mape: 149913.3281 - val_loss: 0.2953 - val_mse: 0.2953 - val_mae: 0.5251 - val_mape: 62589.7773\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.1596 - mse: 0.1596 - mae: 0.3493 - mape: 12105.8076 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.1109 - val_mape: 11763.7090\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.0684 - mse: 0.0684 - mae: 0.2065 - mape: 4074.1304 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0970 - val_mape: 4076.7375\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 2s 226ms/step - loss: 0.0475 - mse: 0.0475 - mae: 0.1755 - mape: 7020.2480 - val_loss: 0.0536 - val_mse: 0.0536 - val_mae: 0.1884 - val_mape: 17895.0176\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0366 - mse: 0.0366 - mae: 0.1475 - mape: 6597.4590 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0988 - val_mape: 6364.2749\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 0.0291 - mse: 0.0291 - mae: 0.1332 - mape: 2750.9204 - val_loss: 0.0305 - val_mse: 0.0305 - val_mae: 0.1239 - val_mape: 7437.0059\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.0259 - mse: 0.0259 - mae: 0.1259 - mape: 7385.3857 - val_loss: 0.0272 - val_mse: 0.0272 - val_mae: 0.1139 - val_mape: 5171.0835\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 2s 227ms/step - loss: 0.0244 - mse: 0.0244 - mae: 0.1217 - mape: 15607.6592 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.0981 - val_mape: 1266.6973\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 0.0226 - mse: 0.0226 - mae: 0.1174 - mape: 7472.0703 - val_loss: 0.0273 - val_mse: 0.0273 - val_mae: 0.1142 - val_mape: 5248.8833\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 2s 222ms/step - loss: 0.0214 - mse: 0.0214 - mae: 0.1144 - mape: 4578.1616 - val_loss: 0.0254 - val_mse: 0.0254 - val_mae: 0.1085 - val_mape: 3679.7224\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 2s 189ms/step - loss: 0.0207 - mse: 0.0207 - mae: 0.1130 - mape: 5398.0698 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1022 - val_mape: 1417.5104\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 0.0189 - mse: 0.0189 - mae: 0.1075 - mape: 15881.0635 - val_loss: 0.0232 - val_mse: 0.0232 - val_mae: 0.1026 - val_mape: 1605.2859\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 2s 221ms/step - loss: 0.0183 - mse: 0.0183 - mae: 0.1059 - mape: 24644.4746 - val_loss: 0.0250 - val_mse: 0.0250 - val_mae: 0.1074 - val_mape: 3344.4021\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 0.0175 - mse: 0.0175 - mae: 0.1036 - mape: 10391.0322 - val_loss: 0.0234 - val_mse: 0.0234 - val_mae: 0.1031 - val_mape: 1812.2013\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 2s 225ms/step - loss: 0.0167 - mse: 0.0167 - mae: 0.1006 - mape: 10663.1279 - val_loss: 0.0235 - val_mse: 0.0235 - val_mae: 0.1034 - val_mape: 1934.4044\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 0.0161 - mse: 0.0161 - mae: 0.0995 - mape: 6142.5796 - val_loss: 0.0233 - val_mse: 0.0233 - val_mae: 0.1030 - val_mape: 1759.0558\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 2s 208ms/step - loss: 0.0154 - mse: 0.0154 - mae: 0.0964 - mape: 11466.7588 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1041 - val_mape: 2174.4395\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 2s 209ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.0950 - mape: 9297.8662 - val_loss: 0.0242 - val_mse: 0.0242 - val_mae: 0.1055 - val_mape: 2684.5029\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.0142 - mse: 0.0142 - mae: 0.0937 - mape: 25001.1875 - val_loss: 0.0239 - val_mse: 0.0239 - val_mae: 0.1045 - val_mape: 2344.3650\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0909 - mape: 2921.5952 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1040 - val_mape: 2143.4736\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:09:30.161307: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6726460305429972793\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_195 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_156 (B  (None, 256, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_157 (B  (None, 249, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_196 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_158 (B  (None, 122, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_197 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_159 (B  (None, 121, 100)          400       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_198 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_199 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 6s 240ms/step - loss: 0.1469 - mse: 0.1469 - mae: 0.3119 - mape: 88590.1641 - val_loss: 0.0933 - val_mse: 0.0933 - val_mae: 0.2847 - val_mape: 41926.9141\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 0.0724 - mse: 0.0724 - mae: 0.2213 - mape: 36953.5000 - val_loss: 0.0238 - val_mse: 0.0238 - val_mae: 0.1043 - val_mape: 2261.8320\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 0.0395 - mse: 0.0395 - mae: 0.1575 - mape: 6388.2651 - val_loss: 0.0358 - val_mse: 0.0358 - val_mae: 0.1397 - val_mape: 10395.9238\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 0.0357 - mse: 0.0357 - mae: 0.1465 - mape: 3394.2263 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0992 - val_mape: 6681.7866\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 0.0272 - mse: 0.0272 - mae: 0.1263 - mape: 10552.6582 - val_loss: 0.0214 - val_mse: 0.0214 - val_mae: 0.1112 - val_mape: 11843.4053\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 0.0224 - mse: 0.0224 - mae: 0.1156 - mape: 2845.0808 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0989 - val_mape: 6448.9180\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 0.0193 - mse: 0.0193 - mae: 0.1078 - mape: 10428.4951 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0971 - val_mape: 2730.0706\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.0176 - mse: 0.0176 - mae: 0.1027 - mape: 3147.0264 - val_loss: 0.0222 - val_mse: 0.0222 - val_mae: 0.1002 - val_mape: 413.4006\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 2s 216ms/step - loss: 0.0161 - mse: 0.0161 - mae: 0.0981 - mape: 9879.9561 - val_loss: 0.0232 - val_mse: 0.0232 - val_mae: 0.1027 - val_mape: 1615.6125\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 2s 192ms/step - loss: 0.0154 - mse: 0.0154 - mae: 0.0964 - mape: 14846.5576 - val_loss: 0.0236 - val_mse: 0.0236 - val_mae: 0.1037 - val_mape: 2058.3335\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0928 - mape: 10396.5322 - val_loss: 0.0243 - val_mse: 0.0243 - val_mae: 0.1056 - val_mape: 2722.4058\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 0.0133 - mse: 0.0133 - mae: 0.0897 - mape: 8332.4121 - val_loss: 0.0235 - val_mse: 0.0235 - val_mae: 0.1033 - val_mape: 1889.6318\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0862 - mape: 11356.4844 - val_loss: 0.0246 - val_mse: 0.0246 - val_mae: 0.1064 - val_mape: 2997.7178\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0832 - mape: 5215.1914 - val_loss: 0.0243 - val_mse: 0.0243 - val_mae: 0.1057 - val_mape: 2774.1099\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0793 - mape: 9497.4863 - val_loss: 0.0245 - val_mse: 0.0245 - val_mae: 0.1061 - val_mape: 2892.5073\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0769 - mape: 12900.5059 - val_loss: 0.0252 - val_mse: 0.0252 - val_mae: 0.1081 - val_mape: 3552.0220\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0750 - mape: 9003.1006 - val_loss: 0.0245 - val_mse: 0.0245 - val_mae: 0.1061 - val_mape: 2917.2908\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 2s 218ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0716 - mape: 11174.8789 - val_loss: 0.0243 - val_mse: 0.0243 - val_mae: 0.1055 - val_mape: 2694.4097\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0693 - mape: 7730.2114 - val_loss: 0.0243 - val_mse: 0.0243 - val_mae: 0.1057 - val_mape: 2753.8069\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0694 - mape: 17092.9785 - val_loss: 0.0231 - val_mse: 0.0231 - val_mae: 0.1025 - val_mape: 1555.1619\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:10:10.700009: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6726460305429972793\n",
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_200 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_160 (B  (None, 256, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_161 (B  (None, 249, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_201 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_162 (B  (None, 122, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_202 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_163 (B  (None, 121, 100)          400       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_203 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_120 (Dense)           (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_204 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 4s 243ms/step - loss: 0.7594 - mse: 0.7594 - mae: 0.7615 - mape: 126502.0312 - val_loss: 0.2471 - val_mse: 0.2471 - val_mae: 0.4770 - val_mape: 56284.9961\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-16 16:10:16.502477: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6726460305429972793\n",
      "2023-10-16 16:10:16.502548: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 553158323905315772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 210ms/step - loss: 0.1475 - mse: 0.1475 - mae: 0.3351 - mape: 14374.2295 - val_loss: 0.0342 - val_mse: 0.0342 - val_mae: 0.1577 - val_mape: 22184.3672\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 0.0607 - mse: 0.0607 - mae: 0.1924 - mape: 19806.7461 - val_loss: 0.0259 - val_mse: 0.0259 - val_mae: 0.1303 - val_mape: 16759.0566\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 0.0416 - mse: 0.0416 - mae: 0.1628 - mape: 31514.9863 - val_loss: 0.0344 - val_mse: 0.0344 - val_mae: 0.1355 - val_mape: 9651.3604\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 2s 200ms/step - loss: 0.0335 - mse: 0.0335 - mae: 0.1419 - mape: 4609.0493 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.1070 - val_mape: 10446.7266\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 2s 204ms/step - loss: 0.0267 - mse: 0.0267 - mae: 0.1264 - mape: 22599.0488 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.0982 - val_mape: 1238.0005\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 2s 211ms/step - loss: 0.0247 - mse: 0.0247 - mae: 0.1228 - mape: 22079.4355 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.1009 - val_mape: 791.3422\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 0.0233 - mse: 0.0233 - mae: 0.1183 - mape: 14794.6738 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.0976 - val_mape: 5174.8384\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 2s 220ms/step - loss: 0.0214 - mse: 0.0214 - mae: 0.1135 - mape: 5476.6172 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0976 - val_mape: 1810.1282\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 0.0206 - mse: 0.0206 - mae: 0.1119 - mape: 2777.5430 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.0993 - val_mape: 325.3053\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 2s 206ms/step - loss: 0.0202 - mse: 0.0202 - mae: 0.1100 - mape: 28623.6406 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0978 - val_mape: 1579.7888\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 2s 215ms/step - loss: 0.0184 - mse: 0.0184 - mae: 0.1058 - mape: 9231.4619 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0970 - val_mape: 2828.8525\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 2s 199ms/step - loss: 0.0177 - mse: 0.0177 - mae: 0.1033 - mape: 11889.4814 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.0982 - val_mape: 1198.8838\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 2s 205ms/step - loss: 0.0166 - mse: 0.0166 - mae: 0.1009 - mape: 10415.9834 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.0993 - val_mape: 336.4246\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 0.0161 - mse: 0.0161 - mae: 0.0988 - mape: 6395.7393 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.0984 - val_mape: 1006.4114\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 2s 216ms/step - loss: 0.0153 - mse: 0.0153 - mae: 0.0967 - mape: 4216.9683 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0978 - val_mape: 1640.6215\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0939 - mape: 14074.0029 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.0984 - val_mape: 1036.2131\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.0139 - mse: 0.0139 - mae: 0.0921 - mape: 21273.0996 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.0988 - val_mape: 674.8328\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.0130 - mse: 0.0130 - mae: 0.0891 - mape: 12422.2734 - val_loss: 0.0216 - val_mse: 0.0216 - val_mae: 0.0990 - val_mape: 582.0970\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 2s 206ms/step - loss: 0.0125 - mse: 0.0125 - mae: 0.0872 - mape: 8540.6465 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.0992 - val_mape: 422.3874\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_205 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_164 (B  (None, 256, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_165 (B  (None, 249, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_206 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_166 (B  (None, 122, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_207 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_167 (B  (None, 121, 100)          400       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_208 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_41 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_209 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_124 (Dense)           (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 5s 225ms/step - loss: 0.0954 - mse: 0.0954 - mae: 0.2521 - mape: 63190.4180 - val_loss: 0.0704 - val_mse: 0.0704 - val_mae: 0.2432 - val_mape: 35896.8047\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 0.0487 - mse: 0.0487 - mae: 0.1728 - mape: 46952.6992 - val_loss: 0.0253 - val_mse: 0.0253 - val_mae: 0.1279 - val_mape: 16229.2744\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 0.0361 - mse: 0.0361 - mae: 0.1470 - mape: 14211.4297 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.0970 - val_mape: 3976.8440\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 0.0287 - mse: 0.0287 - mae: 0.1317 - mape: 5312.8159 - val_loss: 0.0234 - val_mse: 0.0234 - val_mae: 0.1033 - val_mape: 1864.6791\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 0.0255 - mse: 0.0255 - mae: 0.1244 - mape: 5303.1108 - val_loss: 0.0245 - val_mse: 0.0245 - val_mae: 0.1063 - val_mape: 2962.1345\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 2s 209ms/step - loss: 0.0221 - mse: 0.0221 - mae: 0.1160 - mape: 14600.5537 - val_loss: 0.0234 - val_mse: 0.0234 - val_mae: 0.1031 - val_mape: 1808.8972\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 2s 212ms/step - loss: 0.0191 - mse: 0.0191 - mae: 0.1067 - mape: 7644.3374 - val_loss: 0.0236 - val_mse: 0.0236 - val_mae: 0.1038 - val_mape: 2092.1074\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.0175 - mse: 0.0175 - mae: 0.1035 - mape: 6761.1792 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1014 - val_mape: 1045.7867\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0952 - mape: 6780.1763 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1022 - val_mape: 1415.4166\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0938 - mape: 12391.6611 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1000 - val_mape: 274.8053\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0870 - mape: 14446.4893 - val_loss: 0.0222 - val_mse: 0.0222 - val_mae: 0.1002 - val_mape: 406.4181\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 2s 210ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0817 - mape: 15581.4658 - val_loss: 0.0222 - val_mse: 0.0222 - val_mae: 0.1004 - val_mape: 510.7312\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 2s 214ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0789 - mape: 4493.4307 - val_loss: 0.0216 - val_mse: 0.0216 - val_mae: 0.0990 - val_mape: 557.8113\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 2s 207ms/step - loss: 0.0090 - mse: 0.0090 - mae: 0.0744 - mape: 4078.0203 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.0994 - val_mape: 265.3354\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 2s 217ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0705 - mape: 12714.6885 - val_loss: 0.0216 - val_mse: 0.0216 - val_mae: 0.0991 - val_mape: 489.3680\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 2s 213ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0674 - mape: 9003.2119 - val_loss: 0.0228 - val_mse: 0.0228 - val_mae: 0.1017 - val_mape: 1178.1276\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 2s 201ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0676 - mape: 2165.5981 - val_loss: 0.0233 - val_mse: 0.0233 - val_mae: 0.1030 - val_mape: 1772.6906\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 2s 196ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0660 - mape: 2092.6631 - val_loss: 0.0272 - val_mse: 0.0272 - val_mae: 0.1137 - val_mape: 5130.0806\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 2s 219ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0734 - mape: 8660.4580 - val_loss: 0.0342 - val_mse: 0.0342 - val_mae: 0.1350 - val_mape: 9561.4141\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 2s 203ms/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0829 - mape: 23720.4902 - val_loss: 0.0410 - val_mse: 0.0410 - val_mae: 0.1548 - val_mape: 12890.8809\n",
      "9/9 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n"
     ]
    }
   ],
   "source": [
    "df_test_overall  = pd.DataFrame(columns=['State_3E', \"seq\", \"prediction\"])\n",
    "print(df_test_overall)\n",
    "corr_list = []\n",
    "\n",
    "for i in range(1,10):\n",
    "    \n",
    "    input_path_train = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_train.csv\"\n",
    "    input_path_valid = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_validation.csv\"\n",
    "    input_path_test = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_test.csv\"\n",
    "    df_test = pd.read_csv(input_path_test)\n",
    "\n",
    "    # Get first item of the dataset to get the shape of the input data\n",
    "    for element in data_reader(file):\n",
    "        input_shape = element[0].shape\n",
    "\n",
    "    inputs = Input(shape=(input_shape[1],input_shape[2]), name=\"inputs\")\n",
    "    layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "    predictions = Dense(1, activation='linear')(layer)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "                )\n",
    "\n",
    "    history=model.fit(data_reader(input_path_train, batch_size=1024),\n",
    "                            epochs=20,\n",
    "                            validation_data=data_reader(file,batch_size=100),\n",
    "                            callbacks=None,\n",
    "                            verbose=1)\n",
    "\n",
    "    predicted = model.predict(data_reader(input_path_test,\n",
    "                                                batch_size=100))\n",
    "\n",
    "    test_data = data_reader(input_path_test,batch_size=100)\n",
    "    test_tensor = X = np.empty(shape=[0,1])\n",
    "    for batch in test_data:\n",
    "        test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "    df_test[\"prediction\"] = predicted\n",
    "    df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n",
    "    \n",
    "    def pearson_correlation(x, y):\n",
    "        n = len(x)\n",
    "        # Calculate the mean of x and y\n",
    "        mean_x = sum(x) / n\n",
    "        mean_y = sum(y) / n\n",
    "        \n",
    "        # Calculate the numerator and denominators of the correlation coefficient\n",
    "        numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "        denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "        denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "        \n",
    "        # Calculate the correlation coefficient\n",
    "        correlation = numerator / (denominator_x * denominator_y)\n",
    "        return correlation\n",
    "        \n",
    "    corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)\n",
    "    corr_list.append(corr_coefficient)\n",
    "\n",
    "df_test_overall.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/LibA_wide_pivot_state3_test_predicted_cv10fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7951a63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_3E</th>\n",
       "      <th>seq</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007714</td>\n",
       "      <td>AGGACCGGATCAACTAAACAACTCAAACAAGGGCTAATATAACCCA...</td>\n",
       "      <td>0.026140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.137953</td>\n",
       "      <td>AGGACCGGATCAACTAAACACTAGTCATACTTAAAAATTGCAAGGA...</td>\n",
       "      <td>0.026140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.048706</td>\n",
       "      <td>AGGACCGGATCAACTAAACAGGTTCTGACGTATGCTCCTCTATGGA...</td>\n",
       "      <td>0.026140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052804</td>\n",
       "      <td>AGGACCGGATCAACTAAACCCGAGCCTGCCTAGCCCTAGCTTCTCT...</td>\n",
       "      <td>0.026140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.213652</td>\n",
       "      <td>AGGACCGGATCAACTAAACGGAGCAGAGTTAGTGTCAGGTCAAAAA...</td>\n",
       "      <td>0.026140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7626</th>\n",
       "      <td>-0.069795</td>\n",
       "      <td>AGGACCGGATCAACTTTTGTCTTACATAGCTGGAACGACGAACGCT...</td>\n",
       "      <td>-0.098052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7627</th>\n",
       "      <td>-0.027438</td>\n",
       "      <td>AGGACCGGATCAACTTTTGTGGCTGACTCTATATTATCGAACCCCC...</td>\n",
       "      <td>-0.098050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7628</th>\n",
       "      <td>0.209585</td>\n",
       "      <td>AGGACCGGATCAACTTTTTCAGTGAAAGATCACCGCGGGATCTCAC...</td>\n",
       "      <td>-0.098048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7629</th>\n",
       "      <td>-0.153473</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTAGCTTCGGAATGGATAAAACGAGCAG...</td>\n",
       "      <td>-0.098052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7630</th>\n",
       "      <td>-0.060873</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTAGTAAAACTCTTAAACAGTGATTACA...</td>\n",
       "      <td>-0.098051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7631 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      State_3E                                                seq  prediction\n",
       "0    -0.007714  AGGACCGGATCAACTAAACAACTCAAACAAGGGCTAATATAACCCA...    0.026140\n",
       "1     0.137953  AGGACCGGATCAACTAAACACTAGTCATACTTAAAAATTGCAAGGA...    0.026140\n",
       "2    -0.048706  AGGACCGGATCAACTAAACAGGTTCTGACGTATGCTCCTCTATGGA...    0.026140\n",
       "3    -0.052804  AGGACCGGATCAACTAAACCCGAGCCTGCCTAGCCCTAGCTTCTCT...    0.026140\n",
       "4     0.213652  AGGACCGGATCAACTAAACGGAGCAGAGTTAGTGTCAGGTCAAAAA...    0.026140\n",
       "...        ...                                                ...         ...\n",
       "7626 -0.069795  AGGACCGGATCAACTTTTGTCTTACATAGCTGGAACGACGAACGCT...   -0.098052\n",
       "7627 -0.027438  AGGACCGGATCAACTTTTGTGGCTGACTCTATATTATCGAACCCCC...   -0.098050\n",
       "7628  0.209585  AGGACCGGATCAACTTTTTCAGTGAAAGATCACCGCGGGATCTCAC...   -0.098048\n",
       "7629 -0.153473  AGGACCGGATCAACTTTTTTAGCTTCGGAATGGATAAAACGAGCAG...   -0.098052\n",
       "7630 -0.060873  AGGACCGGATCAACTTTTTTAGTAAAACTCTTAAACAGTGATTACA...   -0.098051\n",
       "\n",
       "[7631 rows x 3 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_overall.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/LibA_wide_pivot_state3_test_predicted_cv10fold.csv\", index=False)\n",
    "df_test_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3096cd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5986894757825919,\n",
       " 0.5827273730261453,\n",
       " 0.6064971019630407,\n",
       " 0.6537739882082283,\n",
       " 0.6465771167565411,\n",
       " 0.5416654948282249,\n",
       " 0.6103707614242305,\n",
       " 0.49440679500910495,\n",
       " 0.6672157842296925]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
