{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c1f9e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 262, 4)\n",
      "(78, 7)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import getopt\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Normalization, Masking, Input, Lambda, concatenate, Bidirectional, Dense, Dropout, Flatten, Conv1D,BatchNormalization,  MaxPooling1D, Bidirectional, GRU, TimeDistributed\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n",
    "vocab = [\"A\", \"G\", \"C\", \"T\"]\n",
    "indices = tf.range(len(vocab), dtype = tf.int64)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab,indices)\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, 1)\n",
    "record_defaults = [\n",
    "    tf.constant([''], dtype=tf.string),\n",
    "    tf.constant([''], dtype=tf.string),\n",
    "    tf.constant([''], dtype=tf.string),\n",
    "    tf.constant([''], dtype=tf.string),  \n",
    "    tf.constant([''], dtype=tf.string),\n",
    "    tf.constant([''], dtype=tf.string),\n",
    "    tf.constant([''], dtype=tf.string),  \n",
    "    tf.constant([''], dtype=tf.string),\n",
    "]\n",
    "\n",
    "# Nadav dataset\n",
    "\n",
    "def data_reader(file, batch_size=100, n_parse_threads = 4):\n",
    "    dataset = tf.data.TextLineDataset(file).skip(1)\n",
    "    dataset=dataset.map(preprocess, num_parallel_calls = n_parse_threads)\n",
    "    return dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "def preprocess(record):\n",
    "    fields = tf.io.decode_csv(record, record_defaults=record_defaults)\n",
    "    chars = tf.strings.bytes_split(fields[0])\n",
    "    chars_indeces = table.lookup(chars)\n",
    "    X = tf.one_hot(chars_indeces, depth = len(vocab))\n",
    "    Y = tf.stack(fields[1:])\n",
    "    Y= tf.where(tf.equal(Y,  \"NA\"), [\"-1\"], Y)\n",
    "    Y = tf.strings.to_number(Y, tf.float32)\n",
    "    return X,Y\n",
    "\n",
    "# Get first item of the dataset to get the shape of the input data\n",
    "for element in data_reader(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot.csv\"):\n",
    "    input_shape = element[0].shape\n",
    "    output_shape = element[1].shape\n",
    "\n",
    "print(input_shape)\n",
    "print(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be0250f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv1\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (4, 262)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/multihead_regression.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/multihead_regression.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m inputs \u001b[39m=\u001b[39m Input(input_shape[\u001b[39m1\u001b[39m],input_shape[\u001b[39m2\u001b[39m], name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minputs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/multihead_regression.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#layer = Masking(mask_value=-1.)(inputs)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/multihead_regression.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m layer \u001b[39m=\u001b[39m Conv1D(\u001b[39m250\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m7\u001b[39;49m, strides\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mconv1\u001b[39;49m\u001b[39m\"\u001b[39;49m)(inputs)  \u001b[39m# 250 7 relu\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/multihead_regression.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m layer \u001b[39m=\u001b[39m Dropout(\u001b[39m0.3\u001b[39m)(layer)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/multihead_regression.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m layer \u001b[39m=\u001b[39m BatchNormalization()(layer)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/keras/src/engine/input_spec.py:253\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    251\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[1;32m    252\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ndim \u001b[39m<\u001b[39m spec\u001b[39m.\u001b[39mmin_ndim:\n\u001b[0;32m--> 253\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    254\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    255\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected min_ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mmin_ndim\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfound ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m         )\n\u001b[1;32m    260\u001b[0m \u001b[39m# Check dtype.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"conv1\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (4, 262)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "inputs = Input(input_shape[1],input_shape[2], name=\"inputs\")\n",
    "#layer = Masking(mask_value=-1.)(inputs)\n",
    "layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "layer = Dropout(0.3)(layer)\n",
    "layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "predictions = Dense(1, activation='linear')(layer)\n",
    "\n",
    "# Create trainable variables for mean and standard deviation\n",
    "initial_mean = tf.constant(0.0, dtype=tf.float32)\n",
    "initial_stddev = tf.constant(1.0, dtype=tf.float32)\n",
    "mean_initializer = Constant(initial_mean)\n",
    "variance_initializer = Constant(initial_stddev)\n",
    "\n",
    "norm_prediction = Normalization(axis=-1, \n",
    "                              mean_initializer=mean_initializer, \n",
    "                              variance_initializer=variance_initializer)(predictions)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=inputs, outputs=norm_prediction)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"mean_squared_error\",\n",
    "              metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "              )\n",
    "\n",
    "histories = {}\n",
    "histories=model.fit(data_reader('/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_2col_train.csv',batch_size=100),\n",
    "                        epochs=30,\n",
    "                        validation_data=data_reader('/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_2col_validation.csv',batch_size=100),\n",
    "                        callbacks=None,\n",
    "                        verbose=2)\n",
    "\n",
    "predicted = model.predict(data_reader('/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_2col_test.csv',\n",
    "                                            batch_size=100))\n",
    "\n",
    "test_data = data_reader('/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ_2col_test.csv',batch_size=100)\n",
    "test_tensor = X = np.empty(shape=[0,1])\n",
    "for batch in test_data:\n",
    "    test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "import math\n",
    "def pearson_correlation(x, y):\n",
    "    n = len(x)\n",
    "    # Calculate the mean of x and y\n",
    "    mean_x = sum(x) / n\n",
    "    mean_y = sum(y) / n\n",
    "    \n",
    "    # Calculate the numerator and denominators of the correlation coefficient\n",
    "    numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "    denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "    denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "    \n",
    "    # Calculate the correlation coefficient\n",
    "    correlation = numerator / (denominator_x * denominator_y)\n",
    "    return correlation\n",
    "    \n",
    "corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "histories = {}\n",
    "for i in range(10):\n",
    "    ct=\"EoBaso\"\n",
    "    print(\"Fold %02d in %s\" % (i+1,ct))\n",
    "    histories[ct]=model.fit(data_reader(\"/home/felix/cluster/lvelten/Analysis/SCG4SYN/LibA_HSC/analysis/complete_run1_5cellstates/005_deep/data/%s/train%02d.csv\" % (ct, i+1),batch_size=32),\n",
    "                            epochs=30,\n",
    "                            validation_data=data_reader(\"/home/felix/cluster/lvelten/Analysis/SCG4SYN/LibA_HSC/analysis/complete_run1_5cellstates/005_deep/data/%s/test%02d.csv\" % (ct,i+1),batch_size=32),\n",
    "                            callbacks=None,\n",
    "                            verbose=2)\n",
    "    predicted = model.predict(data_reader(\"/home/felix/cluster/lvelten/Analysis/SCG4SYN/LibA_HSC/analysis/complete_run1_5cellstates/005_deep/data/%s/valid%02d.csv\" % (ct, i+1),\n",
    "                                              batch_size=100))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b903c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plots(history):\n",
    "        plt.plot(history.history[\"pearson_r\"])\n",
    "        plt.plot(history.history[\"val_pearson_r\"])\n",
    "    else :\n",
    "        plt.plot(history.history[metric[4:]])\n",
    "        plt.plot(history.history[metric])\n",
    "    plt.title('model metric')\n",
    "    plt.ylabel(metric[4:])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(foldername + 'metric.png')\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(foldername + 'loss.png')\n",
    "    plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
