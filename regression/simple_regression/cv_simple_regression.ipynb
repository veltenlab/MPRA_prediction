{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ae6861",
   "metadata": {},
   "source": [
    "# MPRA regression with K-fold cross validation\n",
    "\n",
    "### Environment \n",
    "The next chunk contains the commands necessary to install the environment required to run this jupyter notebook\n",
    "Skip this chunk if the installation was previously done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c1f9e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: A conda environment already exists at '/home/felix/anaconda3/envs/tf_MPRA'\n",
      "Remove existing environment (y/[n])? Invalid choice: conda activate tf_mpra\n",
      "WARNING: A conda environment already exists at '/home/felix/anaconda3/envs/tf_MPRA'\n",
      "Remove existing environment (y/[n])? Invalid choice: pip install tensorflow[and-cuda]\n",
      "WARNING: A conda environment already exists at '/home/felix/anaconda3/envs/tf_MPRA'\n",
      "Remove existing environment (y/[n])? Invalid choice: conda install -c anaconda ipykernel\n",
      "WARNING: A conda environment already exists at '/home/felix/anaconda3/envs/tf_MPRA'\n",
      "Remove existing environment (y/[n])? Invalid choice: conda install -c anaconda pandas\n",
      "WARNING: A conda environment already exists at '/home/felix/anaconda3/envs/tf_MPRA'\n",
      "Remove existing environment (y/[n])? Invalid choice: conda install -c anaconda numpy\n",
      "WARNING: A conda environment already exists at '/home/felix/anaconda3/envs/tf_MPRA'\n",
      "Remove existing environment (y/[n])? Invalid choice: conda install -c anaconda scikit-learn\n",
      "WARNING: A conda environment already exists at '/home/felix/anaconda3/envs/tf_MPRA'\n",
      "Remove existing environment (y/[n])? Invalid choice: conda install -c conda-forge matplotlib\n",
      "WARNING: A conda environment already exists at '/home/felix/anaconda3/envs/tf_MPRA'\n",
      "Remove existing environment (y/[n])? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaSystemExit: Exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "conda create --name tf_MPRA python=3.9.7\n",
    "conda activate tf_MPRA\n",
    "pip install tensorflow[and-cuda]\n",
    "conda install -c anaconda ipykernel \n",
    "conda install -c anaconda pandas\n",
    "conda install -c anaconda numpy\n",
    "conda install -c anaconda scikit-learn \n",
    "conda install -c conda-forge matplotlib\n",
    "\n",
    "# After installation if you are using VSCODE to run the notebook you have to close it and re-open\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a1d3c9",
   "metadata": {},
   "source": [
    "### Library imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff43395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:46:44.442286: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-13 12:46:44.577446: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-13 12:46:44.577487: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-13 12:46:44.578091: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-13 12:46:44.626510: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import getopt\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Layer, Lambda, concatenate, Bidirectional, Dense, Dropout, Flatten, Conv1D,BatchNormalization,  MaxPooling1D, Bidirectional, GRU, TimeDistributed\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.initializers import Constant\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b63fd8",
   "metadata": {},
   "source": [
    "### Input ingestion\n",
    "\n",
    "Here we define the methods to read and ingest data and we initialize the random seed.\n",
    "\n",
    "Since we are processing the entire sequence the vocabulary is comprised of upper case nucleotides\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368fda03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:46:46.876916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21669 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337) # for reproducibility\n",
    "\n",
    "# Lower case vocabulary\n",
    "vocab = [\"A\", \"G\", \"C\", \"T\"]\n",
    "\n",
    "# These are the defaults of the data reader method \n",
    "# (each column in the ingested csv must be initialized with the right data type, otherwise the data ingestion fails )\n",
    "indices = tf.range(len(vocab), dtype = tf.int64)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab,indices)\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, 1)\n",
    "defs = [0.] * 1 + [tf.constant([], dtype = \"string\")]\n",
    "\n",
    "# Nadav dataset\n",
    "\n",
    "def data_reader(file, batch_size=100, n_parse_threads=4):\n",
    "    \"\"\"Method for reading the data in an optimized way, can be used inside model.fit()\n",
    "    \n",
    "    Args:\n",
    "        file (_type_): path to csv file\n",
    "        batch_size (int, optional): _description_. Defaults to 100.\n",
    "        n_parse_threads (int, optional): _description_. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        dataset.batch: batch dataset object \n",
    "    \"\"\"\n",
    "    dataset = tf.data.TextLineDataset(file).skip(1)\n",
    "    dataset=dataset.map(preprocess, num_parallel_calls = n_parse_threads)\n",
    "    return dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "def preprocess(record):\n",
    "    \"\"\"Preprocessing method of a dataset object, one-hot-encodes the data\n",
    "\n",
    "    Args:\n",
    "        record (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        X (2D np.array): one-hot-encoded input sequence\n",
    "        Y (1D np.array): MPRA measurements\n",
    "\n",
    "    \"\"\"\n",
    "    fields = tf.io.decode_csv(record, record_defaults=defs)\n",
    "    chars = tf.strings.bytes_split(fields[1])\n",
    "    chars_indeces = table.lookup(chars)\n",
    "    X = tf.one_hot(chars_indeces, depth = len(vocab))\n",
    "    Y = fields[0]\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41502a80",
   "metadata": {},
   "source": [
    "### k-fold cross validation split\n",
    "Here we take the initial csv file and we split it in 3 partitions k times\n",
    "\n",
    "It is possible to randomize the sequences and augment, since the masking of the model motifs was a better choice\n",
    "for understanding the background this strategy is here commented out and not used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6395a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_667371/1817506747.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[\"seq\"] = train['seq'].str.upper()\n",
      "/tmp/ipykernel_667371/1817506747.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"seq\"] = test['seq'].str.upper()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_3E</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>0.053119</td>\n",
       "      <td>AGGACCGGATCAACTGGTGCTGCCGTCACAACGCACTGTGCTTGTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>-0.077200</td>\n",
       "      <td>AGGACCGGATCAACTGTACAGTTATAAGGTAATCTTGTTCGATAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>0.011841</td>\n",
       "      <td>AGGACCGGATCAACTCGACCGGGGTCACCAGGATATTATCAGATGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>-0.103969</td>\n",
       "      <td>AGGACCGGATCAACTAATTGATATTGGCGCGTGTATCCCGAATTTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>0.036170</td>\n",
       "      <td>AGGACCGGATCAACTACTTGTGTTCAGGCACGATTTCTATCGTCGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>0.151705</td>\n",
       "      <td>AGGACCGGATCAACTGGTGGTAGCCACCTAGGGATAGCATAGGAGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5980</th>\n",
       "      <td>-0.000154</td>\n",
       "      <td>AGGACCGGATCAACTGTCAGAACTGCTTTGCCGACCGCGCTTTCTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>0.039057</td>\n",
       "      <td>AGGACCGGATCAACTACGTAGTGCTTTATACCATCGAACCACTGCG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8448</th>\n",
       "      <td>0.091301</td>\n",
       "      <td>AGGACCGGATCAACTTTTGTGTAACGCTGTACGGGGCTGGAGATTT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8071</th>\n",
       "      <td>0.072050</td>\n",
       "      <td>AGGACCGGATCAACTTTCAATGATCAGCACTAAAAACGGTTCTGGT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6791 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      State_3E                                                seq\n",
       "5786  0.053119  AGGACCGGATCAACTGGTGCTGCCGTCACAACGCACTGTGCTTGTT...\n",
       "5873 -0.077200  AGGACCGGATCAACTGTACAGTTATAAGGTAATCTTGTTCGATAAA...\n",
       "3331  0.011841  AGGACCGGATCAACTCGACCGGGGTCACCAGGATATTATCAGATGG...\n",
       "539  -0.103969  AGGACCGGATCAACTAATTGATATTGGCGCGTGTATCCCGAATTTC...\n",
       "1122  0.036170  AGGACCGGATCAACTACTTGTGTTCAGGCACGATTTCTATCGTCGG...\n",
       "...        ...                                                ...\n",
       "5792  0.151705  AGGACCGGATCAACTGGTGGTAGCCACCTAGGGATAGCATAGGAGG...\n",
       "5980 -0.000154  AGGACCGGATCAACTGTCAGAACTGCTTTGCCGACCGCGCTTTCTT...\n",
       "955   0.039057  AGGACCGGATCAACTACGTAGTGCTTTATACCATCGAACCACTGCG...\n",
       "8448  0.091301  AGGACCGGATCAACTTTTGTGTAACGCTGTACGGGGCTGGAGATTT...\n",
       "8071  0.072050  AGGACCGGATCAACTTTCAATGATCAGCACTAAAAACGGTTCTGGT...\n",
       "\n",
       "[6791 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CROSS VALIDATION (10 fold)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# Split the data in three partitions\n",
    "whole_data = pd.read_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3.csv\")\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 2008)\n",
    "\n",
    "o=1\n",
    "# For each fold we split again to get the third partition\n",
    "for i in kf.split(whole_data):\n",
    "    # Get train/test split and upper case all nucleotides\n",
    "    train = whole_data.iloc[i[0]]\n",
    "    train[\"seq\"] = train['seq'].str.upper() \n",
    "    \n",
    "    test =  whole_data.iloc[i[1]]\n",
    "    test[\"seq\"] = test['seq'].str.upper() \n",
    "\n",
    "    train, validation = train_test_split(train, test_size=0.11, random_state=42)\n",
    "    \n",
    "    train.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_train.csv\", index=False)\n",
    "    test.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_test.csv\", index=False)\n",
    "    validation.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_validation.csv\", index=False)\n",
    "    o+=1\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7928e",
   "metadata": {},
   "source": [
    "### Deep Learning model\n",
    "\n",
    "Here we run the model which is based on this paper : \n",
    "\n",
    "https://doi.org/10.1101/2023.03.05.531189\n",
    "\n",
    "I have added a Normalization layer parametrized with two parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d1457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test_10folds  = pd.DataFrame(columns=['State_3E', \"seq\", \"prediction\"])\n",
    "corr_list = []\n",
    "\n",
    "# We define a custom normalization layer to then compile on the model\n",
    "class CustomNormalization(Layer):\n",
    "    \"\"\"Custom normalization layer that normalizes the output of the neural network\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CustomNormalization, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Add trainable variables for mean and standard deviation\n",
    "        self.mean = self.add_weight(\"mean\", shape=(1,), initializer=\"zeros\", trainable=True)\n",
    "        self.stddev = self.add_weight(\"stddev\", shape=(1,), initializer=\"ones\", trainable=True)\n",
    "        super(CustomNormalization, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Normalize the inputs using the learned mean and standard deviation\n",
    "        return (inputs - self.mean) / (self.stddev + 1e-8)\n",
    "\n",
    "# We define the method to compute the pearson correlation between prediction and ground truth\n",
    "def pearson_correlation(x, y):\n",
    "    \"\"\"Computes Pearson Correlation between x and y\n",
    "    Args:\n",
    "        x (np.array): vector of predictions values\n",
    "        y (np.array): vector of ground truth values\n",
    "\n",
    "    Returns:\n",
    "        (float): pearson correlation\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    \n",
    "    # Calculate the mean of x and y\n",
    "    mean_x = sum(x) / n\n",
    "    mean_y = sum(y) / n\n",
    "    \n",
    "    # Calculate the numerator and denominators of the correlation coefficient\n",
    "    numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "    denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "    denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "    \n",
    "    # Calculate the correlation coefficient\n",
    "    correlation = numerator / (denominator_x * denominator_y)\n",
    "    return correlation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Define plotting function of loss\n",
    "def create_plots(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada1f870",
   "metadata": {},
   "source": [
    "#### Model training\n",
    "Here we iterate through the folds and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4155f147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 256, 250)          1000      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 249, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 122, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 121, 100)          400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12100)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization (Cust  (None, 1)                 2         \n",
      " omNormalization)                                                \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:46:54.582784: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-13 12:46:54.679193: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-13 12:46:54.775094: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-13 12:46:56.392035: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f344400b820 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-13 12:46:56.392063: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-11-13 12:46:56.397436: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-13 12:46:56.484694: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34/Unknown - 8s 51ms/step - loss: 0.1259 - mse: 0.1259 - mae: 0.2639 - mape: 28670.8438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:47:00.401560: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 8s 74ms/step - loss: 0.1259 - mse: 0.1259 - mae: 0.2639 - mape: 28670.8438 - val_loss: 0.0236 - val_mse: 0.0236 - val_mae: 0.1015 - val_mape: 106.5220\n",
      "Epoch 2/20\n",
      " 3/34 [=>............................] - ETA: 0s - loss: 0.0336 - mse: 0.0336 - mae: 0.1410 - mape: 1364.6373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:47:01.140893: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4710803253545640298\n",
      "2023-11-13 12:47:01.140962: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0279 - mse: 0.0279 - mae: 0.1290 - mape: 3606.7090 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.0982 - val_mape: 357.6240\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0208 - mse: 0.0208 - mae: 0.1123 - mape: 6495.1416 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0993 - val_mape: 456.4308\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0161 - mse: 0.0161 - mae: 0.0985 - mape: 13524.7031 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.1004 - val_mape: 519.6781\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0914 - mape: 9065.1982 - val_loss: 0.0210 - val_mse: 0.0210 - val_mae: 0.1039 - val_mape: 648.3964\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0841 - mape: 7098.6445 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.1030 - val_mape: 618.3217\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0773 - mape: 13071.8477 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.1085 - val_mape: 781.5745\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0713 - mape: 1126.4238 - val_loss: 0.0232 - val_mse: 0.0232 - val_mae: 0.1167 - val_mape: 955.1781\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0684 - mape: 9499.3066 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1110 - val_mape: 839.0855\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0678 - mape: 5817.2764 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.1010 - val_mape: 544.6161\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0727 - mape: 5609.1943 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.1012 - val_mape: 553.3634\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0761 - mape: 10016.3691 - val_loss: 0.0318 - val_mse: 0.0318 - val_mae: 0.1501 - val_mape: 1463.9580\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0649 - mape: 1854.5720 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.1130 - val_mape: 886.4293\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0569 - mape: 7357.7051 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1099 - val_mape: 823.0281\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0570 - mape: 1572.1012 - val_loss: 0.0216 - val_mse: 0.0216 - val_mae: 0.1096 - val_mape: 823.8133\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0571 - mape: 6779.1602 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.1037 - val_mape: 698.9838\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0586 - mape: 639.9145 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.0958 - val_mape: 153.2794\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0686 - mape: 11291.3945 - val_loss: 0.0289 - val_mse: 0.0289 - val_mae: 0.1216 - val_mape: 540.6913\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0131 - mse: 0.0131 - mae: 0.0949 - mape: 18237.7773 - val_loss: 0.0173 - val_mse: 0.0173 - val_mae: 0.0993 - val_mape: 744.1164\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0792 - mape: 1837.2028 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0917 - val_mape: 629.6119\n",
      "9/9 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:47:25.552543: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n",
      "/tmp/ipykernel_667371/2768337520.py:70: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_test_10folds = pd.concat([df_test_10folds, df_test], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 256, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 249, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 122, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 121, 100)          400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_1 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     33/Unknown - 4s 30ms/step - loss: 0.0737 - mse: 0.0737 - mae: 0.2095 - mape: 35473.3516"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:47:30.591844: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4710803253545640298\n",
      "2023-11-13 12:47:30.591928: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 4s 43ms/step - loss: 0.0728 - mse: 0.0728 - mae: 0.2084 - mape: 34517.2305 - val_loss: 0.0294 - val_mse: 0.0294 - val_mae: 0.1391 - val_mape: 2629.6531\n",
      "Epoch 2/20\n",
      " 3/34 [=>............................] - ETA: 0s - loss: 0.0292 - mse: 0.0292 - mae: 0.1344 - mape: 10338.6709"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:47:30.976466: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4710803253545640298\n",
      "2023-11-13 12:47:30.976547: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0248 - mse: 0.0248 - mae: 0.1210 - mape: 2826.1545 - val_loss: 0.0214 - val_mse: 0.0214 - val_mae: 0.1020 - val_mape: 921.3037\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0179 - mse: 0.0179 - mae: 0.1030 - mape: 9011.9648 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.1039 - val_mape: 1122.2283\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.0138 - mse: 0.0138 - mae: 0.0899 - mape: 10702.3340 - val_loss: 0.0216 - val_mse: 0.0216 - val_mae: 0.1009 - val_mape: 768.2529\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0114 - mse: 0.0114 - mae: 0.0821 - mape: 8651.8389 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.1057 - val_mape: 1260.1055\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0761 - mape: 12764.5420 - val_loss: 0.0238 - val_mse: 0.0238 - val_mae: 0.1171 - val_mape: 1866.6748\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0751 - mape: 7104.2588 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1167 - val_mape: 1850.6747\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0692 - mape: 2625.8870 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1005 - val_mape: 544.2530\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.0072 - mse: 0.0072 - mae: 0.0651 - mape: 8094.1323 - val_loss: 0.0214 - val_mse: 0.0214 - val_mae: 0.1018 - val_mape: 901.2252\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0663 - mape: 4228.8804 - val_loss: 0.0214 - val_mse: 0.0214 - val_mae: 0.1020 - val_mape: 931.8773\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0688 - mape: 1903.8824 - val_loss: 0.0329 - val_mse: 0.0329 - val_mae: 0.1505 - val_mape: 2959.1707\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0692 - mape: 3008.8840 - val_loss: 0.0232 - val_mse: 0.0232 - val_mae: 0.1147 - val_mape: 1765.4906\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0645 - mape: 6373.7036 - val_loss: 0.0299 - val_mse: 0.0299 - val_mae: 0.1412 - val_mape: 2695.4263\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0717 - mape: 10933.7383 - val_loss: 0.0260 - val_mse: 0.0260 - val_mae: 0.1278 - val_mape: 2274.6287\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0768 - mape: 13582.6084 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.1008 - val_mape: 137.9520\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0664 - mape: 1422.8965 - val_loss: 0.0257 - val_mse: 0.0257 - val_mae: 0.1123 - val_mape: 746.7783\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0579 - mape: 2321.9312 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0964 - val_mape: 206.8508\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0528 - mape: 1930.1158 - val_loss: 0.0154 - val_mse: 0.0154 - val_mae: 0.0906 - val_mape: 648.5081\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0502 - mape: 5045.5332 - val_loss: 0.0150 - val_mse: 0.0150 - val_mae: 0.0962 - val_mape: 1349.5986\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0496 - mape: 10309.7197 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0887 - val_mape: 1079.5575\n",
      "9/9 [==============================] - 0s 8ms/step\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 256, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 249, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_2 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 4s 42ms/step - loss: 0.0518 - mse: 0.0518 - mae: 0.1749 - mape: 8160.6245 - val_loss: 0.0223 - val_mse: 0.0223 - val_mae: 0.0977 - val_mape: 142.8833\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0229 - mse: 0.0229 - mae: 0.1160 - mape: 15075.6182 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.0969 - val_mape: 233.0611\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0160 - mse: 0.0160 - mae: 0.0970 - mape: 14336.8516 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.0970 - val_mape: 243.9167\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0119 - mse: 0.0119 - mae: 0.0835 - mape: 5852.5591 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.0969 - val_mape: 220.6185\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0097 - mse: 0.0097 - mae: 0.0749 - mape: 2457.6350 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0972 - val_mape: 271.9947\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0698 - mape: 9622.9541 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.0979 - val_mape: 322.6416\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0670 - mape: 19505.9551 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.1059 - val_mape: 544.7925\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0647 - mape: 5199.1201 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.1001 - val_mape: 408.5506\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0629 - mape: 1400.3340 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.1029 - val_mape: 481.5375\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0593 - mape: 14967.8984 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1114 - val_mape: 641.5687\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0640 - mape: 4890.2505 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1051 - val_mape: 529.3449\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0652 - mape: 4327.3486 - val_loss: 0.0305 - val_mse: 0.0305 - val_mae: 0.1191 - val_mape: 375.9931\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0683 - mape: 4892.1958 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.1016 - val_mape: 459.0719\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0603 - mape: 16122.3799 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0961 - val_mape: 262.4201\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0053 - mse: 0.0053 - mae: 0.0573 - mape: 6423.8394 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0968 - val_mape: 348.2831\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0582 - mape: 2162.5034 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.1073 - val_mape: 604.5543\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0611 - mape: 6543.9834 - val_loss: 0.0223 - val_mse: 0.0223 - val_mae: 0.1185 - val_mape: 764.6343\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0744 - mape: 23234.0957 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1221 - val_mape: 789.6356\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0120 - mse: 0.0120 - mae: 0.0894 - mape: 11508.6465 - val_loss: 0.0154 - val_mse: 0.0154 - val_mae: 0.0891 - val_mape: 331.6579\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0837 - mape: 15262.2188 - val_loss: 0.0224 - val_mse: 0.0224 - val_mae: 0.1102 - val_mape: 436.1278\n",
      "9/9 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:48:25.204740: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_3 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     33/Unknown - 4s 29ms/step - loss: 0.0883 - mse: 0.0883 - mae: 0.2267 - mape: 12014.5947"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:48:30.017812: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4710803253545640298\n",
      "2023-11-13 12:48:30.017885: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 4s 42ms/step - loss: 0.0866 - mse: 0.0866 - mae: 0.2240 - mape: 11697.7783 - val_loss: 0.0268 - val_mse: 0.0268 - val_mae: 0.1134 - val_mape: 222.8773\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:48:30.387824: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4710803253545640298\n",
      "2023-11-13 12:48:30.387896: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0282 - mse: 0.0282 - mae: 0.1298 - mape: 22009.4961 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.1002 - val_mape: 110.3536\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0199 - mse: 0.0199 - mae: 0.1097 - mape: 14177.2109 - val_loss: 0.0244 - val_mse: 0.0244 - val_mae: 0.1066 - val_mape: 170.7417\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0157 - mse: 0.0157 - mae: 0.0968 - mape: 1152.6229 - val_loss: 0.0234 - val_mse: 0.0234 - val_mae: 0.1041 - val_mape: 148.2648\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0130 - mse: 0.0130 - mae: 0.0877 - mape: 11523.9385 - val_loss: 0.0259 - val_mse: 0.0259 - val_mae: 0.1107 - val_mape: 203.4537\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0783 - mape: 3031.8091 - val_loss: 0.0257 - val_mse: 0.0257 - val_mae: 0.1104 - val_mape: 200.5352\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0722 - mape: 10206.6377 - val_loss: 0.0256 - val_mse: 0.0256 - val_mae: 0.1099 - val_mape: 197.4495\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0689 - mape: 15991.5244 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0968 - val_mape: 128.6813\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0697 - mape: 1905.3297 - val_loss: 0.0191 - val_mse: 0.0191 - val_mae: 0.0970 - val_mape: 191.2859\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0820 - mape: 3941.7114 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.1059 - val_mape: 334.8541\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0955 - mape: 5063.6445 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.0992 - val_mape: 101.6559\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.0073 - mse: 0.0073 - mae: 0.0660 - mape: 11380.0625 - val_loss: 0.0191 - val_mse: 0.0191 - val_mae: 0.0971 - val_mape: 197.4185\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0598 - mape: 982.4654 - val_loss: 0.0191 - val_mse: 0.0191 - val_mae: 0.1007 - val_mape: 275.0082\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0599 - mape: 9611.4365 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.1095 - val_mape: 376.4173\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0616 - mape: 3198.6038 - val_loss: 0.0283 - val_mse: 0.0283 - val_mae: 0.1410 - val_mape: 611.0870\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0712 - mape: 4397.0215 - val_loss: 0.0360 - val_mse: 0.0360 - val_mae: 0.1650 - val_mape: 757.0539\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0793 - mape: 10598.5928 - val_loss: 0.0162 - val_mse: 0.0162 - val_mae: 0.0951 - val_mape: 280.8601\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0621 - mape: 4736.5874 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0889 - val_mape: 145.6584\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0516 - mape: 1207.2627 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0859 - val_mape: 153.8375\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0477 - mape: 7230.9727 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0833 - val_mape: 162.4507\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:48:54.551789: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_4 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 4s 43ms/step - loss: 0.0477 - mse: 0.0477 - mae: 0.1663 - mape: 8846.0762 - val_loss: 0.0256 - val_mse: 0.0256 - val_mae: 0.1061 - val_mape: 245.9069\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0210 - mse: 0.0210 - mae: 0.1127 - mape: 17756.3828 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1044 - val_mape: 1322.9939\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0155 - mse: 0.0155 - mae: 0.0953 - mape: 6133.9888 - val_loss: 0.0229 - val_mse: 0.0229 - val_mae: 0.1034 - val_mape: 1087.6238\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0830 - mape: 17229.6035 - val_loss: 0.0231 - val_mse: 0.0231 - val_mae: 0.1031 - val_mape: 928.6387\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0733 - mape: 3332.1729 - val_loss: 0.0231 - val_mse: 0.0231 - val_mae: 0.1084 - val_mape: 1756.8783\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0695 - mape: 1644.2075 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1075 - val_mape: 1674.5337\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0676 - mape: 6905.5586 - val_loss: 0.0238 - val_mse: 0.0238 - val_mae: 0.1123 - val_mape: 2032.7260\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0080 - mse: 0.0080 - mae: 0.0703 - mape: 21387.5410 - val_loss: 0.0229 - val_mse: 0.0229 - val_mae: 0.1033 - val_mape: 1056.9769\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0679 - mape: 3496.0181 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1051 - val_mape: 1426.0591\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0076 - mse: 0.0076 - mae: 0.0684 - mape: 11678.1816 - val_loss: 0.0266 - val_mse: 0.0266 - val_mae: 0.1084 - val_mape: 124.1626\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0058 - mse: 0.0058 - mae: 0.0588 - mape: 2796.1438 - val_loss: 0.0231 - val_mse: 0.0231 - val_mae: 0.1030 - val_mape: 906.6089\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0550 - mape: 5495.5571 - val_loss: 0.0232 - val_mse: 0.0232 - val_mae: 0.1092 - val_mape: 1829.5896\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0511 - mape: 12932.9697 - val_loss: 0.0228 - val_mse: 0.0228 - val_mae: 0.1073 - val_mape: 1689.6373\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0506 - mape: 15181.3535 - val_loss: 0.0223 - val_mse: 0.0223 - val_mae: 0.1044 - val_mape: 1464.7725\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0501 - mape: 10168.2305 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1015 - val_mape: 1111.7267\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0495 - mape: 817.3059 - val_loss: 0.0214 - val_mse: 0.0214 - val_mae: 0.1000 - val_mape: 1057.8743\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0510 - mape: 15233.9209 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.1006 - val_mape: 1495.3167\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0501 - mape: 1907.7758 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1154 - val_mape: 2534.3882\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0524 - mape: 5334.9023 - val_loss: 0.0173 - val_mse: 0.0173 - val_mae: 0.0991 - val_mape: 1842.1001\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0568 - mape: 3659.7107 - val_loss: 0.0149 - val_mse: 0.0149 - val_mae: 0.0874 - val_mape: 734.0327\n",
      "9/9 [==============================] - 0s 9ms/step\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_5 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     33/Unknown - 4s 29ms/step - loss: 0.0803 - mse: 0.0803 - mae: 0.2158 - mape: 1863.0925"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:49:28.836888: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 4s 45ms/step - loss: 0.0791 - mse: 0.0791 - mae: 0.2140 - mape: 1843.7025 - val_loss: 0.0294 - val_mse: 0.0294 - val_mae: 0.1152 - val_mape: 827.4606\n",
      "Epoch 2/20\n",
      " 3/34 [=>............................] - ETA: 0s - loss: 0.0339 - mse: 0.0339 - mae: 0.1376 - mape: 402.6818"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:49:29.336124: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4710803253545640298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0258 - mse: 0.0258 - mae: 0.1233 - mape: 1330.7831 - val_loss: 0.0240 - val_mse: 0.0240 - val_mae: 0.1027 - val_mape: 535.7078\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0201 - mse: 0.0201 - mae: 0.1092 - mape: 1226.3835 - val_loss: 0.0233 - val_mse: 0.0233 - val_mae: 0.1022 - val_mape: 897.7667\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0940 - mape: 1051.9601 - val_loss: 0.0256 - val_mse: 0.0256 - val_mae: 0.1056 - val_mape: 100.4826\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0836 - mape: 724.2888 - val_loss: 0.0261 - val_mse: 0.0261 - val_mae: 0.1069 - val_mape: 222.2729\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0768 - mape: 911.4440 - val_loss: 0.0271 - val_mse: 0.0271 - val_mae: 0.1093 - val_mape: 428.2037\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0723 - mape: 679.6648 - val_loss: 0.0242 - val_mse: 0.0242 - val_mae: 0.1029 - val_mape: 491.9320\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0711 - mape: 800.5406 - val_loss: 0.0228 - val_mse: 0.0228 - val_mae: 0.1052 - val_mape: 1564.0027\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0091 - mse: 0.0091 - mae: 0.0757 - mape: 590.3617 - val_loss: 0.0246 - val_mse: 0.0246 - val_mae: 0.1179 - val_mape: 2593.1101\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0801 - mape: 817.2639 - val_loss: 0.0291 - val_mse: 0.0291 - val_mae: 0.1146 - val_mape: 791.6752\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0690 - mape: 635.4996 - val_loss: 0.0233 - val_mse: 0.0233 - val_mae: 0.1021 - val_mape: 871.7404\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0054 - mse: 0.0054 - mae: 0.0576 - mape: 513.7067 - val_loss: 0.0228 - val_mse: 0.0228 - val_mae: 0.1035 - val_mape: 1330.3999\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0550 - mape: 643.1351 - val_loss: 0.0235 - val_mse: 0.0235 - val_mae: 0.1020 - val_mape: 666.5828\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0051 - mse: 0.0051 - mae: 0.0561 - mape: 383.9091 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1020 - val_mape: 500.8833\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0549 - mape: 515.4207 - val_loss: 0.0240 - val_mse: 0.0240 - val_mae: 0.1023 - val_mape: 301.7723\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0597 - mape: 497.4786 - val_loss: 0.0293 - val_mse: 0.0293 - val_mae: 0.1168 - val_mape: 1072.7318\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0087 - mse: 0.0087 - mae: 0.0758 - mape: 954.0995 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.0975 - val_mape: 570.6012\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0811 - mape: 697.3149 - val_loss: 0.0370 - val_mse: 0.0370 - val_mae: 0.1670 - val_mape: 5121.0728\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0615 - mape: 539.8668 - val_loss: 0.0191 - val_mse: 0.0191 - val_mae: 0.1071 - val_mape: 2835.0466\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 1s 33ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0545 - mape: 548.6886 - val_loss: 0.0173 - val_mse: 0.0173 - val_mae: 0.1013 - val_mape: 2637.3113\n",
      "9/9 [==============================] - 1s 9ms/step\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_27 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_6 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     33/Unknown - 4s 30ms/step - loss: 0.0578 - mse: 0.0578 - mae: 0.1846 - mape: 1808.6833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:49:59.423499: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 4s 44ms/step - loss: 0.0571 - mse: 0.0571 - mae: 0.1830 - mape: 1769.6396 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.0949 - val_mape: 9919.5225\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0220 - mse: 0.0220 - mae: 0.1136 - mape: 1120.3253 - val_loss: 0.0193 - val_mse: 0.0193 - val_mae: 0.0940 - val_mape: 28469.9355\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0165 - mse: 0.0165 - mae: 0.0981 - mape: 1137.3082 - val_loss: 0.0188 - val_mse: 0.0188 - val_mae: 0.0957 - val_mape: 52580.9180\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0848 - mape: 998.8790 - val_loss: 0.0188 - val_mse: 0.0188 - val_mae: 0.0963 - val_mape: 57772.6680\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0754 - mape: 820.8917 - val_loss: 0.0191 - val_mse: 0.0191 - val_mae: 0.0997 - val_mape: 75529.2734\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0699 - mape: 852.1413 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.1038 - val_mape: 90959.4453\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0672 - mape: 675.2349 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.1079 - val_mape: 103667.3047\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0687 - mape: 485.9751 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.1027 - val_mape: 87223.8984\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0714 - mape: 1050.1595 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.1067 - val_mape: 100225.9453\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0626 - mape: 742.8206 - val_loss: 0.0190 - val_mse: 0.0190 - val_mae: 0.0942 - val_mape: 36216.0859\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0639 - mape: 517.7568 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1039 - val_mape: 29379.8945\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0598 - mape: 532.2686 - val_loss: 0.0188 - val_mse: 0.0188 - val_mae: 0.0981 - val_mape: 68785.0156\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0531 - mape: 537.3209 - val_loss: 0.0186 - val_mse: 0.0186 - val_mae: 0.0960 - val_mape: 57459.4414\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0507 - mape: 415.3423 - val_loss: 0.0184 - val_mse: 0.0184 - val_mae: 0.0944 - val_mape: 48142.6328\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0502 - mape: 496.2483 - val_loss: 0.0186 - val_mse: 0.0186 - val_mae: 0.0925 - val_mape: 24297.5898\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0040 - mse: 0.0040 - mae: 0.0485 - mape: 360.2481 - val_loss: 0.0192 - val_mse: 0.0192 - val_mae: 0.0930 - val_mape: 4056.1594\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0491 - mape: 378.2206 - val_loss: 0.0170 - val_mse: 0.0170 - val_mae: 0.0888 - val_mape: 7218.2222\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0043 - mse: 0.0043 - mae: 0.0512 - mape: 484.4023 - val_loss: 0.0152 - val_mse: 0.0152 - val_mae: 0.0860 - val_mape: 14832.1484\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0536 - mape: 600.2697 - val_loss: 0.0190 - val_mse: 0.0190 - val_mae: 0.0993 - val_mape: 69182.2969\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0525 - mape: 644.5256 - val_loss: 0.0241 - val_mse: 0.0241 - val_mae: 0.1208 - val_mape: 130280.4922\n",
      "9/9 [==============================] - 0s 9ms/step\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_28 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_29 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_30 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_31 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_7 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 4s 42ms/step - loss: 0.0751 - mse: 0.0751 - mae: 0.2087 - mape: 3332.6030 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1062 - val_mape: 31320.8691\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:50:29.561095: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4710803253545640298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0241 - mse: 0.0241 - mae: 0.1205 - mape: 1096.3005 - val_loss: 0.0184 - val_mse: 0.0184 - val_mae: 0.0969 - val_mape: 53829.3711\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0177 - mse: 0.0177 - mae: 0.1031 - mape: 706.3000 - val_loss: 0.0183 - val_mse: 0.0183 - val_mae: 0.0971 - val_mape: 55716.0391\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0135 - mse: 0.0135 - mae: 0.0896 - mape: 802.3046 - val_loss: 0.0187 - val_mse: 0.0187 - val_mae: 0.0954 - val_mape: 35428.0703\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0804 - mape: 858.6725 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0968 - val_mape: 8145.4746\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0729 - mape: 734.4293 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0978 - val_mape: 1409.8560\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0686 - mape: 559.2232 - val_loss: 0.0192 - val_mse: 0.0192 - val_mae: 0.0956 - val_mape: 21289.9160\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0665 - mape: 574.5189 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.1057 - val_mape: 97985.7109\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0071 - mse: 0.0071 - mae: 0.0656 - mape: 660.3019 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.1056 - val_mape: 97644.3750\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0077 - mse: 0.0077 - mae: 0.0690 - mape: 839.7957 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.1078 - val_mape: 104974.2891\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0704 - mape: 837.6666 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1061 - val_mape: 31362.4160\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0628 - mape: 786.7026 - val_loss: 0.0183 - val_mse: 0.0183 - val_mae: 0.0975 - val_mape: 60073.4336\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0536 - mape: 671.8457 - val_loss: 0.0184 - val_mse: 0.0184 - val_mae: 0.0997 - val_mape: 73960.2109\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0044 - mse: 0.0044 - mae: 0.0516 - mape: 774.5784 - val_loss: 0.0182 - val_mse: 0.0182 - val_mae: 0.0991 - val_mape: 72183.7891\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0041 - mse: 0.0041 - mae: 0.0494 - mape: 367.3294 - val_loss: 0.0184 - val_mse: 0.0184 - val_mae: 0.1015 - val_mape: 86148.7031\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0476 - mape: 484.2694 - val_loss: 0.0182 - val_mse: 0.0182 - val_mae: 0.1015 - val_mape: 89937.0078\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0037 - mse: 0.0037 - mae: 0.0466 - mape: 447.5249 - val_loss: 0.0166 - val_mse: 0.0166 - val_mae: 0.0955 - val_mape: 72079.7344\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0035 - mse: 0.0035 - mae: 0.0461 - mape: 434.3021 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0896 - val_mape: 44025.4961\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0034 - mse: 0.0034 - mae: 0.0451 - mape: 598.1413 - val_loss: 0.0141 - val_mse: 0.0141 - val_mae: 0.0874 - val_mape: 50988.1055\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 1s 36ms/step - loss: 0.0032 - mse: 0.0032 - mae: 0.0439 - mape: 584.1816 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0844 - val_mape: 38469.6211\n",
      "9/9 [==============================] - 0s 9ms/step\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_32 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_33 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_34 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_35 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_8 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 5s 64ms/step - loss: 0.1022 - mse: 0.1022 - mae: 0.2394 - mape: 47896.1055 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0959 - val_mape: 1231.6338\n",
      "Epoch 2/20\n",
      " 1/34 [..............................] - ETA: 2s - loss: 0.0288 - mse: 0.0288 - mae: 0.1348 - mape: 1703.0089"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:51:00.300140: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4710803253545640298\n",
      "2023-11-13 12:51:00.300227: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0272 - mse: 0.0272 - mae: 0.1278 - mape: 4643.9663 - val_loss: 0.0190 - val_mse: 0.0190 - val_mae: 0.0954 - val_mape: 326.0264\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 1s 38ms/step - loss: 0.0214 - mse: 0.0214 - mae: 0.1135 - mape: 7075.7241 - val_loss: 0.0224 - val_mse: 0.0224 - val_mae: 0.1045 - val_mape: 541.0201\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0164 - mse: 0.0164 - mae: 0.0984 - mape: 5495.9536 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0991 - val_mape: 216.6274\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0126 - mse: 0.0126 - mae: 0.0867 - mape: 6499.8540 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1006 - val_mape: 316.6741\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0103 - mse: 0.0103 - mae: 0.0774 - mape: 9057.4014 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0999 - val_mape: 272.1606\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0721 - mape: 5376.0923 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0973 - val_mape: 119.4427\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0689 - mape: 2095.9470 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1006 - val_mape: 314.8273\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0674 - mape: 3391.1838 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.0988 - val_mape: 198.8166\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0637 - mape: 25499.5039 - val_loss: 0.0224 - val_mse: 0.0224 - val_mae: 0.1044 - val_mape: 535.5140\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0618 - mape: 3090.2639 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1007 - val_mape: 326.1812\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0062 - mse: 0.0062 - mae: 0.0619 - mape: 18789.4258 - val_loss: 0.0180 - val_mse: 0.0180 - val_mae: 0.0939 - val_mape: 630.5700\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0075 - mse: 0.0075 - mae: 0.0683 - mape: 11298.9297 - val_loss: 0.0181 - val_mse: 0.0181 - val_mae: 0.1008 - val_mape: 1760.1169\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0729 - mape: 13024.6299 - val_loss: 0.0255 - val_mse: 0.0255 - val_mae: 0.1143 - val_mape: 1003.9695\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0068 - mse: 0.0068 - mae: 0.0651 - mape: 6862.6494 - val_loss: 0.0255 - val_mse: 0.0255 - val_mae: 0.1147 - val_mape: 1024.6714\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0069 - mse: 0.0069 - mae: 0.0669 - mape: 1518.6345 - val_loss: 0.0279 - val_mse: 0.0279 - val_mae: 0.1234 - val_mape: 1359.4434\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0749 - mape: 892.4998 - val_loss: 0.0167 - val_mse: 0.0167 - val_mae: 0.0981 - val_mape: 1910.5573\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0059 - mse: 0.0059 - mae: 0.0605 - mape: 2421.1465 - val_loss: 0.0151 - val_mse: 0.0151 - val_mae: 0.0928 - val_mape: 1864.4362\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0042 - mse: 0.0042 - mae: 0.0505 - mape: 2804.0276 - val_loss: 0.0136 - val_mse: 0.0136 - val_mae: 0.0830 - val_mape: 857.2744\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0039 - mse: 0.0039 - mae: 0.0489 - mape: 5577.8477 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0798 - val_mape: 979.8870\n",
      "9/9 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:51:24.900054: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_36 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_37 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_38 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_39 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_9 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "34/34 [==============================] - 4s 44ms/step - loss: 0.0454 - mse: 0.0454 - mae: 0.1652 - mape: 1625.2178 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.1026 - val_mape: 95424.3359\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0214 - mse: 0.0214 - mae: 0.1130 - mape: 816.4512 - val_loss: 0.0170 - val_mse: 0.0170 - val_mae: 0.0988 - val_mape: 82272.7266\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 1s 37ms/step - loss: 0.0158 - mse: 0.0158 - mae: 0.0961 - mape: 751.9907 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.0948 - val_mape: 64069.8906\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0844 - mape: 707.4850 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.0938 - val_mape: 57929.8203\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0756 - mape: 484.8587 - val_loss: 0.0169 - val_mse: 0.0169 - val_mae: 0.0983 - val_mape: 80099.6172\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0699 - mape: 529.9380 - val_loss: 0.0191 - val_mse: 0.0191 - val_mae: 0.1100 - val_mape: 116412.8672\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0082 - mse: 0.0082 - mae: 0.0700 - mape: 517.9778 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1245 - val_mape: 148878.3594\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0099 - mse: 0.0099 - mae: 0.0781 - mape: 637.3976 - val_loss: 0.0168 - val_mse: 0.0168 - val_mae: 0.0917 - val_mape: 26380.4473\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0754 - mape: 550.7278 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.1147 - val_mape: 127922.1406\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0063 - mse: 0.0063 - mae: 0.0609 - mape: 455.2867 - val_loss: 0.0184 - val_mse: 0.0184 - val_mae: 0.1068 - val_mape: 107982.2109\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0057 - mse: 0.0057 - mae: 0.0580 - mape: 452.8087 - val_loss: 0.0172 - val_mse: 0.0172 - val_mae: 0.1005 - val_mape: 88731.2344\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0052 - mse: 0.0052 - mae: 0.0562 - mape: 376.8035 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.1024 - val_mape: 95640.4219\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0547 - mape: 321.1863 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.1160 - val_mape: 132207.1875\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0047 - mse: 0.0047 - mae: 0.0529 - mape: 392.5262 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.1026 - val_mape: 98216.3516\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0530 - mape: 376.0976 - val_loss: 0.0166 - val_mse: 0.0166 - val_mae: 0.0984 - val_mape: 87943.8984\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0046 - mse: 0.0046 - mae: 0.0528 - mape: 337.6319 - val_loss: 0.0169 - val_mse: 0.0169 - val_mae: 0.1014 - val_mape: 98768.2734\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 1s 35ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0538 - mape: 405.0577 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0963 - val_mape: 100577.7812\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0048 - mse: 0.0048 - mae: 0.0542 - mape: 481.1426 - val_loss: 0.0141 - val_mse: 0.0141 - val_mae: 0.0848 - val_mape: 23519.9453\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0049 - mse: 0.0049 - mae: 0.0552 - mape: 445.2073 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.1031 - val_mape: 51395.6250\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 1s 34ms/step - loss: 0.0067 - mse: 0.0067 - mae: 0.0660 - mape: 612.6190 - val_loss: 0.0261 - val_mse: 0.0261 - val_mae: 0.1286 - val_mape: 102623.6484\n",
      "9/9 [==============================] - 0s 9ms/step\n",
      "[0.6562095139975734, 0.5983876873654479, 0.6210376778937199, 0.635685840052435, 0.659851930577285, 0.5707244565805054, 0.6954469139358211, 0.5660324750372829, 0.6527517866878505, 0.6499272912494511]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_3E</th>\n",
       "      <th>seq</th>\n",
       "      <th>prediction</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007714</td>\n",
       "      <td>AGGACCGGATCAACTAAACAACTCAAACAAGGGCTAATATAACCCA...</td>\n",
       "      <td>0.065327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.137953</td>\n",
       "      <td>AGGACCGGATCAACTAAACACTAGTCATACTTAAAAATTGCAAGGA...</td>\n",
       "      <td>0.073747</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.048706</td>\n",
       "      <td>AGGACCGGATCAACTAAACAGGTTCTGACGTATGCTCCTCTATGGA...</td>\n",
       "      <td>0.030066</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052804</td>\n",
       "      <td>AGGACCGGATCAACTAAACCCGAGCCTGCCTAGCCCTAGCTTCTCT...</td>\n",
       "      <td>0.077990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.213652</td>\n",
       "      <td>AGGACCGGATCAACTAAACGGAGCAGAGTTAGTGTCAGGTCAAAAA...</td>\n",
       "      <td>0.056666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8473</th>\n",
       "      <td>0.167100</td>\n",
       "      <td>AGGACCGGATCAACTTTTCCGCCTTTTATTATCAGGACTTCACGGG...</td>\n",
       "      <td>0.013850</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474</th>\n",
       "      <td>0.099489</td>\n",
       "      <td>AGGACCGGATCAACTTTTCGCTCATTAGTACAGGGTATAACGGAAG...</td>\n",
       "      <td>-0.097034</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8475</th>\n",
       "      <td>-0.046939</td>\n",
       "      <td>AGGACCGGATCAACTTTTGGTCGGTTGACGGTCGCCTTGATTATTC...</td>\n",
       "      <td>-0.069841</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>0.093662</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTATCTGGTTATCATTCTAGTCTAGTGC...</td>\n",
       "      <td>-0.074672</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8477</th>\n",
       "      <td>0.199862</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTCCCCGTCTGCCAACTTCGTGGCTATC...</td>\n",
       "      <td>-0.041013</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8478 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      State_3E                                                seq  prediction  \\\n",
       "0    -0.007714  AGGACCGGATCAACTAAACAACTCAAACAAGGGCTAATATAACCCA...    0.065327   \n",
       "1     0.137953  AGGACCGGATCAACTAAACACTAGTCATACTTAAAAATTGCAAGGA...    0.073747   \n",
       "2    -0.048706  AGGACCGGATCAACTAAACAGGTTCTGACGTATGCTCCTCTATGGA...    0.030066   \n",
       "3    -0.052804  AGGACCGGATCAACTAAACCCGAGCCTGCCTAGCCCTAGCTTCTCT...    0.077990   \n",
       "4     0.213652  AGGACCGGATCAACTAAACGGAGCAGAGTTAGTGTCAGGTCAAAAA...    0.056666   \n",
       "...        ...                                                ...         ...   \n",
       "8473  0.167100  AGGACCGGATCAACTTTTCCGCCTTTTATTATCAGGACTTCACGGG...    0.013850   \n",
       "8474  0.099489  AGGACCGGATCAACTTTTCGCTCATTAGTACAGGGTATAACGGAAG...   -0.097034   \n",
       "8475 -0.046939  AGGACCGGATCAACTTTTGGTCGGTTGACGGTCGCCTTGATTATTC...   -0.069841   \n",
       "8476  0.093662  AGGACCGGATCAACTTTTTTATCTGGTTATCATTCTAGTCTAGTGC...   -0.074672   \n",
       "8477  0.199862  AGGACCGGATCAACTTTTTTCCCCGTCTGCCAACTTCGTGGCTATC...   -0.041013   \n",
       "\n",
       "     fold  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "...   ...  \n",
       "8473   10  \n",
       "8474   10  \n",
       "8475   10  \n",
       "8476   10  \n",
       "8477   10  \n",
       "\n",
       "[8478 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in range(1,11):\n",
    "    \n",
    "    # Define inputs\n",
    "    input_path_train = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_train.csv\"\n",
    "    input_path_valid = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_validation.csv\"\n",
    "    input_path_test = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_test.csv\"\n",
    "    \n",
    "    # Read test data to then predict\n",
    "    df_test = pd.read_csv(input_path_test)\n",
    "\n",
    "    # Get first item of the dataset to get the shape of the input data\n",
    "    for element in data_reader(input_path_train):\n",
    "        input_shape = element[0].shape\n",
    "    \n",
    "    # Define and compile model\n",
    "    inputs = Input(shape=(input_shape[1],input_shape[2]), name=\"inputs\")\n",
    "    layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "    predictions = Dense(1, activation='linear')(layer)\n",
    "    norm_predictions = CustomNormalization()(predictions)  # Assuming \"predictions\" is your existing output\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=norm_predictions)\n",
    "    model.summary()\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "                )\n",
    "    # Run model\n",
    "    history=model.fit(data_reader(input_path_train, batch_size=200),\n",
    "                            epochs=20,\n",
    "                            validation_data=data_reader(input_path_valid,batch_size=100),\n",
    "                            callbacks=None,\n",
    "                            verbose=1)\n",
    "    \n",
    "    #After training we save the model weights to then run the contribution scores\n",
    "    model_path = '/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/Model_CV'+str(i)+\"_LibA_wide_pivot_state3.h5\"\n",
    "    model.save_weights(model_path, save_format='h5')\n",
    "    \n",
    "    # We predict the test data\n",
    "    predicted = model.predict(data_reader(input_path_test,\n",
    "                                                batch_size=100))\n",
    "\n",
    "    # We fill the dataframe with predictions and fold annotation\n",
    "    test_data = data_reader(input_path_test,batch_size=100)\n",
    "    test_tensor = X = np.empty(shape=[0,1])\n",
    "    for batch in test_data:\n",
    "        test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "    # Append fold to previous folds\n",
    "    df_test[\"prediction\"] = predicted\n",
    "    df_test[\"fold\"] = str(i)\n",
    "    df_test_10folds = pd.concat([df_test_10folds, df_test], ignore_index=True)    \n",
    "\n",
    "    # Append correlation coefficient and append to previous        \n",
    "    corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)\n",
    "    corr_list.append(corr_coefficient)\n",
    "\n",
    "df_test_10folds.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/LibA_wide_pivot_state3_test_predicted_cv10fold.csv\", index=False)\n",
    "print(corr_list)\n",
    "df_test_10folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7772ea68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "create_plots(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0b4ec",
   "metadata": {},
   "source": [
    "# We now compute an ensemble approach we compute for each fold the model 10 times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48bb5d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "68/68 - 5s - loss: 0.0442 - mse: 0.0442 - mae: 0.1573 - mape: 4651.8760 - val_loss: 0.0210 - val_mse: 0.0210 - val_mae: 0.0984 - val_mape: 386.3610 - 5s/epoch - 73ms/step\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.0182 - mse: 0.0182 - mae: 0.1043 - mape: 6573.6782 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0989 - val_mape: 431.1293 - 1s/epoch - 19ms/step\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.0126 - mse: 0.0126 - mae: 0.0855 - mape: 8441.2119 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0989 - val_mape: 432.6306 - 1s/epoch - 19ms/step\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.0110 - mse: 0.0110 - mae: 0.0802 - mape: 8915.3984 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.0981 - val_mape: 332.1422 - 1s/epoch - 19ms/step\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.0106 - mse: 0.0106 - mae: 0.0794 - mape: 4484.3789 - val_loss: 0.0261 - val_mse: 0.0261 - val_mae: 0.1293 - val_mape: 1167.5787 - 1s/epoch - 21ms/step\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.0103 - mse: 0.0103 - mae: 0.0795 - mape: 1910.2388 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.0979 - val_mape: 296.1502 - 1s/epoch - 19ms/step\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.0078 - mse: 0.0078 - mae: 0.0673 - mape: 6105.4077 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.0984 - val_mape: 439.9550 - 1s/epoch - 20ms/step\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.0069 - mse: 0.0069 - mae: 0.0647 - mape: 7571.9717 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.1004 - val_mape: 585.4037 - 1s/epoch - 19ms/step\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.0064 - mse: 0.0064 - mae: 0.0615 - mape: 9836.1504 - val_loss: 0.0183 - val_mse: 0.0183 - val_mae: 0.0970 - val_mape: 519.6456 - 1s/epoch - 19ms/step\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.0059 - mse: 0.0059 - mae: 0.0598 - mape: 8932.1025 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0932 - val_mape: 533.8939 - 1s/epoch - 19ms/step\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.0056 - mse: 0.0056 - mae: 0.0583 - mape: 14616.7090 - val_loss: 0.0147 - val_mse: 0.0147 - val_mae: 0.0914 - val_mape: 496.5928 - 1s/epoch - 20ms/step\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.0055 - mse: 0.0055 - mae: 0.0580 - mape: 2184.8569 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0814 - val_mape: 340.8604 - 1s/epoch - 19ms/step\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.0061 - mse: 0.0061 - mae: 0.0612 - mape: 1939.9537 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0831 - val_mape: 530.2643 - 1s/epoch - 20ms/step\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.0083 - mse: 0.0083 - mae: 0.0724 - mape: 14353.2285 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0801 - val_mape: 285.1495 - 1s/epoch - 20ms/step\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.0093 - mse: 0.0093 - mae: 0.0768 - mape: 15872.1963 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0824 - val_mape: 278.5903 - 1s/epoch - 20ms/step\n",
      "Epoch 16/20\n",
      "68/68 - 1s - loss: 0.0107 - mse: 0.0107 - mae: 0.0827 - mape: 6425.0674 - val_loss: 0.0190 - val_mse: 0.0190 - val_mae: 0.1032 - val_mape: 534.7183 - 1s/epoch - 20ms/step\n",
      "Epoch 17/20\n",
      "68/68 - 1s - loss: 0.0096 - mse: 0.0096 - mae: 0.0779 - mape: 6927.1558 - val_loss: 0.0235 - val_mse: 0.0235 - val_mae: 0.1230 - val_mape: 795.3608 - 1s/epoch - 20ms/step\n",
      "Epoch 18/20\n",
      "68/68 - 2s - loss: 0.0071 - mse: 0.0071 - mae: 0.0663 - mape: 10376.9678 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0880 - val_mape: 423.3642 - 2s/epoch - 22ms/step\n",
      "Epoch 19/20\n",
      "68/68 - 1s - loss: 0.0052 - mse: 0.0052 - mae: 0.0564 - mape: 5175.6367 - val_loss: 0.0140 - val_mse: 0.0140 - val_mae: 0.0882 - val_mape: 601.7111 - 1s/epoch - 20ms/step\n",
      "Epoch 20/20\n",
      "68/68 - 1s - loss: 0.0044 - mse: 0.0044 - mae: 0.0521 - mape: 3424.1289 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0794 - val_mape: 349.8363 - 1s/epoch - 19ms/step\n",
      "9/9 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:52:28.332734: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14849713808749010592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:52:32.420228: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n",
      "2023-11-13 12:52:32.420305: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14849713808749010592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 4s - loss: 0.0647 - mse: 0.0647 - mae: 0.1857 - mape: 2723.6191 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.1005 - val_mape: 523.0434 - 4s/epoch - 60ms/step\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:52:32.815826: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n",
      "2023-11-13 12:52:32.815898: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14849713808749010592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 1s - loss: 0.0195 - mse: 0.0195 - mae: 0.1075 - mape: 24790.9082 - val_loss: 0.0210 - val_mse: 0.0210 - val_mae: 0.1034 - val_mape: 634.2174 - 1s/epoch - 19ms/step\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.0142 - mse: 0.0142 - mae: 0.0914 - mape: 10731.8750 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1046 - val_mape: 673.6396 - 1s/epoch - 19ms/step\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.0111 - mse: 0.0111 - mae: 0.0799 - mape: 9737.9609 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.1128 - val_mape: 878.5895 - 1s/epoch - 19ms/step\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.0099 - mse: 0.0099 - mae: 0.0762 - mape: 1142.1281 - val_loss: 0.0239 - val_mse: 0.0239 - val_mae: 0.1196 - val_mape: 1008.8282 - 1s/epoch - 19ms/step\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.0092 - mse: 0.0092 - mae: 0.0739 - mape: 6754.9292 - val_loss: 0.0307 - val_mse: 0.0307 - val_mae: 0.1464 - val_mape: 1415.2301 - 1s/epoch - 19ms/step\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.0090 - mse: 0.0090 - mae: 0.0736 - mape: 15028.8711 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.1136 - val_mape: 899.7740 - 1s/epoch - 19ms/step\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.0085 - mse: 0.0085 - mae: 0.0718 - mape: 7239.8403 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0957 - val_mape: 358.6353 - 1s/epoch - 20ms/step\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.0075 - mse: 0.0075 - mae: 0.0665 - mape: 10525.3174 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.1057 - val_mape: 843.4951 - 1s/epoch - 19ms/step\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.0064 - mse: 0.0064 - mae: 0.0618 - mape: 10775.6221 - val_loss: 0.0160 - val_mse: 0.0160 - val_mae: 0.0916 - val_mape: 548.9055 - 1s/epoch - 20ms/step\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.0067 - mse: 0.0067 - mae: 0.0638 - mape: 13241.9668 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0855 - val_mape: 559.2213 - 1s/epoch - 19ms/step\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.0078 - mse: 0.0078 - mae: 0.0690 - mape: 11436.8652 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1107 - val_mape: 510.1700 - 1s/epoch - 20ms/step\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.0091 - mse: 0.0091 - mae: 0.0753 - mape: 10541.3848 - val_loss: 0.0303 - val_mse: 0.0303 - val_mae: 0.1383 - val_mape: 836.6674 - 1s/epoch - 19ms/step\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.0081 - mse: 0.0081 - mae: 0.0708 - mape: 3165.7251 - val_loss: 0.0159 - val_mse: 0.0159 - val_mae: 0.0933 - val_mape: 397.8675 - 1s/epoch - 19ms/step\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.0068 - mse: 0.0068 - mae: 0.0644 - mape: 10647.4219 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0825 - val_mape: 426.8482 - 1s/epoch - 19ms/step\n",
      "Epoch 16/20\n",
      "68/68 - 1s - loss: 0.0057 - mse: 0.0057 - mae: 0.0589 - mape: 4999.6631 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0808 - val_mape: 399.6198 - 1s/epoch - 20ms/step\n",
      "Epoch 17/20\n",
      "68/68 - 1s - loss: 0.0053 - mse: 0.0053 - mae: 0.0567 - mape: 12639.9248 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0819 - val_mape: 330.4705 - 1s/epoch - 19ms/step\n",
      "Epoch 18/20\n",
      "68/68 - 1s - loss: 0.0052 - mse: 0.0052 - mae: 0.0562 - mape: 10684.8545 - val_loss: 0.0149 - val_mse: 0.0149 - val_mae: 0.0895 - val_mape: 319.1878 - 1s/epoch - 21ms/step\n",
      "Epoch 19/20\n",
      "68/68 - 1s - loss: 0.0054 - mse: 0.0054 - mae: 0.0578 - mape: 4593.5259 - val_loss: 0.0192 - val_mse: 0.0192 - val_mae: 0.1064 - val_mape: 475.7199 - 1s/epoch - 20ms/step\n",
      "Epoch 20/20\n",
      "68/68 - 1s - loss: 0.0056 - mse: 0.0056 - mae: 0.0595 - mape: 6095.7065 - val_loss: 0.0242 - val_mse: 0.0242 - val_mae: 0.1240 - val_mape: 769.8776 - 1s/epoch - 20ms/step\n",
      "9/9 [==============================] - 0s 7ms/step\n",
      "Epoch 1/20\n",
      "68/68 - 4s - loss: 0.1098 - mse: 0.1098 - mae: 0.2286 - mape: 15586.6934 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.0981 - val_mape: 347.0635 - 4s/epoch - 61ms/step\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:53:03.845832: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 2s - loss: 0.0229 - mse: 0.0229 - mae: 0.1170 - mape: 18990.2812 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.1131 - val_mape: 884.7284 - 2s/epoch - 23ms/step\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.0167 - mse: 0.0167 - mae: 0.1001 - mape: 6870.8511 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1108 - val_mape: 835.1774 - 1s/epoch - 21ms/step\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.0131 - mse: 0.0131 - mae: 0.0873 - mape: 13662.2129 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1090 - val_mape: 793.9219 - 1s/epoch - 21ms/step\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.0109 - mse: 0.0109 - mae: 0.0797 - mape: 15264.2930 - val_loss: 0.0253 - val_mse: 0.0253 - val_mae: 0.1261 - val_mape: 1118.9170 - 1s/epoch - 20ms/step\n",
      "Epoch 6/20\n",
      "68/68 - 2s - loss: 0.0098 - mse: 0.0098 - mae: 0.0754 - mape: 13782.8975 - val_loss: 0.0257 - val_mse: 0.0257 - val_mae: 0.1275 - val_mape: 1142.3826 - 2s/epoch - 22ms/step\n",
      "Epoch 7/20\n",
      "68/68 - 2s - loss: 0.0085 - mse: 0.0085 - mae: 0.0711 - mape: 5700.4556 - val_loss: 0.0308 - val_mse: 0.0308 - val_mae: 0.1470 - val_mape: 1424.5502 - 2s/epoch - 23ms/step\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.0084 - mse: 0.0084 - mae: 0.0714 - mape: 7393.4951 - val_loss: 0.0271 - val_mse: 0.0271 - val_mae: 0.1349 - val_mape: 1275.3698 - 1s/epoch - 20ms/step\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.0089 - mse: 0.0089 - mae: 0.0739 - mape: 9130.4375 - val_loss: 0.0178 - val_mse: 0.0178 - val_mae: 0.0931 - val_mape: 403.8647 - 1s/epoch - 21ms/step\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.0077 - mse: 0.0077 - mae: 0.0676 - mape: 3101.4836 - val_loss: 0.0150 - val_mse: 0.0150 - val_mae: 0.0898 - val_mape: 524.9104 - 1s/epoch - 19ms/step\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.0067 - mse: 0.0067 - mae: 0.0638 - mape: 3523.1985 - val_loss: 0.0146 - val_mse: 0.0146 - val_mae: 0.0879 - val_mape: 456.7622 - 1s/epoch - 19ms/step\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.0063 - mse: 0.0063 - mae: 0.0620 - mape: 1685.7394 - val_loss: 0.0139 - val_mse: 0.0139 - val_mae: 0.0886 - val_mape: 638.3301 - 1s/epoch - 19ms/step\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.0069 - mse: 0.0069 - mae: 0.0653 - mape: 9095.5127 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0820 - val_mape: 506.9428 - 1s/epoch - 19ms/step\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.0085 - mse: 0.0085 - mae: 0.0724 - mape: 12314.1787 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.0862 - val_mape: 279.6873 - 1s/epoch - 19ms/step\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.0081 - mse: 0.0081 - mae: 0.0709 - mape: 884.1678 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.1124 - val_mape: 707.6721 - 1s/epoch - 19ms/step\n",
      "Epoch 16/20\n",
      "68/68 - 1s - loss: 0.0069 - mse: 0.0069 - mae: 0.0649 - mape: 10838.7334 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0948 - val_mape: 449.4713 - 1s/epoch - 19ms/step\n",
      "Epoch 17/20\n",
      "68/68 - 1s - loss: 0.0053 - mse: 0.0053 - mae: 0.0567 - mape: 6364.4004 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0832 - val_mape: 272.8587 - 1s/epoch - 19ms/step\n",
      "Epoch 18/20\n",
      "68/68 - 1s - loss: 0.0044 - mse: 0.0044 - mae: 0.0515 - mape: 15633.9980 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0856 - val_mape: 390.5208 - 1s/epoch - 19ms/step\n",
      "Epoch 19/20\n",
      "68/68 - 1s - loss: 0.0043 - mse: 0.0043 - mae: 0.0514 - mape: 10917.9502 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0827 - val_mape: 368.1588 - 1s/epoch - 19ms/step\n",
      "Epoch 20/20\n",
      "68/68 - 1s - loss: 0.0041 - mse: 0.0041 - mae: 0.0501 - mape: 12941.5732 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0846 - val_mape: 350.8127 - 1s/epoch - 19ms/step\n",
      "9/9 [==============================] - 0s 9ms/step\n",
      "Epoch 1/20\n",
      "68/68 - 4s - loss: 0.0449 - mse: 0.0449 - mae: 0.1608 - mape: 37772.2109 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.0982 - val_mape: 261.0280 - 4s/epoch - 64ms/step\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:53:35.780937: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n",
      "2023-11-13 12:53:35.781015: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14849713808749010592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 2s - loss: 0.0186 - mse: 0.0186 - mae: 0.1048 - mape: 4885.7173 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0990 - val_mape: 440.1450 - 2s/epoch - 26ms/step\n",
      "Epoch 3/20\n",
      "68/68 - 2s - loss: 0.0131 - mse: 0.0131 - mae: 0.0871 - mape: 1402.5748 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.1009 - val_mape: 538.2029 - 2s/epoch - 25ms/step\n",
      "Epoch 4/20\n",
      "68/68 - 2s - loss: 0.0104 - mse: 0.0104 - mae: 0.0772 - mape: 22352.2090 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1099 - val_mape: 814.5352 - 2s/epoch - 27ms/step\n",
      "Epoch 5/20\n",
      "68/68 - 2s - loss: 0.0099 - mse: 0.0099 - mae: 0.0770 - mape: 9663.7822 - val_loss: 0.0326 - val_mse: 0.0326 - val_mae: 0.1526 - val_mape: 1497.4357 - 2s/epoch - 24ms/step\n",
      "Epoch 6/20\n",
      "68/68 - 2s - loss: 0.0093 - mse: 0.0093 - mae: 0.0747 - mape: 9136.3496 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0989 - val_mape: 439.1716 - 2s/epoch - 24ms/step\n",
      "Epoch 7/20\n",
      "68/68 - 2s - loss: 0.0078 - mse: 0.0078 - mae: 0.0679 - mape: 3781.4150 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1101 - val_mape: 826.2286 - 2s/epoch - 24ms/step\n",
      "Epoch 8/20\n",
      "68/68 - 2s - loss: 0.0072 - mse: 0.0072 - mae: 0.0657 - mape: 1961.9122 - val_loss: 0.0194 - val_mse: 0.0194 - val_mae: 0.0953 - val_mape: 420.8449 - 2s/epoch - 31ms/step\n",
      "Epoch 9/20\n",
      "68/68 - 2s - loss: 0.0068 - mse: 0.0068 - mae: 0.0636 - mape: 1822.6731 - val_loss: 0.0183 - val_mse: 0.0183 - val_mae: 0.0976 - val_mape: 642.6365 - 2s/epoch - 32ms/step\n",
      "Epoch 10/20\n",
      "68/68 - 2s - loss: 0.0066 - mse: 0.0066 - mae: 0.0636 - mape: 15618.8457 - val_loss: 0.0146 - val_mse: 0.0146 - val_mae: 0.0884 - val_mape: 597.1213 - 2s/epoch - 27ms/step\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.0068 - mse: 0.0068 - mae: 0.0645 - mape: 4387.1777 - val_loss: 0.0152 - val_mse: 0.0152 - val_mae: 0.0881 - val_mape: 539.8933 - 1s/epoch - 22ms/step\n",
      "Epoch 12/20\n",
      "68/68 - 2s - loss: 0.0073 - mse: 0.0073 - mae: 0.0670 - mape: 4820.3325 - val_loss: 0.0140 - val_mse: 0.0140 - val_mae: 0.0831 - val_mape: 283.2944 - 2s/epoch - 29ms/step\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.0089 - mse: 0.0089 - mae: 0.0750 - mape: 14440.0156 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.1034 - val_mape: 437.7265 - 1s/epoch - 21ms/step\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.0105 - mse: 0.0105 - mae: 0.0819 - mape: 5845.5928 - val_loss: 0.0236 - val_mse: 0.0236 - val_mae: 0.1181 - val_mape: 754.3259 - 1s/epoch - 20ms/step\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.0095 - mse: 0.0095 - mae: 0.0774 - mape: 11124.5488 - val_loss: 0.0144 - val_mse: 0.0144 - val_mae: 0.0882 - val_mape: 424.7601 - 1s/epoch - 21ms/step\n",
      "Epoch 16/20\n",
      "68/68 - 2s - loss: 0.0073 - mse: 0.0073 - mae: 0.0669 - mape: 11751.7617 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0794 - val_mape: 286.4151 - 2s/epoch - 23ms/step\n",
      "Epoch 17/20\n",
      "68/68 - 1s - loss: 0.0055 - mse: 0.0055 - mae: 0.0579 - mape: 5348.6729 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0801 - val_mape: 320.8626 - 1s/epoch - 22ms/step\n",
      "Epoch 18/20\n",
      "68/68 - 2s - loss: 0.0045 - mse: 0.0045 - mae: 0.0528 - mape: 5254.3882 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0786 - val_mape: 335.4940 - 2s/epoch - 25ms/step\n",
      "Epoch 19/20\n",
      "68/68 - 1s - loss: 0.0040 - mse: 0.0040 - mae: 0.0497 - mape: 2448.2966 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0807 - val_mape: 419.6967 - 1s/epoch - 21ms/step\n",
      "Epoch 20/20\n",
      "68/68 - 2s - loss: 0.0037 - mse: 0.0037 - mae: 0.0479 - mape: 10233.8369 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0802 - val_mape: 290.4543 - 2s/epoch - 24ms/step\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:54:08.862554: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14849713808749010592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "68/68 - 5s - loss: 0.0730 - mse: 0.0730 - mae: 0.1926 - mape: 34335.7109 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.0982 - val_mape: 370.6967 - 5s/epoch - 67ms/step\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:54:13.892251: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n",
      "2023-11-13 12:54:13.892334: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14849713808749010592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 1s - loss: 0.0204 - mse: 0.0204 - mae: 0.1099 - mape: 8762.6914 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0996 - val_mape: 476.2711 - 1s/epoch - 19ms/step\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.0150 - mse: 0.0150 - mae: 0.0938 - mape: 17263.4434 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.1058 - val_mape: 707.3666 - 1s/epoch - 19ms/step\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.0116 - mse: 0.0116 - mae: 0.0821 - mape: 3250.9780 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.1127 - val_mape: 876.6499 - 1s/epoch - 19ms/step\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.0099 - mse: 0.0099 - mae: 0.0767 - mape: 4383.1128 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1044 - val_mape: 667.6744 - 1s/epoch - 20ms/step\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.0088 - mse: 0.0088 - mae: 0.0717 - mape: 1227.7538 - val_loss: 0.0238 - val_mse: 0.0238 - val_mae: 0.1192 - val_mape: 1003.4296 - 1s/epoch - 20ms/step\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.0081 - mse: 0.0081 - mae: 0.0690 - mape: 2288.7139 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.1070 - val_mape: 751.8574 - 1s/epoch - 19ms/step\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.0080 - mse: 0.0080 - mae: 0.0685 - mape: 3700.9905 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.1092 - val_mape: 829.9181 - 1s/epoch - 20ms/step\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.0084 - mse: 0.0084 - mae: 0.0718 - mape: 4693.7007 - val_loss: 0.0306 - val_mse: 0.0306 - val_mae: 0.1500 - val_mape: 1535.9663 - 1s/epoch - 22ms/step\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.0078 - mse: 0.0078 - mae: 0.0692 - mape: 3089.0601 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0876 - val_mape: 236.7548 - 1s/epoch - 22ms/step\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.0072 - mse: 0.0072 - mae: 0.0660 - mape: 12894.2529 - val_loss: 0.0139 - val_mse: 0.0139 - val_mae: 0.0840 - val_mape: 428.9737 - 1s/epoch - 21ms/step\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.0065 - mse: 0.0065 - mae: 0.0624 - mape: 13627.5000 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0830 - val_mape: 502.3721 - 1s/epoch - 20ms/step\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.0060 - mse: 0.0060 - mae: 0.0606 - mape: 12836.0420 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0817 - val_mape: 456.1197 - 1s/epoch - 20ms/step\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.0063 - mse: 0.0063 - mae: 0.0625 - mape: 5128.2319 - val_loss: 0.0142 - val_mse: 0.0142 - val_mae: 0.0862 - val_mape: 262.3138 - 1s/epoch - 19ms/step\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.0085 - mse: 0.0085 - mae: 0.0724 - mape: 3249.0371 - val_loss: 0.0191 - val_mse: 0.0191 - val_mae: 0.1041 - val_mape: 499.2389 - 1s/epoch - 18ms/step\n",
      "Epoch 16/20\n",
      "68/68 - 1s - loss: 0.0085 - mse: 0.0085 - mae: 0.0732 - mape: 9192.8896 - val_loss: 0.0258 - val_mse: 0.0258 - val_mae: 0.1251 - val_mape: 745.6603 - 1s/epoch - 19ms/step\n",
      "Epoch 17/20\n",
      "68/68 - 1s - loss: 0.0071 - mse: 0.0071 - mae: 0.0664 - mape: 2158.2449 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0931 - val_mape: 365.8310 - 1s/epoch - 19ms/step\n",
      "Epoch 18/20\n",
      "68/68 - 1s - loss: 0.0057 - mse: 0.0057 - mae: 0.0593 - mape: 4425.1860 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0837 - val_mape: 330.9920 - 1s/epoch - 19ms/step\n",
      "Epoch 19/20\n",
      "68/68 - 1s - loss: 0.0047 - mse: 0.0047 - mae: 0.0541 - mape: 4146.3203 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0841 - val_mape: 384.4582 - 1s/epoch - 19ms/step\n",
      "Epoch 20/20\n",
      "68/68 - 1s - loss: 0.0044 - mse: 0.0044 - mae: 0.0522 - mape: 3431.7341 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0834 - val_mape: 511.6073 - 1s/epoch - 18ms/step\n",
      "9/9 [==============================] - 0s 9ms/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:54:44.591139: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n",
      "2023-11-13 12:54:44.591211: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14849713808749010592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 4s - loss: 0.0490 - mse: 0.0490 - mae: 0.1644 - mape: 26294.9043 - val_loss: 0.0222 - val_mse: 0.0222 - val_mae: 0.0988 - val_mape: 200.0979 - 4s/epoch - 59ms/step\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.0186 - mse: 0.0186 - mae: 0.1050 - mape: 10036.1299 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.0983 - val_mape: 248.8860 - 1s/epoch - 22ms/step\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.0139 - mse: 0.0139 - mae: 0.0900 - mape: 12848.6055 - val_loss: 0.0248 - val_mse: 0.0248 - val_mae: 0.1041 - val_mape: 175.6963 - 1s/epoch - 20ms/step\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.0108 - mse: 0.0108 - mae: 0.0794 - mape: 3368.4150 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.0992 - val_mape: 168.8995 - 1s/epoch - 20ms/step\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.0100 - mse: 0.0100 - mae: 0.0765 - mape: 2087.0620 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1000 - val_mape: 132.9371 - 1s/epoch - 20ms/step\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.0091 - mse: 0.0091 - mae: 0.0734 - mape: 2046.3824 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.0982 - val_mape: 245.9231 - 1s/epoch - 19ms/step\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.0097 - mse: 0.0097 - mae: 0.0767 - mape: 2079.3584 - val_loss: 0.0300 - val_mse: 0.0300 - val_mae: 0.1443 - val_mape: 1385.2106 - 1s/epoch - 18ms/step\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.0106 - mse: 0.0106 - mae: 0.0809 - mape: 2047.7990 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0957 - val_mape: 313.6096 - 1s/epoch - 19ms/step\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.0078 - mse: 0.0078 - mae: 0.0678 - mape: 967.1202 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0943 - val_mape: 141.5684 - 1s/epoch - 19ms/step\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.0066 - mse: 0.0066 - mae: 0.0628 - mape: 13407.7695 - val_loss: 0.0152 - val_mse: 0.0152 - val_mae: 0.0860 - val_mape: 200.5290 - 1s/epoch - 19ms/step\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.0060 - mse: 0.0060 - mae: 0.0600 - mape: 873.6854 - val_loss: 0.0134 - val_mse: 0.0134 - val_mae: 0.0836 - val_mape: 275.1982 - 1s/epoch - 19ms/step\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.0053 - mse: 0.0053 - mae: 0.0569 - mape: 6026.0024 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0840 - val_mape: 439.6027 - 1s/epoch - 19ms/step\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.0054 - mse: 0.0054 - mae: 0.0576 - mape: 3091.7400 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0820 - val_mape: 430.5801 - 1s/epoch - 19ms/step\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.0054 - mse: 0.0054 - mae: 0.0577 - mape: 5267.5713 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0894 - val_mape: 434.9667 - 1s/epoch - 19ms/step\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.0071 - mse: 0.0071 - mae: 0.0667 - mape: 15502.1162 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0831 - val_mape: 276.2319 - 1s/epoch - 20ms/step\n",
      "Epoch 16/20\n",
      "68/68 - 1s - loss: 0.0090 - mse: 0.0090 - mae: 0.0759 - mape: 2684.8340 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0822 - val_mape: 398.3054 - 1s/epoch - 19ms/step\n",
      "Epoch 17/20\n",
      "68/68 - 1s - loss: 0.0108 - mse: 0.0108 - mae: 0.0834 - mape: 2717.5979 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.1047 - val_mape: 555.7731 - 1s/epoch - 19ms/step\n",
      "Epoch 18/20\n",
      "68/68 - 1s - loss: 0.0102 - mse: 0.0102 - mae: 0.0811 - mape: 12664.0273 - val_loss: 0.0177 - val_mse: 0.0177 - val_mae: 0.1001 - val_mape: 572.6440 - 1s/epoch - 19ms/step\n",
      "Epoch 19/20\n",
      "68/68 - 1s - loss: 0.0069 - mse: 0.0069 - mae: 0.0654 - mape: 10807.6826 - val_loss: 0.0148 - val_mse: 0.0148 - val_mae: 0.0914 - val_mape: 364.7339 - 1s/epoch - 21ms/step\n",
      "Epoch 20/20\n",
      "68/68 - 1s - loss: 0.0051 - mse: 0.0051 - mae: 0.0564 - mape: 2492.3201 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0947 - val_mape: 327.7892 - 1s/epoch - 21ms/step\n",
      "9/9 [==============================] - 0s 9ms/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:55:15.677663: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 4s - loss: 0.0577 - mse: 0.0577 - mae: 0.1798 - mape: 7944.7671 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0997 - val_mape: 480.5628 - 4s/epoch - 59ms/step\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.0193 - mse: 0.0193 - mae: 0.1065 - mape: 13892.4980 - val_loss: 0.0210 - val_mse: 0.0210 - val_mae: 0.1034 - val_mape: 632.5604 - 1s/epoch - 20ms/step\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.0137 - mse: 0.0137 - mae: 0.0893 - mape: 17899.6191 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0989 - val_mape: 431.7386 - 1s/epoch - 19ms/step\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.0108 - mse: 0.0108 - mae: 0.0788 - mape: 732.4716 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.1026 - val_mape: 605.7069 - 1s/epoch - 20ms/step\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.0097 - mse: 0.0097 - mae: 0.0752 - mape: 8175.0356 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.1055 - val_mape: 700.5739 - 1s/epoch - 19ms/step\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.0089 - mse: 0.0089 - mae: 0.0723 - mape: 24314.8047 - val_loss: 0.0252 - val_mse: 0.0252 - val_mae: 0.1255 - val_mape: 1111.1830 - 1s/epoch - 19ms/step\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.0089 - mse: 0.0089 - mae: 0.0738 - mape: 2594.9670 - val_loss: 0.0214 - val_mse: 0.0214 - val_mae: 0.0975 - val_mape: 256.5891 - 1s/epoch - 19ms/step\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.0076 - mse: 0.0076 - mae: 0.0672 - mape: 10553.9766 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.1075 - val_mape: 790.9040 - 1s/epoch - 19ms/step\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.0064 - mse: 0.0064 - mae: 0.0618 - mape: 6661.8311 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.1078 - val_mape: 869.3651 - 1s/epoch - 20ms/step\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.0060 - mse: 0.0060 - mae: 0.0599 - mape: 14839.0166 - val_loss: 0.0154 - val_mse: 0.0154 - val_mae: 0.0932 - val_mape: 626.4354 - 1s/epoch - 20ms/step\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.0056 - mse: 0.0056 - mae: 0.0583 - mape: 2511.3467 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0824 - val_mape: 362.0519 - 1s/epoch - 19ms/step\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.0052 - mse: 0.0052 - mae: 0.0563 - mape: 1616.9893 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0803 - val_mape: 319.4837 - 1s/epoch - 19ms/step\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.0053 - mse: 0.0053 - mae: 0.0566 - mape: 2850.9243 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0800 - val_mape: 472.0151 - 1s/epoch - 18ms/step\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.0067 - mse: 0.0067 - mae: 0.0648 - mape: 14940.0928 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0832 - val_mape: 539.8270 - 1s/epoch - 19ms/step\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.0093 - mse: 0.0093 - mae: 0.0778 - mape: 12095.5537 - val_loss: 0.0183 - val_mse: 0.0183 - val_mae: 0.1012 - val_mape: 451.8018 - 1s/epoch - 18ms/step\n",
      "Epoch 16/20\n",
      "68/68 - 1s - loss: 0.0118 - mse: 0.0118 - mae: 0.0875 - mape: 10246.5322 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1189 - val_mape: 769.1495 - 1s/epoch - 19ms/step\n",
      "Epoch 17/20\n",
      "68/68 - 1s - loss: 0.0087 - mse: 0.0087 - mae: 0.0739 - mape: 12948.0244 - val_loss: 0.0141 - val_mse: 0.0141 - val_mae: 0.0882 - val_mape: 297.1888 - 1s/epoch - 18ms/step\n",
      "Epoch 18/20\n",
      "68/68 - 1s - loss: 0.0056 - mse: 0.0056 - mae: 0.0587 - mape: 1451.5284 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0829 - val_mape: 273.8261 - 1s/epoch - 19ms/step\n",
      "Epoch 19/20\n",
      "68/68 - 1s - loss: 0.0047 - mse: 0.0047 - mae: 0.0534 - mape: 5456.0825 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0829 - val_mape: 349.3041 - 1s/epoch - 19ms/step\n",
      "Epoch 20/20\n",
      "68/68 - 1s - loss: 0.0042 - mse: 0.0042 - mae: 0.0507 - mape: 5669.3784 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0837 - val_mape: 335.0851 - 1s/epoch - 20ms/step\n",
      "9/9 [==============================] - 0s 9ms/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:55:45.944992: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4758399812689065096\n",
      "2023-11-13 12:55:45.945071: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14849713808749010592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 4s - loss: 0.0524 - mse: 0.0524 - mae: 0.1688 - mape: 48021.7969 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0989 - val_mape: 431.7624 - 4s/epoch - 58ms/step\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.0196 - mse: 0.0196 - mae: 0.1079 - mape: 12646.4922 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0990 - val_mape: 437.5881 - 1s/epoch - 19ms/step\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.0136 - mse: 0.0136 - mae: 0.0889 - mape: 3120.2908 - val_loss: 0.0223 - val_mse: 0.0223 - val_mae: 0.0989 - val_mape: 189.6442 - 1s/epoch - 19ms/step\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.0109 - mse: 0.0109 - mae: 0.0793 - mape: 8516.5244 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.0981 - val_mape: 291.4493 - 1s/epoch - 18ms/step\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.0100 - mse: 0.0100 - mae: 0.0764 - mape: 9417.3145 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0996 - val_mape: 476.3716 - 1s/epoch - 18ms/step\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.0092 - mse: 0.0092 - mae: 0.0737 - mape: 3028.6331 - val_loss: 0.0214 - val_mse: 0.0214 - val_mae: 0.1067 - val_mape: 736.5529 - 1s/epoch - 18ms/step\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.0108 - mse: 0.0108 - mae: 0.0823 - mape: 14307.6270 - val_loss: 0.0248 - val_mse: 0.0248 - val_mae: 0.1044 - val_mape: 201.4645 - 1s/epoch - 19ms/step\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.0087 - mse: 0.0087 - mae: 0.0723 - mape: 13635.7275 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.0978 - val_mape: 492.3977 - 1s/epoch - 20ms/step\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.0070 - mse: 0.0070 - mae: 0.0647 - mape: 5797.5757 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0953 - val_mape: 543.5643 - 1s/epoch - 19ms/step\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.0062 - mse: 0.0062 - mae: 0.0610 - mape: 2590.6829 - val_loss: 0.0150 - val_mse: 0.0150 - val_mae: 0.0877 - val_mape: 324.8189 - 1s/epoch - 19ms/step\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.0061 - mse: 0.0061 - mae: 0.0608 - mape: 5405.0034 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0819 - val_mape: 265.3970 - 1s/epoch - 21ms/step\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.0057 - mse: 0.0057 - mae: 0.0586 - mape: 5287.1851 - val_loss: 0.0138 - val_mse: 0.0138 - val_mae: 0.0861 - val_mape: 422.6536 - 1s/epoch - 19ms/step\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.0054 - mse: 0.0054 - mae: 0.0574 - mape: 1436.1538 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0816 - val_mape: 413.1425 - 1s/epoch - 19ms/step\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.0060 - mse: 0.0060 - mae: 0.0613 - mape: 10464.6299 - val_loss: 0.0130 - val_mse: 0.0130 - val_mae: 0.0826 - val_mape: 560.7013 - 1s/epoch - 19ms/step\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.0079 - mse: 0.0079 - mae: 0.0701 - mape: 7937.0562 - val_loss: 0.0132 - val_mse: 0.0132 - val_mae: 0.0867 - val_mape: 383.9270 - 1s/epoch - 19ms/step\n",
      "Epoch 16/20\n",
      "68/68 - 1s - loss: 0.0100 - mse: 0.0100 - mae: 0.0796 - mape: 19087.9473 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0911 - val_mape: 524.9572 - 1s/epoch - 19ms/step\n",
      "Epoch 17/20\n",
      "68/68 - 1s - loss: 0.0099 - mse: 0.0099 - mae: 0.0798 - mape: 10097.4326 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.1075 - val_mape: 733.6263 - 1s/epoch - 19ms/step\n",
      "Epoch 18/20\n",
      "68/68 - 1s - loss: 0.0081 - mse: 0.0081 - mae: 0.0716 - mape: 15196.7031 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0937 - val_mape: 600.6916 - 1s/epoch - 21ms/step\n",
      "Epoch 19/20\n",
      "68/68 - 1s - loss: 0.0060 - mse: 0.0060 - mae: 0.0607 - mape: 2679.4651 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0841 - val_mape: 544.2450 - 1s/epoch - 22ms/step\n",
      "Epoch 20/20\n",
      "68/68 - 1s - loss: 0.0048 - mse: 0.0048 - mae: 0.0542 - mape: 9649.3916 - val_loss: 0.0122 - val_mse: 0.0122 - val_mae: 0.0806 - val_mape: 362.9627 - 1s/epoch - 19ms/step\n",
      "9/9 [==============================] - 0s 9ms/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:56:16.741406: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14849713808749010592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 4s - loss: 0.1253 - mse: 0.1253 - mae: 0.2388 - mape: 10975.4932 - val_loss: 0.0236 - val_mse: 0.0236 - val_mae: 0.1014 - val_mape: 105.7062 - 4s/epoch - 62ms/step\n",
      "Epoch 2/20\n",
      "68/68 - 1s - loss: 0.0227 - mse: 0.0227 - mae: 0.1167 - mape: 13979.4219 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1015 - val_mape: 107.8383 - 1s/epoch - 20ms/step\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.0173 - mse: 0.0173 - mae: 0.1018 - mape: 2235.7063 - val_loss: 0.0233 - val_mse: 0.0233 - val_mae: 0.1007 - val_mape: 112.1908 - 1s/epoch - 19ms/step\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.0133 - mse: 0.0133 - mae: 0.0894 - mape: 15986.1670 - val_loss: 0.0239 - val_mse: 0.0239 - val_mae: 0.1021 - val_mape: 125.1423 - 1s/epoch - 20ms/step\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.0109 - mse: 0.0109 - mae: 0.0805 - mape: 3933.8306 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1017 - val_mape: 113.5774 - 1s/epoch - 20ms/step\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.0093 - mse: 0.0093 - mae: 0.0742 - mape: 12114.0352 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.0992 - val_mape: 165.8779 - 1s/epoch - 20ms/step\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.0081 - mse: 0.0081 - mae: 0.0693 - mape: 22536.9512 - val_loss: 0.0214 - val_mse: 0.0214 - val_mae: 0.0977 - val_mape: 277.3127 - 1s/epoch - 20ms/step\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.0073 - mse: 0.0073 - mae: 0.0660 - mape: 848.7849 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.0964 - val_mape: 366.7784 - 1s/epoch - 20ms/step\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.0068 - mse: 0.0068 - mae: 0.0640 - mape: 9639.3281 - val_loss: 0.0182 - val_mse: 0.0182 - val_mae: 0.0951 - val_mape: 499.3350 - 1s/epoch - 19ms/step\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.0062 - mse: 0.0062 - mae: 0.0618 - mape: 10577.7012 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0878 - val_mape: 309.3990 - 1s/epoch - 19ms/step\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.0060 - mse: 0.0060 - mae: 0.0608 - mape: 7136.6914 - val_loss: 0.0144 - val_mse: 0.0144 - val_mae: 0.0868 - val_mape: 493.5524 - 1s/epoch - 20ms/step\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.0060 - mse: 0.0060 - mae: 0.0609 - mape: 9666.1973 - val_loss: 0.0146 - val_mse: 0.0146 - val_mae: 0.0920 - val_mape: 694.7739 - 1s/epoch - 20ms/step\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.0068 - mse: 0.0068 - mae: 0.0656 - mape: 3452.4185 - val_loss: 0.0143 - val_mse: 0.0143 - val_mae: 0.0869 - val_mape: 370.3336 - 1s/epoch - 19ms/step\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.0098 - mse: 0.0098 - mae: 0.0799 - mape: 15766.7314 - val_loss: 0.0141 - val_mse: 0.0141 - val_mae: 0.0870 - val_mape: 336.6827 - 1s/epoch - 19ms/step\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.0077 - mse: 0.0077 - mae: 0.0693 - mape: 10363.7539 - val_loss: 0.0126 - val_mse: 0.0126 - val_mae: 0.0817 - val_mape: 414.4552 - 1s/epoch - 19ms/step\n",
      "Epoch 16/20\n",
      "68/68 - 1s - loss: 0.0050 - mse: 0.0050 - mae: 0.0550 - mape: 9771.0635 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0820 - val_mape: 323.3398 - 1s/epoch - 19ms/step\n",
      "Epoch 17/20\n",
      "68/68 - 1s - loss: 0.0047 - mse: 0.0047 - mae: 0.0534 - mape: 10149.2930 - val_loss: 0.0135 - val_mse: 0.0135 - val_mae: 0.0850 - val_mape: 291.9381 - 1s/epoch - 22ms/step\n",
      "Epoch 18/20\n",
      "68/68 - 1s - loss: 0.0048 - mse: 0.0048 - mae: 0.0546 - mape: 14065.7598 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0884 - val_mape: 402.1189 - 1s/epoch - 20ms/step\n",
      "Epoch 19/20\n",
      "68/68 - 1s - loss: 0.0066 - mse: 0.0066 - mae: 0.0655 - mape: 20001.0156 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0919 - val_mape: 784.9581 - 1s/epoch - 19ms/step\n",
      "Epoch 20/20\n",
      "68/68 - 1s - loss: 0.0067 - mse: 0.0067 - mae: 0.0648 - mape: 3490.3538 - val_loss: 0.0128 - val_mse: 0.0128 - val_mae: 0.0830 - val_mape: 344.5550 - 1s/epoch - 19ms/step\n",
      "9/9 [==============================] - 0s 9ms/step\n",
      "Epoch 1/20\n",
      "68/68 - 4s - loss: 0.1083 - mse: 0.1083 - mae: 0.2302 - mape: 9598.1582 - val_loss: 0.0216 - val_mse: 0.0216 - val_mae: 0.0981 - val_mape: 278.7565 - 4s/epoch - 61ms/step\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:56:48.423511: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14849713808749010592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 1s - loss: 0.0224 - mse: 0.0224 - mae: 0.1153 - mape: 7239.0337 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1109 - val_mape: 837.1691 - 1s/epoch - 20ms/step\n",
      "Epoch 3/20\n",
      "68/68 - 1s - loss: 0.0171 - mse: 0.0171 - mae: 0.1010 - mape: 17583.5039 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.1028 - val_mape: 613.9725 - 1s/epoch - 20ms/step\n",
      "Epoch 4/20\n",
      "68/68 - 1s - loss: 0.0132 - mse: 0.0132 - mae: 0.0885 - mape: 8419.8047 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1107 - val_mape: 832.9368 - 1s/epoch - 19ms/step\n",
      "Epoch 5/20\n",
      "68/68 - 1s - loss: 0.0111 - mse: 0.0111 - mae: 0.0809 - mape: 2609.2063 - val_loss: 0.0216 - val_mse: 0.0216 - val_mae: 0.1078 - val_mape: 763.2318 - 1s/epoch - 20ms/step\n",
      "Epoch 6/20\n",
      "68/68 - 1s - loss: 0.0097 - mse: 0.0097 - mae: 0.0759 - mape: 5382.7769 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1110 - val_mape: 839.2021 - 1s/epoch - 20ms/step\n",
      "Epoch 7/20\n",
      "68/68 - 1s - loss: 0.0088 - mse: 0.0088 - mae: 0.0723 - mape: 11757.5615 - val_loss: 0.0238 - val_mse: 0.0238 - val_mae: 0.1199 - val_mape: 1016.7537 - 1s/epoch - 19ms/step\n",
      "Epoch 8/20\n",
      "68/68 - 1s - loss: 0.0078 - mse: 0.0078 - mae: 0.0682 - mape: 1084.9587 - val_loss: 0.0222 - val_mse: 0.0222 - val_mae: 0.1136 - val_mape: 912.8597 - 1s/epoch - 19ms/step\n",
      "Epoch 9/20\n",
      "68/68 - 1s - loss: 0.0075 - mse: 0.0075 - mae: 0.0671 - mape: 950.9225 - val_loss: 0.0192 - val_mse: 0.0192 - val_mae: 0.1026 - val_mape: 722.2596 - 1s/epoch - 19ms/step\n",
      "Epoch 10/20\n",
      "68/68 - 1s - loss: 0.0070 - mse: 0.0070 - mae: 0.0648 - mape: 9445.6758 - val_loss: 0.0171 - val_mse: 0.0171 - val_mae: 0.0971 - val_mape: 612.4295 - 1s/epoch - 19ms/step\n",
      "Epoch 11/20\n",
      "68/68 - 1s - loss: 0.0079 - mse: 0.0079 - mae: 0.0701 - mape: 4860.2900 - val_loss: 0.0152 - val_mse: 0.0152 - val_mae: 0.0867 - val_mape: 297.1735 - 1s/epoch - 19ms/step\n",
      "Epoch 12/20\n",
      "68/68 - 1s - loss: 0.0083 - mse: 0.0083 - mae: 0.0722 - mape: 4126.0229 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0974 - val_mape: 604.6508 - 1s/epoch - 19ms/step\n",
      "Epoch 13/20\n",
      "68/68 - 1s - loss: 0.0096 - mse: 0.0096 - mae: 0.0778 - mape: 12866.0986 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0929 - val_mape: 414.7428 - 1s/epoch - 19ms/step\n",
      "Epoch 14/20\n",
      "68/68 - 1s - loss: 0.0085 - mse: 0.0085 - mae: 0.0720 - mape: 19214.5938 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0824 - val_mape: 651.4483 - 1s/epoch - 19ms/step\n",
      "Epoch 15/20\n",
      "68/68 - 1s - loss: 0.0088 - mse: 0.0088 - mae: 0.0744 - mape: 13860.3955 - val_loss: 0.0123 - val_mse: 0.0123 - val_mae: 0.0827 - val_mape: 451.5923 - 1s/epoch - 19ms/step\n",
      "Epoch 16/20\n",
      "68/68 - 1s - loss: 0.0092 - mse: 0.0092 - mae: 0.0761 - mape: 4929.2773 - val_loss: 0.0256 - val_mse: 0.0256 - val_mae: 0.1287 - val_mape: 1032.8557 - 1s/epoch - 19ms/step\n",
      "Epoch 17/20\n",
      "68/68 - 1s - loss: 0.0074 - mse: 0.0074 - mae: 0.0675 - mape: 16685.5156 - val_loss: 0.0190 - val_mse: 0.0190 - val_mae: 0.1071 - val_mape: 781.5198 - 1s/epoch - 19ms/step\n",
      "Epoch 18/20\n",
      "68/68 - 1s - loss: 0.0057 - mse: 0.0057 - mae: 0.0593 - mape: 2994.6609 - val_loss: 0.0148 - val_mse: 0.0148 - val_mae: 0.0912 - val_mape: 640.2874 - 1s/epoch - 19ms/step\n",
      "Epoch 19/20\n",
      "68/68 - 1s - loss: 0.0050 - mse: 0.0050 - mae: 0.0555 - mape: 6521.8911 - val_loss: 0.0140 - val_mse: 0.0140 - val_mae: 0.0884 - val_mape: 487.7404 - 1s/epoch - 20ms/step\n",
      "Epoch 20/20\n",
      "68/68 - 1s - loss: 0.0047 - mse: 0.0047 - mae: 0.0535 - mape: 10092.2119 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0865 - val_mape: 551.0181 - 1s/epoch - 19ms/step\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 12:57:14.544901: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14849713808749010592\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_667371/1379236160.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prediction_iteration_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mcorr_coefficient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpearson_correlation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mcorr_per_iteration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_coefficient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mdf_test_10folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test_10folds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_MPRA/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "df_test_10folds  = pd.DataFrame()\n",
    "corr_list = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    \n",
    "    input_path_train = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_train.csv\"\n",
    "    input_path_valid = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_validation.csv\"\n",
    "    input_path_test = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_test.csv\"\n",
    "   \n",
    "    df_test = pd.read_csv(input_path_test)\n",
    "    df_test[\"fold\"] = str(i)\n",
    "    corr_per_iteration = []\n",
    "    # Get first item of the dataset to get the shape of the input data\n",
    "    for element in data_reader(input_path_train):\n",
    "        input_shape = element[0].shape\n",
    "        \n",
    "    for iteration in range(1,11):\n",
    "        inputs = Input(shape=(input_shape[1],input_shape[2]), name=\"inputs\")\n",
    "        layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "        layer = Dropout(0.3)(layer)\n",
    "        layer = BatchNormalization()(layer)\n",
    "        layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "        layer = BatchNormalization()(layer)\n",
    "        layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "        layer = Dropout(0.3)(layer)\n",
    "        layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "        layer = BatchNormalization()(layer)\n",
    "        layer = Dropout(0.3)(layer)\n",
    "        layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "        layer = BatchNormalization()(layer)\n",
    "        layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "        layer = Dropout(0.3)(layer)\n",
    "        layer = Flatten()(layer)\n",
    "        layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "        layer = Dropout(0.3)(layer)\n",
    "        layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "        predictions = Dense(1, activation='linear')(layer)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=predictions)\n",
    "        model.compile(optimizer=\"adam\",\n",
    "                    loss=\"mean_squared_error\",\n",
    "                    metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "                    )\n",
    "\n",
    "        history=model.fit(data_reader(input_path_train, batch_size=100),\n",
    "                                epochs=20,\n",
    "                                validation_data=data_reader(input_path_valid,batch_size=100),\n",
    "                                callbacks=None,\n",
    "                                verbose=2)\n",
    "\n",
    "        predicted = model.predict(data_reader(input_path_test,\n",
    "                                                    batch_size=100))\n",
    "\n",
    "        test_data = data_reader(input_path_test,batch_size=100)\n",
    "        test_tensor = X = np.empty(shape=[0,1])\n",
    "        for batch in test_data:\n",
    "            test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "        df_test[\"prediction_iteration_\"+str(iteration)] = predicted\n",
    "        \n",
    "                \n",
    "        corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)\n",
    "        corr_per_iteration.append(corr_coefficient)\n",
    "    \n",
    "    df_test_10folds = df_test_10folds.append(df_test, ignore_index=True)\n",
    "    print(df_test_10folds)\n",
    "        \n",
    "    corr_ensemble = np.mean(corr_per_iteration)\n",
    "    corr_list.append(corr_ensemble)\n",
    "\n",
    "df_test_10folds.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/LibA_wide_pivot_state3_test_predicted_cv10fold_ensemble.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
