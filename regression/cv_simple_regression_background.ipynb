{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "921b4b40",
   "metadata": {},
   "source": [
    "# MPRA regression of background samples with K-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb96b1",
   "metadata": {},
   "source": [
    "### Environment \n",
    "The next chunk contains the commands necessary to install the environment required to run this jupyter notebook\n",
    "Skip this chunk if the installation was previously done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b76b192d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/felix/anaconda3/envs/tensorflow_2_gpu\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    pandas-2.1.1               |   py39h1128e8f_0        13.5 MB  anaconda\n",
      "    python-tzdata-2023.3       |     pyhd3eb1b0_0         149 KB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        13.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  python-tzdata      anaconda/noarch::python-tzdata-2023.3-pyhd3eb1b0_0 None\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  pandas                               1.5.2-py39h417a72b_0 --> 2.1.1-py39h1128e8f_0 None\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? \n",
      "\n",
      "Downloading and Extracting Packages\n",
      "python-tzdata-2023.3 | 149 KB    | ########## | 100% \n",
      "pandas-2.1.1         | 13.5 MB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/felix/anaconda3/envs/tf_MPRA\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.9.7\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.08.22 |       h06a4308_0         123 KB\n",
      "    openssl-1.1.1w             |       h7f8727e_0         3.7 MB\n",
      "    pip-23.3                   |   py39h06a4308_0         2.6 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         6.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main None\n",
      "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu None\n",
      "  ca-certificates    pkgs/main/linux-64::ca-certificates-2023.08.22-h06a4308_0 None\n",
      "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1 None\n",
      "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2 None\n",
      "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 None\n",
      "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 None\n",
      "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 None\n",
      "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 None\n",
      "  openssl            pkgs/main/linux-64::openssl-1.1.1w-h7f8727e_0 None\n",
      "  pip                pkgs/main/linux-64::pip-23.3-py39h06a4308_0 None\n",
      "  python             pkgs/main/linux-64::python-3.9.7-h12debd9_1 None\n",
      "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 None\n",
      "  setuptools         pkgs/main/linux-64::setuptools-68.0.0-py39h06a4308_0 None\n",
      "  sqlite             pkgs/main/linux-64::sqlite-3.41.2-h5eee18b_0 None\n",
      "  tk                 pkgs/main/linux-64::tk-8.6.12-h1ccaba5_0 None\n",
      "  tzdata             pkgs/main/noarch::tzdata-2023c-h04d1e81_0 None\n",
      "  wheel              pkgs/main/linux-64::wheel-0.41.2-py39h06a4308_0 None\n",
      "  xz                 pkgs/main/linux-64::xz-5.4.2-h5eee18b_0 None\n",
      "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_0 None\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? Invalid choice: conda activate tf_mpra\n",
      "Proceed ([y]/n)? Invalid choice: pip install tensorflow[and-cuda]\n",
      "Proceed ([y]/n)? Invalid choice: conda install -c anaconda ipykernel\n",
      "Proceed ([y]/n)? Invalid choice: conda install -c anaconda pandas\n",
      "Proceed ([y]/n)? \n",
      "\n",
      "Downloading and Extracting Packages\n",
      "openssl-1.1.1w       | 3.7 MB    | ########## | 100% \n",
      "pip-23.3             | 2.6 MB    | ########## | 100% \n",
      "ca-certificates-2023 | 123 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate tf_MPRA\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "Retrieving notices: ...working... done\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "conda create --name tf_MPRA python=3.9.7\n",
    "conda activate tf_MPRA\n",
    "pip install tensorflow[and-cuda]\n",
    "conda install -c anaconda ipykernel \n",
    "conda install -c anaconda pandas\n",
    "conda install -c anaconda numpy\n",
    "conda install -c anaconda scikit-learn \n",
    "conda install -c conda-forge matplotlib\n",
    "\n",
    "# After installation if you are using VSCODE to run the notebook you have to close it and re-open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b66a7a",
   "metadata": {},
   "source": [
    "### Library imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c1f9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import getopt\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Input, Masking, Lambda, concatenate, Bidirectional, Dense, Dropout, Flatten, Conv1D,BatchNormalization,  MaxPooling1D, Bidirectional, GRU, TimeDistributed\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37317fa",
   "metadata": {},
   "source": [
    "### Input ingestion\n",
    "\n",
    "Here we define the methods to read and ingest data and we initialize the random seed.\n",
    "\n",
    "Since we are processing the background the vocabulary is comprised of lower case nucleotides.\n",
    "\n",
    "The upper cases (where the motif is), will be encoded as a zero-like vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a0aec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337) # for reproducibility\n",
    "\n",
    "# Lower case vocabulary\n",
    "vocab = [\"a\", \"c\", \"g\", \"t\"]\n",
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets=1)\n",
    "\n",
    "# These are the defaults of the data reader method \n",
    "# (each column in the ingested csv must be initialized with the right data type, otherwise the data ingestion fails )\n",
    "defs = [0.] * 1 + [tf.constant([], dtype=\"string\")] + [tf.constant([], dtype=\"string\")]\n",
    "\n",
    "\n",
    "def data_reader(file, batch_size=100, n_parse_threads=4):\n",
    "    \"\"\"Method for reading the data in an optimized way, can be used inside model.fit()\n",
    "    \n",
    "    Args:\n",
    "        file (_type_): path to csv file\n",
    "        batch_size (int, optional): _description_. Defaults to 100.\n",
    "        n_parse_threads (int, optional): _description_. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        dataset.batch: batch dataset object \n",
    "    \"\"\"\n",
    "    dataset = tf.data.TextLineDataset(file).skip(1)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    return dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "def preprocess(record):\n",
    "    \"\"\"Preprocessing method of a dataset object, one-hot-encodes the data\n",
    "\n",
    "    Args:\n",
    "        record (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        X (2D np.array): one-hot-encoded input sequence\n",
    "        Y (1D np.array): MPRA measurements\n",
    "\n",
    "    \"\"\"\n",
    "    # Extract fields from passed batch\n",
    "    fields = tf.io.decode_csv(record, record_defaults=defs)\n",
    "    chars = tf.strings.bytes_split(fields[1])     # Extract sequences from 1st field\n",
    "    chars_indices = table.lookup(chars)     # one-hot-encoding\n",
    "    \n",
    "    # Create a mask for out-of-vocabulary characters\n",
    "    oov_mask = tf.equal(chars_indices, len(vocab))\n",
    "    \n",
    "    # Explicitly cast the value to int64\n",
    "    chars_indices = tf.where(oov_mask, tf.constant(len(vocab), dtype=tf.int64), chars_indices)\n",
    "    \n",
    "    X = tf.one_hot(chars_indices, depth=len(vocab))\n",
    "    Y = fields[0]\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb6f55f",
   "metadata": {},
   "source": [
    "### Randomization of motif sequences and data augmentation\n",
    "\n",
    "This chunk defines a function that takes a dataframe with sequences and replaces upper case characters with random sequences N times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72098bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>id</th>\n",
       "      <th>rnd_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaACGTAGGCTA</td>\n",
       "      <td>1a</td>\n",
       "      <td>aaaAATCGCCTGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaACGTAGGCTA</td>\n",
       "      <td>1a</td>\n",
       "      <td>aaaTGCCTTTCTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaaACGTAGGCTA</td>\n",
       "      <td>1a</td>\n",
       "      <td>aaaAGATGTGACC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tttTTACGGTACACGT</td>\n",
       "      <td>2a</td>\n",
       "      <td>tttAAGCATTGGTGTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tttTTACGGTACACGT</td>\n",
       "      <td>2a</td>\n",
       "      <td>tttACTAAGGCCTAAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tttTTACGGTACACGT</td>\n",
       "      <td>2a</td>\n",
       "      <td>tttCGAACAGCACAGC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cccCGTACATACAGT</td>\n",
       "      <td>3a</td>\n",
       "      <td>cccTTCGTGAGAGTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cccCGTACATACAGT</td>\n",
       "      <td>3a</td>\n",
       "      <td>cccTCAAGCGCCTGT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cccCGTACATACAGT</td>\n",
       "      <td>3a</td>\n",
       "      <td>cccCTTAGGGGCTAC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                seq  id           rnd_seq\n",
       "0     aaaACGTAGGCTA  1a     aaaAATCGCCTGG\n",
       "1     aaaACGTAGGCTA  1a     aaaTGCCTTTCTA\n",
       "2     aaaACGTAGGCTA  1a     aaaAGATGTGACC\n",
       "3  tttTTACGGTACACGT  2a  tttAAGCATTGGTGTT\n",
       "4  tttTTACGGTACACGT  2a  tttACTAAGGCCTAAT\n",
       "5  tttTTACGGTACACGT  2a  tttCGAACAGCACAGC\n",
       "6   cccCGTACATACAGT  3a   cccTTCGTGAGAGTC\n",
       "7   cccCGTACATACAGT  3a   cccTCAAGCGCCTGT\n",
       "8   cccCGTACATACAGT  3a   cccCTTAGGGGCTAC"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def randomize_motifs_and_augment(df, num_augmentations=100):\n",
    "    \"\"\"This methods takes a dataframe containing a 'seq' column, randomizes the upper case characters and augments this sequences n times\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe containing a 'seq' column\n",
    "        num_augmentations (int, optional): Number of random sequences to obtaining for each input sequence. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): df with an additional 'rnd_seq' column containing randomized upper case sequences, each sequence has N augmentation additional rows.\n",
    "    \"\"\"\n",
    "    augmented_sequences = []\n",
    "\n",
    "    for sequence in df['seq']:\n",
    "        for _ in range(num_augmentations):\n",
    "            random_sequence = ''.join(random.choice(\"ACGT\") if char.isupper() else char for char in sequence)\n",
    "            augmented_sequences.append(random_sequence)\n",
    "\n",
    "    augmented_df = pd.DataFrame({'rnd_seq': augmented_sequences})\n",
    "    df = df.loc[df.index.repeat(num_augmentations)].reset_index(drop=True)\n",
    "    df = pd.concat([df, augmented_df], axis=1)\n",
    "    return df\n",
    "\n",
    "# Example data frame with DNA sequences\n",
    "\n",
    "# test dataframe\n",
    "data = {'seq': [\"aaaACGTAGGCTA\", \"tttTTACGGTACACGT\", \"cccCGTACATACAGT\"],\n",
    "        'id' : [\"1a\", \"2a\", \"3a\"]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the randomize_motifs_and_augment function\n",
    "result_df = randomize_motifs_and_augment(df, num_augmentations=3)\n",
    "\n",
    "# Display the resulting data frame\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4dae46",
   "metadata": {},
   "source": [
    "### k-fold cross validation split\n",
    "Here we take the initial csv file and we split it in 3 partitions k times\n",
    "\n",
    "It is possible to randomize the sequences and augment, since the masking of the model motifs was a better choice\n",
    "for understanding the background this strategy is here commented out and not used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6395a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION (10 fold)\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "whole_data = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/no_upper_LibA_wide_pivot_state3.csv\"\n",
    "out_data = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/\"\n",
    "# Split the data in two partitions\n",
    "whole_data = pd.read_csv(whole_data)\n",
    "k = 10\n",
    "kf = KFold(n_splits = k, shuffle = True, random_state = 2008)\n",
    "\n",
    "o=1\n",
    "# For each fold we split again to get the third partition\n",
    "for i in kf.split(whole_data):\n",
    "    \n",
    "    # Extract data from fold\n",
    "    train = whole_data.iloc[i[0]]\n",
    "    test =  whole_data.iloc[i[1]]\n",
    "    \n",
    "    # Split into train, validation and test\n",
    "    valid, validation = train_test_split(train, test_size=0.111, random_state=42)\n",
    "    \n",
    "    # Randomize motifs\n",
    "    #train = randomize_motifs_and_augment(train, num_augmentations=100)\n",
    "    #train[\"rnd_seq\"] = train['rnd_seq'].str.lower() \n",
    "    #test = randomize_motifs_and_augment(test, num_augmentations=100)\n",
    "    #test[\"rnd_seq\"] = test['rnd_seq'].str.lower() \n",
    "    #validation = randomize_motifs_and_augment(validation, num_augmentations=100)\n",
    "    #validation[\"rnd_seq\"] = validation['rnd_seq'].str.lower() \n",
    "    \n",
    "    train[[\"State_3E\", \"seq\", \"CRS\"]].to_csv(out_data+\"background_CV\"+str(o)+\"_LibA_wide_pivot_state3_train.csv\", index=False)\n",
    "    test[[\"State_3E\", \"seq\", \"CRS\"]].to_csv(out_data+\"background_CV\"+str(o)+\"_LibA_wide_pivot_state3_test.csv\", index=False)\n",
    "    validation[[\"State_3E\", \"seq\", \"CRS\"]].to_csv(out_data+\"background_CV\"+str(o)+\"_LibA_wide_pivot_state3_validation.csv\", index=False)\n",
    "    o+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ad7e0d",
   "metadata": {},
   "source": [
    "### Masking motifs\n",
    "\n",
    "Since we do not want to backpropagate through the masked values we apply a mask on them\n",
    "\n",
    "The mask is applied on values one-hot-encoded as a zero-like vector\n",
    "\n",
    "Here we test the behaviour of the mask method to make sure it not masking 0 contained in every vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da889308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0.]]], shape=(2, 3, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=bool, numpy=\n",
       "array([[False,  True,  True],\n",
       "       [ True,  True, False]])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the masking layer with mask_value=0\n",
    "masking_layer = tf.keras.layers.Masking(mask_value=0.0)\n",
    "\n",
    "# Example input tensor with shape (batch_size, sequence_length, vocab_size)\n",
    "input_tensor = tf.constant([\n",
    "    [[0, 0, 0, 0, 0], [1, 0, 0, 0, 0], [0, 0, 0, 1, 0]],\n",
    "    [[0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0]]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "# Apply the masking layer to the input tensor\n",
    "masked_tensor = masking_layer(input_tensor)\n",
    "\n",
    "print(masked_tensor)\n",
    "masking_layer.compute_mask(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc417f4a",
   "metadata": {},
   "source": [
    "### Deep Learning model\n",
    "\n",
    "Here we run the model which is based on this paper : \n",
    "\n",
    "https://doi.org/10.1101/2023.03.05.531189\n",
    "\n",
    "I have added a Normalization layer parametrized with two parameters. Here we define the custom layer, the method to compute pearson correlation and a plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bffb5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we initialize the df where each fold test prediction will be appended to\n",
    "# the list containing the correlations of each fold is also initialized\n",
    "df_test_10folds  = pd.DataFrame(columns=['State_3E', \"seq\", \"prediction\"])\n",
    "corr_list = []\n",
    "\n",
    "# We define a custom normalization layer to then compile on the model\n",
    "class CustomNormalization(Layer):\n",
    "    \"\"\"Custom normalization layer that normalizes the output of the neural network\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CustomNormalization, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Add trainable variables for mean and standard deviation\n",
    "        self.mean = self.add_weight(\"mean\", shape=(1,), initializer=\"zeros\", trainable=True)\n",
    "        self.stddev = self.add_weight(\"stddev\", shape=(1,), initializer=\"ones\", trainable=True)\n",
    "        super(CustomNormalization, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Normalize the inputs using the learned mean and standard deviation\n",
    "        return (inputs - self.mean) / (self.stddev + 1e-8)\n",
    "\n",
    "# We define the method to compute the pearson correlation between prediction and ground truth\n",
    "def pearson_correlation(x, y):\n",
    "    \"\"\"Computes Pearson Correlation between x and y\n",
    "    Args:\n",
    "        x (np.array): vector of predictions values\n",
    "        y (np.array): vector of ground truth values\n",
    "\n",
    "    Returns:\n",
    "        (float): pearson correlation\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    \n",
    "    # Calculate the mean of x and y\n",
    "    mean_x = sum(x) / n\n",
    "    mean_y = sum(y) / n\n",
    "    \n",
    "    # Calculate the numerator and denominators of the correlation coefficient\n",
    "    numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "    denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "    denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "    \n",
    "    # Calculate the correlation coefficient\n",
    "    correlation = numerator / (denominator_x * denominator_y)\n",
    "    return correlation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Define plotting function of loss\n",
    "def create_plots(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3faff54",
   "metadata": {},
   "source": [
    "#### Model training\n",
    "Here we iterate through the folds and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03d1457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 256, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 249, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 122, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 121, 100)          400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_1 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     15/Unknown - 4s 58ms/step - loss: 0.0914 - mse: 0.0914 - mae: 0.2353 - mape: 9328.7246"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:05:16.597588: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 4s 84ms/step - loss: 0.0906 - mse: 0.0906 - mae: 0.2341 - mape: 9178.5771 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0981 - val_mape: 396.1911\n",
      "Epoch 2/20\n",
      " 1/16 [>.............................] - ETA: 1s - loss: 0.0317 - mse: 0.0317 - mae: 0.1349 - mape: 736.2130"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:05:16.968107: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n",
      "2023-10-31 16:05:16.968194: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5912206572438734970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0306 - mse: 0.0306 - mae: 0.1322 - mape: 25966.2031 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.1077 - val_mape: 768.2260\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0290 - mse: 0.0290 - mae: 0.1290 - mape: 8284.9717 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.0982 - val_mape: 405.1178\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0252 - mse: 0.0252 - mae: 0.1191 - mape: 24618.6270 - val_loss: 0.0207 - val_mse: 0.0207 - val_mae: 0.0996 - val_mape: 493.1470\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0233 - mse: 0.0233 - mae: 0.1143 - mape: 3556.4373 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.1023 - val_mape: 607.5490\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.0215 - mse: 0.0215 - mae: 0.1095 - mape: 20775.6934 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.1000 - val_mape: 512.6558\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0202 - mse: 0.0202 - mae: 0.1055 - mape: 4119.1909 - val_loss: 0.0210 - val_mse: 0.0210 - val_mae: 0.0978 - val_mape: 358.2250\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0233 - mse: 0.0233 - mae: 0.1162 - mape: 11418.4424 - val_loss: 0.0242 - val_mse: 0.0242 - val_mae: 0.1027 - val_mape: 145.1583\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0670 - mse: 0.0670 - mae: 0.2103 - mape: 32947.8477 - val_loss: 0.3705 - val_mse: 0.3705 - val_mae: 0.5914 - val_mape: 5058.9189\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.0909 - mse: 0.0909 - mae: 0.2511 - mape: 26458.3848 - val_loss: 0.0213 - val_mse: 0.0213 - val_mae: 0.1066 - val_mape: 739.4568\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0244 - mse: 0.0244 - mae: 0.1169 - mape: 2431.1233 - val_loss: 0.0397 - val_mse: 0.0397 - val_mae: 0.1738 - val_mape: 1763.4768\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0197 - mse: 0.0197 - mae: 0.1024 - mape: 9151.7090 - val_loss: 0.0314 - val_mse: 0.0314 - val_mae: 0.1490 - val_mape: 1447.2283\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0184 - mse: 0.0184 - mae: 0.0976 - mape: 3719.6597 - val_loss: 0.0307 - val_mse: 0.0307 - val_mae: 0.1465 - val_mape: 1412.8170\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0180 - mse: 0.0180 - mae: 0.0968 - mape: 3800.4155 - val_loss: 0.0308 - val_mse: 0.0308 - val_mae: 0.1469 - val_mape: 1418.9628\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0173 - mse: 0.0173 - mae: 0.0959 - mape: 4912.2529 - val_loss: 0.0317 - val_mse: 0.0317 - val_mae: 0.1497 - val_mape: 1456.6252\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0167 - mse: 0.0167 - mae: 0.0943 - mape: 4611.3135 - val_loss: 0.0336 - val_mse: 0.0336 - val_mae: 0.1559 - val_mape: 1537.7054\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0161 - mse: 0.0161 - mae: 0.0932 - mape: 2271.8435 - val_loss: 0.0362 - val_mse: 0.0362 - val_mae: 0.1639 - val_mape: 1640.1716\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0153 - mse: 0.0153 - mae: 0.0910 - mape: 6233.5210 - val_loss: 0.0373 - val_mse: 0.0373 - val_mae: 0.1670 - val_mape: 1679.0543\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0893 - mape: 1130.0684 - val_loss: 0.0371 - val_mse: 0.0371 - val_mae: 0.1665 - val_mape: 1672.6660\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0141 - mse: 0.0141 - mae: 0.0878 - mape: 3152.6741 - val_loss: 0.0380 - val_mse: 0.0380 - val_mae: 0.1689 - val_mape: 1702.8606\n",
      "2/2 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:05:39.315049: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n",
      "/tmp/ipykernel_350065/22906815.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_test_10folds = pd.concat([df_test_10folds, df_test], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 256, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 249, 250)          1000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_2 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     15/Unknown - 3s 58ms/step - loss: 0.3043 - mse: 0.3043 - mae: 0.4407 - mape: 59318.4023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:05:44.167361: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 4s 84ms/step - loss: 0.3000 - mse: 0.3000 - mae: 0.4362 - mape: 58316.9805 - val_loss: 0.0295 - val_mse: 0.0295 - val_mae: 0.1177 - val_mape: 782.7260\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.0384 - mse: 0.0384 - mae: 0.1497 - mape: 12420.9805 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.1047 - val_mape: 1173.3855\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0317 - mse: 0.0317 - mae: 0.1357 - mape: 11917.9131 - val_loss: 0.0224 - val_mse: 0.0224 - val_mae: 0.1006 - val_mape: 399.1526\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0282 - mse: 0.0282 - mae: 0.1256 - mape: 2493.4578 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.1010 - val_mape: 785.8858\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0266 - mse: 0.0266 - mae: 0.1223 - mape: 2972.0320 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1004 - val_mape: 581.3675\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0250 - mse: 0.0250 - mae: 0.1188 - mape: 12755.0547 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1004 - val_mape: 565.5026\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0234 - mse: 0.0234 - mae: 0.1134 - mape: 11976.4834 - val_loss: 0.0220 - val_mse: 0.0220 - val_mae: 0.1004 - val_mape: 533.3916\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0223 - mse: 0.0223 - mae: 0.1112 - mape: 9744.4805 - val_loss: 0.0223 - val_mse: 0.0223 - val_mae: 0.1005 - val_mape: 426.7253\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0204 - mse: 0.0204 - mae: 0.1057 - mape: 13770.7588 - val_loss: 0.0239 - val_mse: 0.0239 - val_mae: 0.1033 - val_mape: 105.7040\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0185 - mse: 0.0185 - mae: 0.1012 - mape: 1321.7977 - val_loss: 0.0259 - val_mse: 0.0259 - val_mae: 0.1079 - val_mape: 372.4789\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0172 - mse: 0.0172 - mae: 0.0978 - mape: 14066.2793 - val_loss: 0.0245 - val_mse: 0.0245 - val_mae: 0.1047 - val_mape: 186.3728\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0160 - mse: 0.0160 - mae: 0.0948 - mape: 8354.3809 - val_loss: 0.0264 - val_mse: 0.0264 - val_mae: 0.1094 - val_mape: 447.0063\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0151 - mse: 0.0151 - mae: 0.0931 - mape: 2178.2253 - val_loss: 0.0289 - val_mse: 0.0289 - val_mae: 0.1161 - val_mape: 722.8743\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0196 - mse: 0.0196 - mae: 0.1096 - mape: 4076.4470 - val_loss: 0.0426 - val_mse: 0.0426 - val_mae: 0.1553 - val_mape: 1801.9102\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0340 - mse: 0.0340 - mae: 0.1513 - mape: 36559.1133 - val_loss: 0.1170 - val_mse: 0.1170 - val_mae: 0.3093 - val_mape: 4847.8892\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0463 - mse: 0.0463 - mae: 0.1793 - mape: 19320.2148 - val_loss: 0.0293 - val_mse: 0.0293 - val_mae: 0.1388 - val_mape: 2595.4602\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0329 - mse: 0.0329 - mae: 0.1460 - mape: 7218.8945 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.1051 - val_mape: 1209.5846\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0202 - mse: 0.0202 - mae: 0.1116 - mape: 5744.2500 - val_loss: 0.0239 - val_mse: 0.0239 - val_mae: 0.1034 - val_mape: 100.5410\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0922 - mape: 22164.9941 - val_loss: 0.0217 - val_mse: 0.0217 - val_mae: 0.1066 - val_mape: 1311.8297\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0826 - mape: 3504.4160 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.1004 - val_mape: 502.3103\n",
      "2/2 [==============================] - 0s 56ms/step\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_3 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 4s 87ms/step - loss: 0.0552 - mse: 0.0552 - mae: 0.1848 - mape: 20048.5605 - val_loss: 0.0310 - val_mse: 0.0310 - val_mae: 0.1460 - val_mape: 1057.7018\n",
      "Epoch 2/20\n",
      " 1/16 [>.............................] - ETA: 1s - loss: 0.0446 - mse: 0.0446 - mae: 0.1683 - mape: 1577.3434"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:06:12.748817: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n",
      "2023-10-31 16:06:12.748890: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5912206572438734970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0319 - mse: 0.0319 - mae: 0.1352 - mape: 2666.4209 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1158 - val_mape: 705.1102\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0258 - mse: 0.0258 - mae: 0.1197 - mape: 10210.0518 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.1063 - val_mape: 549.5868\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0223 - mse: 0.0223 - mae: 0.1111 - mape: 15896.4189 - val_loss: 0.0239 - val_mse: 0.0239 - val_mae: 0.1198 - val_mape: 758.8601\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0195 - mse: 0.0195 - mae: 0.1038 - mape: 1077.5920 - val_loss: 0.0240 - val_mse: 0.0240 - val_mae: 0.1201 - val_mape: 763.0800\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0166 - mse: 0.0166 - mae: 0.0955 - mape: 4574.9268 - val_loss: 0.0240 - val_mse: 0.0240 - val_mae: 0.1202 - val_mape: 764.6924\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0889 - mape: 5689.1489 - val_loss: 0.0253 - val_mse: 0.0253 - val_mae: 0.1256 - val_mape: 831.7108\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0128 - mse: 0.0128 - mae: 0.0852 - mape: 4676.4238 - val_loss: 0.0271 - val_mse: 0.0271 - val_mae: 0.1327 - val_mape: 914.5834\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0122 - mse: 0.0122 - mae: 0.0842 - mape: 4927.4370 - val_loss: 0.0308 - val_mse: 0.0308 - val_mae: 0.1453 - val_mape: 1050.8020\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0814 - mape: 7464.1836 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.1062 - val_mape: 547.6514\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0157 - mse: 0.0157 - mae: 0.0997 - mape: 16173.8027 - val_loss: 0.0224 - val_mse: 0.0224 - val_mae: 0.0981 - val_mape: 128.1259\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0150 - mse: 0.0150 - mae: 0.0940 - mape: 2664.5181 - val_loss: 0.0231 - val_mse: 0.0231 - val_mae: 0.1164 - val_mape: 712.8652\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0743 - mape: 1694.6659 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.1022 - val_mape: 461.4277\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0695 - mape: 5427.5674 - val_loss: 0.0248 - val_mse: 0.0248 - val_mae: 0.1236 - val_mape: 808.4067\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0074 - mse: 0.0074 - mae: 0.0668 - mape: 5967.1221 - val_loss: 0.0252 - val_mse: 0.0252 - val_mae: 0.1251 - val_mape: 826.3655\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0066 - mse: 0.0066 - mae: 0.0636 - mape: 1976.7960 - val_loss: 0.0241 - val_mse: 0.0241 - val_mae: 0.1206 - val_mape: 769.2562\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0061 - mse: 0.0061 - mae: 0.0606 - mape: 9160.8740 - val_loss: 0.0246 - val_mse: 0.0246 - val_mae: 0.1229 - val_mape: 799.4618\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0060 - mse: 0.0060 - mae: 0.0600 - mape: 4302.1660 - val_loss: 0.0269 - val_mse: 0.0269 - val_mae: 0.1319 - val_mape: 906.0438\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0056 - mse: 0.0056 - mae: 0.0582 - mape: 705.6116 - val_loss: 0.0356 - val_mse: 0.0356 - val_mae: 0.1598 - val_mape: 1195.6985\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0577 - mape: 9189.6191 - val_loss: 0.0299 - val_mse: 0.0299 - val_mae: 0.1422 - val_mape: 1018.1141\n",
      "2/2 [==============================] - 0s 52ms/step\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_4 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 4s 84ms/step - loss: 0.5164 - mse: 0.5164 - mae: 0.5764 - mape: 52050.5781 - val_loss: 0.0190 - val_mse: 0.0190 - val_mae: 0.0993 - val_mape: 251.8715\n",
      "Epoch 2/20\n",
      " 1/16 [>.............................] - ETA: 1s - loss: 0.0372 - mse: 0.0372 - mae: 0.1433 - mape: 1100.1429"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:06:41.297567: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5912206572438734970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0395 - mse: 0.0395 - mae: 0.1545 - mape: 19237.1152 - val_loss: 0.0469 - val_mse: 0.0469 - val_mae: 0.1924 - val_mape: 900.2628\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0305 - mse: 0.0305 - mae: 0.1323 - mape: 2286.5627 - val_loss: 0.0250 - val_mse: 0.0250 - val_mae: 0.1287 - val_mape: 526.8071\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0296 - mse: 0.0296 - mae: 0.1298 - mape: 19170.1543 - val_loss: 0.0293 - val_mse: 0.0293 - val_mae: 0.1440 - val_mape: 626.4689\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0277 - mse: 0.0277 - mae: 0.1254 - mape: 25665.7363 - val_loss: 0.0322 - val_mse: 0.0322 - val_mae: 0.1529 - val_mape: 681.0211\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0271 - mse: 0.0271 - mae: 0.1241 - mape: 10627.6621 - val_loss: 0.0269 - val_mse: 0.0269 - val_mae: 0.1357 - val_mape: 573.5923\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0250 - mse: 0.0250 - mae: 0.1178 - mape: 4540.5210 - val_loss: 0.0314 - val_mse: 0.0314 - val_mae: 0.1506 - val_mape: 667.1462\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0241 - mse: 0.0241 - mae: 0.1177 - mape: 22232.3379 - val_loss: 0.0277 - val_mse: 0.0277 - val_mae: 0.1385 - val_mape: 591.4271\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0232 - mse: 0.0232 - mae: 0.1149 - mape: 10243.2197 - val_loss: 0.0283 - val_mse: 0.0283 - val_mae: 0.1404 - val_mape: 603.6351\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0223 - mse: 0.0223 - mae: 0.1120 - mape: 13265.9678 - val_loss: 0.0265 - val_mse: 0.0265 - val_mae: 0.1344 - val_mape: 565.1608\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0206 - mse: 0.0206 - mae: 0.1073 - mape: 3814.5964 - val_loss: 0.0281 - val_mse: 0.0281 - val_mae: 0.1399 - val_mape: 600.6107\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0196 - mse: 0.0196 - mae: 0.1047 - mape: 6625.8643 - val_loss: 0.0303 - val_mse: 0.0303 - val_mae: 0.1471 - val_mape: 645.3906\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0183 - mse: 0.0183 - mae: 0.1008 - mape: 6926.3716 - val_loss: 0.0292 - val_mse: 0.0292 - val_mae: 0.1434 - val_mape: 622.6025\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0174 - mse: 0.0174 - mae: 0.0989 - mape: 10876.2705 - val_loss: 0.0330 - val_mse: 0.0330 - val_mae: 0.1554 - val_mape: 696.3126\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0164 - mse: 0.0164 - mae: 0.0957 - mape: 7763.1714 - val_loss: 0.0332 - val_mse: 0.0332 - val_mae: 0.1559 - val_mape: 699.1987\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0155 - mse: 0.0155 - mae: 0.0941 - mape: 5203.5342 - val_loss: 0.0342 - val_mse: 0.0342 - val_mae: 0.1589 - val_mape: 716.7633\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.0912 - mape: 11861.9658 - val_loss: 0.0327 - val_mse: 0.0327 - val_mae: 0.1545 - val_mape: 690.4188\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0136 - mse: 0.0136 - mae: 0.0879 - mape: 9537.4980 - val_loss: 0.0325 - val_mse: 0.0325 - val_mae: 0.1538 - val_mape: 686.3871\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0858 - mape: 14215.9365 - val_loss: 0.0371 - val_mse: 0.0371 - val_mae: 0.1670 - val_mape: 763.0234\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0121 - mse: 0.0121 - mae: 0.0841 - mape: 10480.5244 - val_loss: 0.0371 - val_mse: 0.0371 - val_mae: 0.1672 - val_mape: 764.0157\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa142dfd8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:07:04.021921: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_5 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 4s 83ms/step - loss: 0.1218 - mse: 0.1218 - mae: 0.2682 - mape: 32207.4043 - val_loss: 0.0234 - val_mse: 0.0234 - val_mae: 0.1030 - val_mape: 765.7639\n",
      "Epoch 2/20\n",
      " 1/16 [>.............................] - ETA: 1s - loss: 0.0485 - mse: 0.0485 - mae: 0.1761 - mape: 1415.9617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:07:09.351872: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n",
      "2023-10-31 16:07:09.351952: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5912206572438734970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0372 - mse: 0.0372 - mae: 0.1471 - mape: 6059.6802 - val_loss: 0.0234 - val_mse: 0.0234 - val_mae: 0.1030 - val_mape: 730.5199\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0310 - mse: 0.0310 - mae: 0.1332 - mape: 7773.0454 - val_loss: 0.0244 - val_mse: 0.0244 - val_mae: 0.1041 - val_mape: 456.4008\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0287 - mse: 0.0287 - mae: 0.1291 - mape: 17850.1582 - val_loss: 0.0229 - val_mse: 0.0229 - val_mae: 0.1029 - val_mape: 999.5724\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0256 - mse: 0.0256 - mae: 0.1201 - mape: 10985.9482 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1032 - val_mape: 1111.0691\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0233 - mse: 0.0233 - mae: 0.1140 - mape: 11180.8926 - val_loss: 0.0226 - val_mse: 0.0226 - val_mae: 0.1037 - val_mape: 1255.3544\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0207 - mse: 0.0207 - mae: 0.1063 - mape: 3316.9688 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1033 - val_mape: 1141.4448\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0180 - mse: 0.0180 - mae: 0.0994 - mape: 4522.8813 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1032 - val_mape: 1114.4296\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0164 - mse: 0.0164 - mae: 0.0944 - mape: 1963.6061 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1034 - val_mape: 1168.3938\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0155 - mse: 0.0155 - mae: 0.0922 - mape: 4113.4106 - val_loss: 0.0226 - val_mse: 0.0226 - val_mae: 0.1040 - val_mape: 1295.4818\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0150 - mse: 0.0150 - mae: 0.0917 - mape: 7061.5474 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1032 - val_mape: 1126.0286\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0891 - mape: 10327.4785 - val_loss: 0.0251 - val_mse: 0.0251 - val_mae: 0.1052 - val_mape: 299.0647\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0846 - mape: 3328.5681 - val_loss: 0.0226 - val_mse: 0.0226 - val_mae: 0.1040 - val_mape: 1297.1481\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0111 - mse: 0.0111 - mae: 0.0808 - mape: 8517.4014 - val_loss: 0.0229 - val_mse: 0.0229 - val_mae: 0.1029 - val_mape: 966.1107\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0101 - mse: 0.0101 - mae: 0.0775 - mape: 3263.9312 - val_loss: 0.0234 - val_mse: 0.0234 - val_mae: 0.1030 - val_mape: 730.1077\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0092 - mse: 0.0092 - mae: 0.0737 - mape: 10894.1367 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1028 - val_mape: 924.7814\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0085 - mse: 0.0085 - mae: 0.0718 - mape: 7397.2495 - val_loss: 0.0230 - val_mse: 0.0230 - val_mae: 0.1028 - val_mape: 910.9386\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0707 - mape: 8335.3516 - val_loss: 0.0235 - val_mse: 0.0235 - val_mae: 0.1031 - val_mape: 696.4286\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0081 - mse: 0.0081 - mae: 0.0706 - mape: 970.8970 - val_loss: 0.0244 - val_mse: 0.0244 - val_mae: 0.1041 - val_mape: 451.4602\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0100 - mse: 0.0100 - mae: 0.0792 - mape: 5872.0356 - val_loss: 0.0270 - val_mse: 0.0270 - val_mae: 0.1092 - val_mape: 197.0502\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa142eb18b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 49ms/step\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_27 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_6 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 4s 86ms/step - loss: 0.0860 - mse: 0.0860 - mae: 0.2279 - mape: 2306.7119 - val_loss: 0.0293 - val_mse: 0.0293 - val_mae: 0.1377 - val_mape: 3601.9048\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0322 - mse: 0.0322 - mae: 0.1368 - mape: 1427.3810 - val_loss: 0.0233 - val_mse: 0.0233 - val_mae: 0.1019 - val_mape: 818.4401\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0268 - mse: 0.0268 - mae: 0.1225 - mape: 1146.4163 - val_loss: 0.0228 - val_mse: 0.0228 - val_mae: 0.1024 - val_mape: 1110.4886\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0242 - mse: 0.0242 - mae: 0.1159 - mape: 1051.8286 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1055 - val_mape: 1624.2133\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0228 - mse: 0.0228 - mae: 0.1110 - mape: 813.0651 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1055 - val_mape: 1625.6235\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0207 - mse: 0.0207 - mae: 0.1064 - mape: 875.9709 - val_loss: 0.0227 - val_mse: 0.0227 - val_mae: 0.1047 - val_mape: 1525.2705\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0189 - mse: 0.0189 - mae: 0.1018 - mape: 1010.3201 - val_loss: 0.0232 - val_mse: 0.0232 - val_mae: 0.1019 - val_mape: 850.6169\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0198 - mse: 0.0198 - mae: 0.1050 - mape: 1234.1282 - val_loss: 0.0289 - val_mse: 0.0289 - val_mae: 0.1141 - val_mape: 768.1829\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1740 - mape: 2782.5833 - val_loss: 0.2484 - val_mse: 0.2484 - val_mae: 0.4751 - val_mape: 11450.9443\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0488 - mse: 0.0488 - mae: 0.1695 - mape: 1352.8927 - val_loss: 0.2855 - val_mse: 0.2855 - val_mae: 0.5178 - val_mape: 15252.7402\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0216 - mse: 0.0216 - mae: 0.1071 - mape: 768.2744 - val_loss: 0.2692 - val_mse: 0.2692 - val_mae: 0.5021 - val_mape: 14817.6787\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0197 - mse: 0.0197 - mae: 0.1004 - mape: 723.1493 - val_loss: 0.2895 - val_mse: 0.2895 - val_mae: 0.5216 - val_mape: 15361.8516\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0192 - mse: 0.0192 - mae: 0.0986 - mape: 665.9305 - val_loss: 0.2966 - val_mse: 0.2966 - val_mae: 0.5281 - val_mape: 15547.1934\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0190 - mse: 0.0190 - mae: 0.0982 - mape: 702.4916 - val_loss: 0.2902 - val_mse: 0.2902 - val_mae: 0.5222 - val_mape: 15385.5703\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0186 - mse: 0.0186 - mae: 0.0979 - mape: 665.9010 - val_loss: 0.2838 - val_mse: 0.2838 - val_mae: 0.5162 - val_mape: 15220.8926\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0180 - mse: 0.0180 - mae: 0.0972 - mape: 664.0100 - val_loss: 0.2802 - val_mse: 0.2802 - val_mae: 0.5127 - val_mape: 15128.9355\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0175 - mse: 0.0175 - mae: 0.0960 - mape: 686.5349 - val_loss: 0.2833 - val_mse: 0.2833 - val_mae: 0.5157 - val_mape: 15217.4902\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0168 - mse: 0.0168 - mae: 0.0944 - mape: 660.4863 - val_loss: 0.2892 - val_mse: 0.2892 - val_mae: 0.5213 - val_mape: 15380.4932\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0162 - mse: 0.0162 - mae: 0.0930 - mape: 569.9416 - val_loss: 0.2964 - val_mse: 0.2964 - val_mae: 0.5279 - val_mape: 15575.5664\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0153 - mse: 0.0153 - mae: 0.0910 - mape: 703.1839 - val_loss: 0.2860 - val_mse: 0.2860 - val_mae: 0.5182 - val_mape: 15311.5088\n",
      "2/2 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:08:00.681722: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_28 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_29 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_30 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_31 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_7 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     15/Unknown - 4s 61ms/step - loss: 0.0784 - mse: 0.0784 - mae: 0.2201 - mape: 2351.0105"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:08:05.721476: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n",
      "2023-10-31 16:08:05.721560: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5912206572438734970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 4s 86ms/step - loss: 0.0775 - mse: 0.0775 - mae: 0.2187 - mape: 2321.9814 - val_loss: 0.0264 - val_mse: 0.0264 - val_mae: 0.1331 - val_mape: 158746.9062\n",
      "Epoch 2/20\n",
      " 1/16 [>.............................] - ETA: 1s - loss: 0.0398 - mse: 0.0398 - mae: 0.1563 - mape: 643.0056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:08:06.088370: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n",
      "2023-10-31 16:08:06.088442: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5912206572438734970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0326 - mse: 0.0326 - mae: 0.1375 - mape: 9829.1113 - val_loss: 0.0190 - val_mse: 0.0190 - val_mae: 0.0994 - val_mape: 74801.8906\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0295 - mse: 0.0295 - mae: 0.1303 - mape: 15822.6289 - val_loss: 0.0187 - val_mse: 0.0187 - val_mae: 0.0957 - val_mape: 55197.8906\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0348 - mse: 0.0348 - mae: 0.1453 - mape: 18212.6816 - val_loss: 0.0282 - val_mse: 0.0282 - val_mae: 0.1182 - val_mape: 61532.5234\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0701 - mse: 0.0701 - mae: 0.2198 - mape: 25310.5547 - val_loss: 0.1274 - val_mse: 0.1274 - val_mae: 0.3302 - val_mape: 336740.2188\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0886 - mse: 0.0886 - mae: 0.2526 - mape: 39669.8320 - val_loss: 0.1350 - val_mse: 0.1350 - val_mae: 0.3498 - val_mape: 458613.9062\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0444 - mse: 0.0444 - mae: 0.1683 - mape: 15077.5361 - val_loss: 0.0382 - val_mse: 0.0382 - val_mae: 0.1490 - val_mape: 111669.7891\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0220 - mse: 0.0220 - mae: 0.1086 - mape: 6459.3975 - val_loss: 0.0187 - val_mse: 0.0187 - val_mae: 0.0946 - val_mape: 45786.9766\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0182 - mse: 0.0182 - mae: 0.0981 - mape: 7369.5747 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.1083 - val_mape: 104512.8281\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0172 - mse: 0.0172 - mae: 0.0950 - mape: 9366.3525 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.1064 - val_mape: 99105.6797\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0165 - mse: 0.0165 - mae: 0.0931 - mape: 7175.1230 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.1038 - val_mape: 90978.5703\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0159 - mse: 0.0159 - mae: 0.0917 - mape: 2360.1562 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.1041 - val_mape: 92124.2891\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0902 - mape: 5356.2935 - val_loss: 0.0201 - val_mse: 0.0201 - val_mae: 0.1062 - val_mape: 98519.9141\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0881 - mape: 1210.4154 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.1040 - val_mape: 91682.1094\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0134 - mse: 0.0134 - mae: 0.0856 - mape: 7881.7725 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.1088 - val_mape: 105702.7969\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0123 - mse: 0.0123 - mae: 0.0826 - mape: 1646.2137 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1113 - val_mape: 112498.9531\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0797 - mape: 8731.2842 - val_loss: 0.0223 - val_mse: 0.0223 - val_mae: 0.1168 - val_mape: 125695.8125\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0104 - mse: 0.0104 - mae: 0.0773 - mape: 2316.6086 - val_loss: 0.0233 - val_mse: 0.0233 - val_mae: 0.1208 - val_mape: 134530.6875\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0094 - mse: 0.0094 - mae: 0.0743 - mape: 2984.3792 - val_loss: 0.0239 - val_mse: 0.0239 - val_mae: 0.1236 - val_mape: 140345.6094\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0088 - mse: 0.0088 - mae: 0.0717 - mape: 7195.1895 - val_loss: 0.0250 - val_mse: 0.0250 - val_mae: 0.1276 - val_mape: 148245.2031\n",
      "2/2 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:08:28.839268: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_32 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_33 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_34 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_35 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_8 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 5s 86ms/step - loss: 0.0881 - mse: 0.0881 - mae: 0.2312 - mape: 15950.3633 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.0978 - val_mape: 8490.8398\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0323 - mse: 0.0323 - mae: 0.1363 - mape: 14004.8271 - val_loss: 0.0218 - val_mse: 0.0218 - val_mae: 0.1129 - val_mape: 115040.1328\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.0294 - mse: 0.0294 - mae: 0.1302 - mape: 6471.6279 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.1041 - val_mape: 86997.0156\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0265 - mse: 0.0265 - mae: 0.1228 - mape: 4921.8740 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.1025 - val_mape: 79932.3828\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0237 - mse: 0.0237 - mae: 0.1142 - mape: 1396.8760 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.1055 - val_mape: 92296.7656\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0213 - mse: 0.0213 - mae: 0.1085 - mape: 2535.8118 - val_loss: 0.0197 - val_mse: 0.0197 - val_mae: 0.1019 - val_mape: 77255.6094\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0189 - mse: 0.0189 - mae: 0.1014 - mape: 5583.2397 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.1002 - val_mape: 68115.6719\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0173 - mse: 0.0173 - mae: 0.0971 - mape: 2673.8977 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.0999 - val_mape: 66813.2031\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0160 - mse: 0.0160 - mae: 0.0932 - mape: 1602.5409 - val_loss: 0.0194 - val_mse: 0.0194 - val_mae: 0.0983 - val_mape: 55839.2070\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0147 - mse: 0.0147 - mae: 0.0898 - mape: 3810.7466 - val_loss: 0.0194 - val_mse: 0.0194 - val_mae: 0.0982 - val_mape: 55024.2305\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0136 - mse: 0.0136 - mae: 0.0870 - mape: 1686.3611 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.1003 - val_mape: 68840.8203\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0124 - mse: 0.0124 - mae: 0.0839 - mape: 11157.3242 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.1057 - val_mape: 92846.4531\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0110 - mse: 0.0110 - mae: 0.0797 - mape: 14751.9736 - val_loss: 0.0204 - val_mse: 0.0204 - val_mae: 0.1064 - val_mape: 95322.5781\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0102 - mse: 0.0102 - mae: 0.0774 - mape: 2262.2925 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.1008 - val_mape: 71793.2031\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0098 - mse: 0.0098 - mae: 0.0766 - mape: 4288.3169 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.0974 - val_mape: 48206.2539\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0108 - mse: 0.0108 - mae: 0.0806 - mape: 17584.3438 - val_loss: 0.0237 - val_mse: 0.0237 - val_mae: 0.1210 - val_mape: 135512.5781\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0095 - mse: 0.0095 - mae: 0.0760 - mape: 4328.5098 - val_loss: 0.0196 - val_mse: 0.0196 - val_mae: 0.1013 - val_mape: 74115.4453\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0084 - mse: 0.0084 - mae: 0.0720 - mape: 10981.8145 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.0978 - val_mape: 51800.4883\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0093 - mse: 0.0093 - mae: 0.0759 - mape: 2597.6401 - val_loss: 0.0225 - val_mse: 0.0225 - val_mae: 0.1007 - val_mape: 8453.0674\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0112 - mse: 0.0112 - mae: 0.0853 - mape: 23111.5312 - val_loss: 0.0397 - val_mse: 0.0397 - val_mae: 0.1522 - val_mape: 112992.4531\n",
      "2/2 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:08:57.424341: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_36 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_37 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_38 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_39 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_9 (Cu  (None, 1)                 2         \n",
      " stomNormalization)                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     16/Unknown - 4s 95ms/step - loss: 0.1063 - mse: 0.1063 - mae: 0.2501 - mape: 14166.1748"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:09:03.022965: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 5s 121ms/step - loss: 0.1063 - mse: 0.1063 - mae: 0.2501 - mape: 14166.1748 - val_loss: 0.0178 - val_mse: 0.0178 - val_mae: 0.0984 - val_mape: 1476.9056\n",
      "Epoch 2/20\n",
      " 1/16 [>.............................] - ETA: 1s - loss: 0.0375 - mse: 0.0375 - mae: 0.1477 - mape: 946.8655"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:09:03.373706: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n",
      "2023-10-31 16:09:03.373779: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5912206572438734970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0308 - mse: 0.0308 - mae: 0.1322 - mape: 11139.2969 - val_loss: 0.0181 - val_mse: 0.0181 - val_mae: 0.1002 - val_mape: 1648.8364\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0275 - mse: 0.0275 - mae: 0.1247 - mape: 8725.0947 - val_loss: 0.0182 - val_mse: 0.0182 - val_mae: 0.0944 - val_mape: 693.4366\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0249 - mse: 0.0249 - mae: 0.1177 - mape: 8020.9287 - val_loss: 0.0177 - val_mse: 0.0177 - val_mae: 0.0957 - val_mape: 1155.1061\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0229 - mse: 0.0229 - mae: 0.1127 - mape: 16444.4238 - val_loss: 0.0177 - val_mse: 0.0177 - val_mae: 0.0967 - val_mape: 1281.5107\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0212 - mse: 0.0212 - mae: 0.1074 - mape: 7168.4492 - val_loss: 0.0179 - val_mse: 0.0179 - val_mae: 0.0945 - val_mape: 877.3151\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0204 - mse: 0.0204 - mae: 0.1052 - mape: 14747.8125 - val_loss: 0.0179 - val_mse: 0.0179 - val_mae: 0.0944 - val_mape: 821.5801\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0231 - mse: 0.0231 - mae: 0.1150 - mape: 6583.3452 - val_loss: 0.0248 - val_mse: 0.0248 - val_mae: 0.1114 - val_mape: 850.9312\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.0505 - mse: 0.0505 - mae: 0.1814 - mape: 27403.2988 - val_loss: 0.2799 - val_mse: 0.2799 - val_mae: 0.5121 - val_mape: 10712.9268\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0677 - mse: 0.0677 - mae: 0.2140 - mape: 34437.0742 - val_loss: 0.0748 - val_mse: 0.0748 - val_mae: 0.2527 - val_mape: 6666.6807\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0243 - mse: 0.0243 - mae: 0.1158 - mape: 2866.5815 - val_loss: 0.0290 - val_mse: 0.0290 - val_mae: 0.1438 - val_mape: 3601.5820\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.0197 - mse: 0.0197 - mae: 0.1021 - mape: 1535.2570 - val_loss: 0.0183 - val_mse: 0.0183 - val_mae: 0.1016 - val_mape: 1763.8798\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0185 - mse: 0.0185 - mae: 0.0985 - mape: 1358.8823 - val_loss: 0.0180 - val_mse: 0.0180 - val_mae: 0.0992 - val_mape: 1561.1292\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0178 - mse: 0.0178 - mae: 0.0963 - mape: 5114.1738 - val_loss: 0.0188 - val_mse: 0.0188 - val_mae: 0.1041 - val_mape: 1935.5236\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0171 - mse: 0.0171 - mae: 0.0943 - mape: 5111.0332 - val_loss: 0.0193 - val_mse: 0.0193 - val_mae: 0.1067 - val_mape: 2094.4292\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0164 - mse: 0.0164 - mae: 0.0928 - mape: 1070.8317 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.1090 - val_mape: 2221.6978\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0156 - mse: 0.0156 - mae: 0.0909 - mape: 2488.0657 - val_loss: 0.0208 - val_mse: 0.0208 - val_mae: 0.1136 - val_mape: 2454.9802\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0152 - mse: 0.0152 - mae: 0.0893 - mape: 5840.2441 - val_loss: 0.0212 - val_mse: 0.0212 - val_mae: 0.1151 - val_mape: 2524.0479\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0146 - mse: 0.0146 - mae: 0.0882 - mape: 5319.8735 - val_loss: 0.0216 - val_mse: 0.0216 - val_mae: 0.1170 - val_mape: 2610.3467\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0140 - mse: 0.0140 - mae: 0.0869 - mape: 5105.3994 - val_loss: 0.0223 - val_mse: 0.0223 - val_mae: 0.1196 - val_mape: 2717.9573\n",
      "2/2 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:09:26.241050: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_40 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_41 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_42 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_43 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_10 (C  (None, 1)                 2         \n",
      " ustomNormalization)                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     15/Unknown - 4s 60ms/step - loss: 0.1082 - mse: 0.1082 - mae: 0.2634 - mape: 15389.9033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:09:31.094026: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n",
      "2023-10-31 16:09:31.094128: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5912206572438734970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 4s 86ms/step - loss: 0.1069 - mse: 0.1069 - mae: 0.2613 - mape: 15137.0898 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.1026 - val_mape: 94722.6719\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0317 - mse: 0.0317 - mae: 0.1333 - mape: 25630.1758 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.1020 - val_mape: 92656.3125\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0274 - mse: 0.0274 - mae: 0.1236 - mape: 8939.4922 - val_loss: 0.0169 - val_mse: 0.0169 - val_mae: 0.0984 - val_mape: 80449.0312\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0254 - mse: 0.0254 - mae: 0.1185 - mape: 11065.4697 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.0947 - val_mape: 63809.2070\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0225 - mse: 0.0225 - mae: 0.1119 - mape: 9361.7412 - val_loss: 0.0168 - val_mse: 0.0168 - val_mae: 0.0982 - val_mape: 79732.9375\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0207 - mse: 0.0207 - mae: 0.1065 - mape: 8704.6797 - val_loss: 0.0166 - val_mse: 0.0166 - val_mae: 0.0963 - val_mape: 71615.9531\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0189 - mse: 0.0189 - mae: 0.1016 - mape: 15144.9189 - val_loss: 0.0165 - val_mse: 0.0165 - val_mae: 0.0956 - val_mape: 68321.6719\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0169 - mse: 0.0169 - mae: 0.0959 - mape: 3990.8093 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.0925 - val_mape: 48847.1992\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0156 - mse: 0.0156 - mae: 0.0919 - mape: 2754.4690 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.0939 - val_mape: 59321.8047\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0144 - mse: 0.0144 - mae: 0.0886 - mape: 2351.3391 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.0930 - val_mape: 53157.0977\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0844 - mape: 7626.8003 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.0924 - val_mape: 47431.8945\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0118 - mse: 0.0118 - mae: 0.0819 - mape: 1904.1282 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.0933 - val_mape: 55241.4766\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0786 - mape: 3164.5503 - val_loss: 0.0184 - val_mse: 0.0184 - val_mae: 0.1065 - val_mape: 106081.1328\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0105 - mse: 0.0105 - mae: 0.0788 - mape: 1983.2017 - val_loss: 0.0173 - val_mse: 0.0173 - val_mae: 0.1013 - val_mape: 90546.7812\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0804 - mape: 6902.7495 - val_loss: 0.0343 - val_mse: 0.0343 - val_mae: 0.1616 - val_mape: 212227.0625\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0150 - mse: 0.0150 - mae: 0.0968 - mape: 10465.7705 - val_loss: 0.0177 - val_mse: 0.0177 - val_mae: 0.0929 - val_mape: 6983.8901\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0107 - mse: 0.0107 - mae: 0.0791 - mape: 2234.6987 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.0944 - val_mape: 62218.6797\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.0083 - mse: 0.0083 - mae: 0.0707 - mape: 578.9857 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.0919 - val_mape: 40771.0742\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0078 - mse: 0.0078 - mae: 0.0681 - mape: 1069.5878 - val_loss: 0.0165 - val_mse: 0.0165 - val_mae: 0.0954 - val_mape: 67709.5000\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.0070 - mse: 0.0070 - mae: 0.0648 - mape: 2856.2803 - val_loss: 0.0182 - val_mse: 0.0182 - val_mae: 0.1060 - val_mape: 104679.7578\n",
      "2/2 [==============================] - 0s 52ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 16:09:54.234061: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1417812890782289615\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_3E</th>\n",
       "      <th>seq</th>\n",
       "      <th>prediction</th>\n",
       "      <th>CRS</th>\n",
       "      <th>fold</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007714</td>\n",
       "      <td>aggaccggatcaactaaacaactcaaacaagggctaatataaccca...</td>\n",
       "      <td>0.183773</td>\n",
       "      <td>LibA.Seq7829</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.137953</td>\n",
       "      <td>aggaccggatcaactaaacactagtcatacttaaaaattgcaagga...</td>\n",
       "      <td>0.183946</td>\n",
       "      <td>LibA.Seq271</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.048706</td>\n",
       "      <td>aggaccggatcaactaaacaggttctgacgtatgctcctctatgga...</td>\n",
       "      <td>0.183883</td>\n",
       "      <td>LibA.Seq4548</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052804</td>\n",
       "      <td>aggaccggatcaactaaacccgagcctgcctagccctagcttctct...</td>\n",
       "      <td>0.183823</td>\n",
       "      <td>LibA.Seq4582</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.213652</td>\n",
       "      <td>aggaccggatcaactaaacggagcagagttagtgtcaggtcaaaaa...</td>\n",
       "      <td>0.183870</td>\n",
       "      <td>LibA.Seq2863</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8473</th>\n",
       "      <td>0.167100</td>\n",
       "      <td>aggaccggatcaacttttccgccttttattatcaggacttcacggg...</td>\n",
       "      <td>0.087564</td>\n",
       "      <td>LibA.Seq762</td>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474</th>\n",
       "      <td>0.099489</td>\n",
       "      <td>aggaccggatcaacttttcgctcattagtacagggtataacggaag...</td>\n",
       "      <td>0.087567</td>\n",
       "      <td>LibA.Seq2029</td>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8475</th>\n",
       "      <td>-0.046939</td>\n",
       "      <td>aggaccggatcaacttttggtcggttgacggtcgccttgattattc...</td>\n",
       "      <td>0.087542</td>\n",
       "      <td>LibA.Seq4154</td>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>0.093662</td>\n",
       "      <td>aggaccggatcaacttttttatctggttatcattctagtctagtgc...</td>\n",
       "      <td>0.087527</td>\n",
       "      <td>LibA.Seq1298</td>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8477</th>\n",
       "      <td>0.199862</td>\n",
       "      <td>aggaccggatcaacttttttccccgtctgccaacttcgtggctatc...</td>\n",
       "      <td>0.087588</td>\n",
       "      <td>LibA.Seq908</td>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8478 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      State_3E                                                seq  prediction  \\\n",
       "0    -0.007714  aggaccggatcaactaaacaactcaaacaagggctaatataaccca...    0.183773   \n",
       "1     0.137953  aggaccggatcaactaaacactagtcatacttaaaaattgcaagga...    0.183946   \n",
       "2    -0.048706  aggaccggatcaactaaacaggttctgacgtatgctcctctatgga...    0.183883   \n",
       "3    -0.052804  aggaccggatcaactaaacccgagcctgcctagccctagcttctct...    0.183823   \n",
       "4     0.213652  aggaccggatcaactaaacggagcagagttagtgtcaggtcaaaaa...    0.183870   \n",
       "...        ...                                                ...         ...   \n",
       "8473  0.167100  aggaccggatcaacttttccgccttttattatcaggacttcacggg...    0.087564   \n",
       "8474  0.099489  aggaccggatcaacttttcgctcattagtacagggtataacggaag...    0.087567   \n",
       "8475 -0.046939  aggaccggatcaacttttggtcggttgacggtcgccttgattattc...    0.087542   \n",
       "8476  0.093662  aggaccggatcaacttttttatctggttatcattctagtctagtgc...    0.087527   \n",
       "8477  0.199862  aggaccggatcaacttttttccccgtctgccaacttcgtggctatc...    0.087588   \n",
       "\n",
       "               CRS fold partition  \n",
       "0     LibA.Seq7829    1      test  \n",
       "1      LibA.Seq271    1      test  \n",
       "2     LibA.Seq4548    1      test  \n",
       "3     LibA.Seq4582    1      test  \n",
       "4     LibA.Seq2863    1      test  \n",
       "...            ...  ...       ...  \n",
       "8473   LibA.Seq762   10      test  \n",
       "8474  LibA.Seq2029   10      test  \n",
       "8475  LibA.Seq4154   10      test  \n",
       "8476  LibA.Seq1298   10      test  \n",
       "8477   LibA.Seq908   10      test  \n",
       "\n",
       "[8478 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We iterate through each of the train folds to train, test and validate the model\n",
    "for i in range(1,11):\n",
    "    \n",
    "    #Define inputs\n",
    "    input_path_train = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/background_CV\"+str(i)+\"_LibA_wide_pivot_state3_train.csv\"\n",
    "    input_path_valid = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/background_CV\"+str(i)+\"_LibA_wide_pivot_state3_validation.csv\"\n",
    "    input_path_test = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/background_CV\"+str(i)+\"_LibA_wide_pivot_state3_test.csv\"\n",
    "    \n",
    "    # Read test data to then predict\n",
    "    df_test = pd.read_csv(input_path_test)\n",
    "\n",
    "    # Get first item of the dataset to get the shape of the input data\n",
    "    for element in data_reader(input_path_train):\n",
    "        input_shape = element[0].shape\n",
    "\n",
    "    # Define and compile model\n",
    "    inputs = Input(shape=(input_shape[1],input_shape[2]), name=\"inputs\")\n",
    "    inputs = Masking()(inputs)\n",
    "    layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "    predictions = Dense(1, activation='linear')(layer)\n",
    "    norm_predictions = CustomNormalization()(predictions)  # Assuming \"predictions\" is your existing output\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=norm_predictions)\n",
    "    model.summary()\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "                )\n",
    "\n",
    "    # Run model\n",
    "    history=model.fit(data_reader(input_path_train, batch_size=500),\n",
    "                            epochs=20,\n",
    "                            validation_data=data_reader(input_path_valid,batch_size=500),\n",
    "                            callbacks=None,\n",
    "                            verbose=1)\n",
    "    \n",
    "    #After training we save the model weights to then run the contribution scores\n",
    "    model_path = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/test_background.h5\"\n",
    "    model.save_weights(model_path, save_format='h5') \n",
    "    \n",
    "    # We predict the test data\n",
    "    predicted = model.predict(data_reader(input_path_test, batch_size=500))\n",
    "\n",
    "    # We reed the data in the same order to compute the correlation score\n",
    "    test_data = data_reader(input_path_test,batch_size=500)\n",
    "    test_tensor = np.empty(shape=[0,1])\n",
    "    for batch in test_data:\n",
    "        test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "    # We fill the dataframe with predictions and fold annotation\n",
    "    df_test[\"prediction\"] = predicted\n",
    "    df_test[\"fold\"] = str(i)\n",
    "    df_test[\"partition\"] = \"test\"\n",
    "    \n",
    "    # Append fold to previous folds\n",
    "    df_test_10folds = pd.concat([df_test_10folds, df_test], ignore_index=True)    \n",
    "    # Append correlation coefficient and append to previous\n",
    "    corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)\n",
    "    corr_list.append(corr_coefficient)\n",
    "\n",
    "# Save the results for all folds\n",
    "df_test_10folds.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/background_LibA_wide_pivot_state3_test_predicted_cv10fold.csv\", index=False)\n",
    "\n",
    "df_test_10folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7772ea68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_plots(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
