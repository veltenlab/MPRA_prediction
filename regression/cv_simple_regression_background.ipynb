{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "921b4b40",
   "metadata": {},
   "source": [
    "# MPRA regression of background samples with K-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb96b1",
   "metadata": {},
   "source": [
    "### Environment \n",
    "The next chunk contains the commands necessary to install the environment required to run this jupyter notebook\n",
    "Skip this chunk if the installation was previously done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b76b192d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/felix/anaconda3/envs/tensorflow_2_gpu\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    pandas-2.1.1               |   py39h1128e8f_0        13.5 MB  anaconda\n",
      "    python-tzdata-2023.3       |     pyhd3eb1b0_0         149 KB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        13.6 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  python-tzdata      anaconda/noarch::python-tzdata-2023.3-pyhd3eb1b0_0 None\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  pandas                               1.5.2-py39h417a72b_0 --> 2.1.1-py39h1128e8f_0 None\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? \n",
      "\n",
      "Downloading and Extracting Packages\n",
      "python-tzdata-2023.3 | 149 KB    | ########## | 100% \n",
      "pandas-2.1.1         | 13.5 MB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.9.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/felix/anaconda3/envs/tf_MPRA\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.9.7\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.08.22 |       h06a4308_0         123 KB\n",
      "    openssl-1.1.1w             |       h7f8727e_0         3.7 MB\n",
      "    pip-23.3                   |   py39h06a4308_0         2.6 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         6.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main None\n",
      "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu None\n",
      "  ca-certificates    pkgs/main/linux-64::ca-certificates-2023.08.22-h06a4308_0 None\n",
      "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1 None\n",
      "  libffi             pkgs/main/linux-64::libffi-3.3-he6710b0_2 None\n",
      "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 None\n",
      "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 None\n",
      "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 None\n",
      "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 None\n",
      "  openssl            pkgs/main/linux-64::openssl-1.1.1w-h7f8727e_0 None\n",
      "  pip                pkgs/main/linux-64::pip-23.3-py39h06a4308_0 None\n",
      "  python             pkgs/main/linux-64::python-3.9.7-h12debd9_1 None\n",
      "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 None\n",
      "  setuptools         pkgs/main/linux-64::setuptools-68.0.0-py39h06a4308_0 None\n",
      "  sqlite             pkgs/main/linux-64::sqlite-3.41.2-h5eee18b_0 None\n",
      "  tk                 pkgs/main/linux-64::tk-8.6.12-h1ccaba5_0 None\n",
      "  tzdata             pkgs/main/noarch::tzdata-2023c-h04d1e81_0 None\n",
      "  wheel              pkgs/main/linux-64::wheel-0.41.2-py39h06a4308_0 None\n",
      "  xz                 pkgs/main/linux-64::xz-5.4.2-h5eee18b_0 None\n",
      "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_0 None\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? Invalid choice: conda activate tf_mpra\n",
      "Proceed ([y]/n)? Invalid choice: pip install tensorflow[and-cuda]\n",
      "Proceed ([y]/n)? Invalid choice: conda install -c anaconda ipykernel\n",
      "Proceed ([y]/n)? Invalid choice: conda install -c anaconda pandas\n",
      "Proceed ([y]/n)? \n",
      "\n",
      "Downloading and Extracting Packages\n",
      "openssl-1.1.1w       | 3.7 MB    | ########## | 100% \n",
      "pip-23.3             | 2.6 MB    | ########## | 100% \n",
      "ca-certificates-2023 | 123 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate tf_MPRA\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "Retrieving notices: ...working... done\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "conda create --name tf_MPRA python=3.9.7\n",
    "conda activate tf_MPRA\n",
    "pip install tensorflow[and-cuda]\n",
    "conda install -c anaconda ipykernel\n",
    "conda install -c anaconda pandas\n",
    "conda install -c anaconda numpy\n",
    "conda install -c anaconda scikit-learn \n",
    "conda install -c conda-forge matplotlib\n",
    "\n",
    "# After installation if you are using VSCODE to run the notebook you have to close it and re-open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b66a7a",
   "metadata": {},
   "source": [
    "### Library imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c1f9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import getopt\n",
    "import sys\n",
    "\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Input, Masking, Lambda, concatenate, Bidirectional, Dense, Dropout, Flatten, Conv1D,BatchNormalization,  MaxPooling1D, Bidirectional, GRU, TimeDistributed\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37317fa",
   "metadata": {},
   "source": [
    "### Input ingestion\n",
    "\n",
    "Here we define the methods to read and ingest data and we initialize the random seed.\n",
    "\n",
    "Since we are processing the background the vocabulary is comprised of lower case nucleotides.\n",
    "\n",
    "The upper cases (where the motif is), will be encoded as a zero-like vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a0aec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337) # for reproducibility\n",
    "\n",
    "# Lower case vocabulary\n",
    "vocab = [\"a\", \"c\", \"g\", \"t\"]\n",
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets=1)\n",
    "\n",
    "# These are the defaults of the data reader method \n",
    "# (each column in the ingested csv must be initialized with the right data type, otherwise the data ingestion fails )\n",
    "defs = [0.] * 1 + [tf.constant([], dtype=\"string\")] + [tf.constant([], dtype=\"string\")]\n",
    "\n",
    "\n",
    "def data_reader(file, batch_size=100, n_parse_threads=4):\n",
    "    \"\"\"Method for reading the data in an optimized way, can be used inside model.fit()\n",
    "    \n",
    "    Args:\n",
    "        file (_type_): path to csv file\n",
    "        batch_size (int, optional): _description_. Defaults to 100.\n",
    "        n_parse_threads (int, optional): _description_. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        dataset.batch: batch dataset object \n",
    "    \"\"\"\n",
    "    dataset = tf.data.TextLineDataset(file).skip(1)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    return dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "def preprocess(record):\n",
    "    \"\"\"Preprocessing method of a dataset object, one-hot-encodes the data\n",
    "\n",
    "    Args:\n",
    "        record (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        X (2D np.array): one-hot-encoded input sequence\n",
    "        Y (1D np.array): MPRA measurements\n",
    "\n",
    "    \"\"\"\n",
    "    # Extract fields from passed batch\n",
    "    fields = tf.io.decode_csv(record, record_defaults=defs)\n",
    "    chars = tf.strings.bytes_split(fields[1])     # Extract sequences from 1st field\n",
    "    chars_indices = table.lookup(chars)     # one-hot-encoding\n",
    "    \n",
    "    # Create a mask for out-of-vocabulary characters\n",
    "    oov_mask = tf.equal(chars_indices, len(vocab))\n",
    "    \n",
    "    # Explicitly cast the value to int64\n",
    "    chars_indices = tf.where(oov_mask, tf.constant(len(vocab), dtype=tf.int64), chars_indices)\n",
    "    \n",
    "    X = tf.one_hot(chars_indices, depth=len(vocab))\n",
    "    Y = fields[0]\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb6f55f",
   "metadata": {},
   "source": [
    "### Randomization of motif sequences and data augmentation\n",
    "\n",
    "This chunk defines a function that takes a dataframe with sequences and replaces upper case characters with random sequences N times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72098bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>id</th>\n",
       "      <th>rnd_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaACGTAGGCTA</td>\n",
       "      <td>1a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaACGTAGGCTA</td>\n",
       "      <td>1a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaaACGTAGGCTA</td>\n",
       "      <td>1a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tttTTACGGTACACGT</td>\n",
       "      <td>2a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tttTTACGGTACACGT</td>\n",
       "      <td>2a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tttTTACGGTACACGT</td>\n",
       "      <td>2a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cccCGTACATACAGT</td>\n",
       "      <td>3a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cccCGTACATACAGT</td>\n",
       "      <td>3a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cccCGTACATACAGT</td>\n",
       "      <td>3a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aaaCTAGTCGACG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aaaTTGTGCGCGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aaaGGGAGTAGTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tttGAAGGTTTTATGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tttAGCTTTCCTCGCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tttGGGGCAGTGGCTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cccGGATGCCGACGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cccCAGTCGTGTACC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cccTATCCAGGAGCG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                seq   id           rnd_seq\n",
       "0     aaaACGTAGGCTA   1a               NaN\n",
       "1     aaaACGTAGGCTA   1a               NaN\n",
       "2     aaaACGTAGGCTA   1a               NaN\n",
       "3  tttTTACGGTACACGT   2a               NaN\n",
       "4  tttTTACGGTACACGT   2a               NaN\n",
       "5  tttTTACGGTACACGT   2a               NaN\n",
       "6   cccCGTACATACAGT   3a               NaN\n",
       "7   cccCGTACATACAGT   3a               NaN\n",
       "8   cccCGTACATACAGT   3a               NaN\n",
       "0               NaN  NaN     aaaCTAGTCGACG\n",
       "1               NaN  NaN     aaaTTGTGCGCGG\n",
       "2               NaN  NaN     aaaGGGAGTAGTC\n",
       "3               NaN  NaN  tttGAAGGTTTTATGG\n",
       "4               NaN  NaN  tttAGCTTTCCTCGCA\n",
       "5               NaN  NaN  tttGGGGCAGTGGCTA\n",
       "6               NaN  NaN   cccGGATGCCGACGG\n",
       "7               NaN  NaN   cccCAGTCGTGTACC\n",
       "8               NaN  NaN   cccTATCCAGGAGCG"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def randomize_motifs_and_augment(df, num_augmentations=100):\n",
    "    \"\"\"This methods takes a dataframe containing a 'seq' column, randomizes the upper case characters and augments this sequences n times\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe containing a 'seq' column\n",
    "        num_augmentations (int, optional): Number of random sequences to obtaining for each input sequence. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): df with an additional 'rnd_seq' column containing randomized upper case sequences, each sequence has N augmentation additional rows.\n",
    "    \"\"\"\n",
    "    augmented_sequences = []\n",
    "\n",
    "    for sequence in df['seq']:\n",
    "        for _ in range(num_augmentations):\n",
    "            random_sequence = ''.join(random.choice(\"ACGT\") if char.isupper() else char for char in sequence)\n",
    "            augmented_sequences.append(random_sequence)\n",
    "\n",
    "    augmented_df = pd.DataFrame({'rnd_seq': augmented_sequences})\n",
    "    df = df.loc[df.index.repeat(num_augmentations)].reset_index(drop=True)\n",
    "    df = pd.concat([df, augmented_df], axis=1)\n",
    "    return df\n",
    "\n",
    "# Example data frame with DNA sequences\n",
    "\n",
    "# test dataframe\n",
    "data = {'seq': [\"aaaACGTAGGCTA\", \"tttTTACGGTACACGT\", \"cccCGTACATACAGT\"],\n",
    "        'id' : [\"1a\", \"2a\", \"3a\"]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Call the randomize_motifs_and_augment function\n",
    "result_df = randomize_motifs_and_augment(df, num_augmentations=3)\n",
    "\n",
    "# Display the resulting data frame\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4dae46",
   "metadata": {},
   "source": [
    "### k-fold cross validation split\n",
    "Here we take the initial csv file and we split it in 3 partitions k times\n",
    "\n",
    "It is possible to randomize the sequences and augment, since the masking of the model motifs was a better choice\n",
    "for understanding the background this strategy is here commented out and not used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6395a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION (10 fold)\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "whole_data = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/no_upper_LibA_wide_pivot_state3.csv\"\n",
    "out_data = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/\"\n",
    "# Split the data in two partitions\n",
    "whole_data = pd.read_csv(whole_data)\n",
    "k = 10\n",
    "kf = KFold(n_splits = k, shuffle = True, random_state = 2008)\n",
    "\n",
    "o=1\n",
    "# For each fold we split again to get the third partition\n",
    "for i in kf.split(whole_data):\n",
    "    \n",
    "    # Extract data from fold\n",
    "    train = whole_data.iloc[i[0]]\n",
    "    test =  whole_data.iloc[i[1]]\n",
    "    \n",
    "    # Split into train, validation and test\n",
    "    valid, validation = train_test_split(train, test_size=0.111, random_state=42)\n",
    "    \n",
    "    # Randomize motifs\n",
    "    #train = randomize_motifs_and_augment(train, num_augmentations=100)\n",
    "    #train[\"rnd_seq\"] = train['rnd_seq'].str.lower() \n",
    "    #test = randomize_motifs_and_augment(test, num_augmentations=100)\n",
    "    #test[\"rnd_seq\"] = test['rnd_seq'].str.lower() \n",
    "    #validation = randomize_motifs_and_augment(validation, num_augmentations=100)\n",
    "    #validation[\"rnd_seq\"] = validation['rnd_seq'].str.lower() \n",
    "    \n",
    "    train[[\"State_3E\", \"seq\", \"CRS\"]].to_csv(out_data+\"background_CV\"+str(o)+\"_LibA_wide_pivot_state3_train.csv\", index=False)\n",
    "    test[[\"State_3E\", \"seq\", \"CRS\"]].to_csv(out_data+\"background_CV\"+str(o)+\"_LibA_wide_pivot_state3_test.csv\", index=False)\n",
    "    validation[[\"State_3E\", \"seq\", \"CRS\"]].to_csv(out_data+\"background_CV\"+str(o)+\"_LibA_wide_pivot_state3_validation.csv\", index=False)\n",
    "    o+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ad7e0d",
   "metadata": {},
   "source": [
    "### Masking motifs\n",
    "\n",
    "Since we do not want to backpropagate through the masked values we apply a mask on them\n",
    "\n",
    "The mask is applied on values one-hot-encoded as a zero-like vector\n",
    "\n",
    "Here we test the behaviour of the mask method to make sure it not masking 0 contained in every vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da889308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0.]]], shape=(2, 3, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=bool, numpy=\n",
       "array([[False,  True,  True],\n",
       "       [ True,  True, False]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the masking layer with mask_value=0\n",
    "masking_layer = tf.keras.layers.Masking(mask_value=0.0)\n",
    "\n",
    "# Example input tensor with shape (batch_size, sequence_length, vocab_size)\n",
    "input_tensor = tf.constant([\n",
    "    [[0, 0, 0, 0, 0], [1, 0, 0, 0, 0], [0, 0, 0, 1, 0]],\n",
    "    [[0, 0, 0, 0, 1], [0, 0, 0, 0, 1], [0, 0, 0, 0, 0]]\n",
    "], dtype=tf.float32)\n",
    "\n",
    "# Apply the masking layer to the input tensor\n",
    "masked_tensor = masking_layer(input_tensor)\n",
    "\n",
    "print(masked_tensor)\n",
    "masking_layer.compute_mask(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc417f4a",
   "metadata": {},
   "source": [
    "### Deep Learning model\n",
    "\n",
    "Here we run the model which is based on this paper : \n",
    "\n",
    "https://doi.org/10.1101/2023.03.05.531189\n",
    "\n",
    "I have added a Normalization layer parametrized with two parameters. Here we define the custom layer, the method to compute pearson correlation and a plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bffb5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we initialize the df where each fold test prediction will be appended to\n",
    "# the list containing the correlations of each fold is also initialized\n",
    "df_test_10folds  = pd.DataFrame(columns=['State_3E', \"seq\", \"prediction\"])\n",
    "corr_list = []\n",
    "\n",
    "# We define a custom normalization layer to then compile on the model\n",
    "class CustomNormalization(Layer):\n",
    "    \"\"\"Custom normalization layer that normalizes the output of the neural network\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CustomNormalization, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # Add trainable variables for mean and standard deviation\n",
    "        self.mean = self.add_weight(\"mean\", shape=(1,), initializer=\"zeros\", trainable=True)\n",
    "        self.stddev = self.add_weight(\"stddev\", shape=(1,), initializer=\"ones\", trainable=True)\n",
    "        super(CustomNormalization, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Normalize the inputs using the learned mean and standard deviation\n",
    "        return (inputs - self.mean) / (self.stddev + 1e-8)\n",
    "\n",
    "# We define the method to compute the pearson correlation between prediction and ground truth\n",
    "def pearson_correlation(x, y):\n",
    "    \"\"\"Computes Pearson Correlation between x and y\n",
    "    Args:\n",
    "        x (np.array): vector of predictions values\n",
    "        y (np.array): vector of ground truth values\n",
    "\n",
    "    Returns:\n",
    "        (float): pearson correlation\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    \n",
    "    # Calculate the mean of x and y\n",
    "    mean_x = sum(x) / n\n",
    "    mean_y = sum(y) / n\n",
    "    \n",
    "    # Calculate the numerator and denominators of the correlation coefficient\n",
    "    numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "    denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "    denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "    \n",
    "    # Calculate the correlation coefficient\n",
    "    correlation = numerator / (denominator_x * denominator_y)\n",
    "    return correlation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Define plotting function of loss\n",
    "def create_plots(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3faff54",
   "metadata": {},
   "source": [
    "#### Model training\n",
    "Here we iterate through the folds and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03d1457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_100 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_80 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_81 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_101 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_82 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_102 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_83 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_103 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_104 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_20 (C  (None, 1)                 2         \n",
      " ustomNormalization)                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 5s 27ms/step - loss: 0.0904 - mse: 0.0904 - mae: 0.2240 - mape: 48932.3320 - val_loss: 0.0516 - val_mse: 0.0516 - val_mae: 0.1612 - val_mape: 159.2170\n",
      "Epoch 2/20\n",
      " 4/77 [>.............................] - ETA: 1s - loss: 0.0625 - mse: 0.0625 - mae: 0.1791 - mape: 355.5330"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:55:14.943120: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 422699371556086469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0597 - mse: 0.0597 - mae: 0.1784 - mape: 9509.8574 - val_loss: 0.0511 - val_mse: 0.0511 - val_mae: 0.1615 - val_mape: 173.5569\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0550 - mse: 0.0550 - mae: 0.1711 - mape: 10959.9570 - val_loss: 0.0528 - val_mse: 0.0528 - val_mae: 0.1764 - val_mape: 333.8909\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0532 - mse: 0.0532 - mae: 0.1679 - mape: 8220.0303 - val_loss: 0.0860 - val_mse: 0.0860 - val_mae: 0.2518 - val_mape: 675.1546\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1630 - mape: 4676.3574 - val_loss: 0.0865 - val_mse: 0.0865 - val_mae: 0.2528 - val_mape: 679.3126\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0486 - mse: 0.0486 - mae: 0.1618 - mape: 9238.5537 - val_loss: 0.0987 - val_mse: 0.0987 - val_mae: 0.2752 - val_mape: 759.3158\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1620 - mape: 14156.8760 - val_loss: 0.0793 - val_mse: 0.0793 - val_mae: 0.2430 - val_mape: 654.3745\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1616 - mape: 13384.4941 - val_loss: 0.0553 - val_mse: 0.0553 - val_mae: 0.1955 - val_mape: 472.9304\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1594 - mape: 16689.4219 - val_loss: 0.0398 - val_mse: 0.0398 - val_mae: 0.1574 - val_mape: 296.6056\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1595 - mape: 7058.1270 - val_loss: 0.0428 - val_mse: 0.0428 - val_mae: 0.1673 - val_mape: 340.4495\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0453 - mse: 0.0453 - mae: 0.1581 - mape: 18233.1836 - val_loss: 0.0349 - val_mse: 0.0349 - val_mae: 0.1424 - val_mape: 197.6544\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0450 - mse: 0.0450 - mae: 0.1575 - mape: 3236.0298 - val_loss: 0.0353 - val_mse: 0.0353 - val_mae: 0.1462 - val_mape: 236.6560\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0439 - mse: 0.0439 - mae: 0.1560 - mape: 9673.5732 - val_loss: 0.0344 - val_mse: 0.0344 - val_mae: 0.1437 - val_mape: 241.1472\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0421 - mse: 0.0421 - mae: 0.1542 - mape: 4218.3008 - val_loss: 0.0363 - val_mse: 0.0363 - val_mae: 0.1528 - val_mape: 294.8602\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0416 - mse: 0.0416 - mae: 0.1526 - mape: 14974.9795 - val_loss: 0.0357 - val_mse: 0.0357 - val_mae: 0.1516 - val_mape: 309.4020\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0415 - mse: 0.0415 - mae: 0.1528 - mape: 23281.2715 - val_loss: 0.0326 - val_mse: 0.0326 - val_mae: 0.1395 - val_mape: 236.3142\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0406 - mse: 0.0406 - mae: 0.1511 - mape: 20622.0059 - val_loss: 0.0343 - val_mse: 0.0343 - val_mae: 0.1453 - val_mape: 269.5489\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0424 - mse: 0.0424 - mae: 0.1546 - mape: 17250.0273 - val_loss: 0.0328 - val_mse: 0.0328 - val_mae: 0.1436 - val_mape: 260.7945\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0407 - mse: 0.0407 - mae: 0.1514 - mape: 20014.4707 - val_loss: 0.0315 - val_mse: 0.0315 - val_mae: 0.1373 - val_mape: 235.4347\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0411 - mse: 0.0411 - mae: 0.1525 - mape: 9905.8857 - val_loss: 0.0395 - val_mse: 0.0395 - val_mae: 0.1633 - val_mape: 381.0811\n",
      "2/2 [==============================] - 0s 59ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:55:52.073541: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_105 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_84 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_85 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_106 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_86 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_107 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_87 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_108 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_109 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_21 (C  (None, 1)                 2         \n",
      " ustomNormalization)                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 5s 27ms/step - loss: 0.0902 - mse: 0.0902 - mae: 0.2250 - mape: 54845.9297 - val_loss: 0.0650 - val_mse: 0.0650 - val_mae: 0.1746 - val_mape: 146.8540\n",
      "Epoch 2/20\n",
      " 4/77 [>.............................] - ETA: 1s - loss: 0.0809 - mse: 0.0809 - mae: 0.1972 - mape: 423.0044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:55:58.187942: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n",
      "2023-11-10 12:55:58.188023: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 422699371556086469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0613 - mse: 0.0613 - mae: 0.1798 - mape: 20431.4160 - val_loss: 0.0656 - val_mse: 0.0656 - val_mae: 0.1752 - val_mape: 133.8401\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0561 - mse: 0.0561 - mae: 0.1709 - mape: 13575.4512 - val_loss: 0.0637 - val_mse: 0.0637 - val_mae: 0.1923 - val_mape: 696.6546\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0518 - mse: 0.0518 - mae: 0.1659 - mape: 18095.3652 - val_loss: 0.0659 - val_mse: 0.0659 - val_mae: 0.1988 - val_mape: 765.5031\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1634 - mape: 5387.7866 - val_loss: 0.0701 - val_mse: 0.0701 - val_mae: 0.2097 - val_mape: 868.4425\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1618 - mape: 11735.6426 - val_loss: 0.0715 - val_mse: 0.0715 - val_mae: 0.2150 - val_mape: 917.8820\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1612 - mape: 20959.8730 - val_loss: 0.0550 - val_mse: 0.0550 - val_mae: 0.1813 - val_mape: 637.2633\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0459 - mse: 0.0459 - mae: 0.1577 - mape: 14275.1338 - val_loss: 0.0431 - val_mse: 0.0431 - val_mae: 0.1575 - val_mape: 435.7504\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0468 - mse: 0.0468 - mae: 0.1595 - mape: 17432.7031 - val_loss: 0.0438 - val_mse: 0.0438 - val_mae: 0.1670 - val_mape: 618.3807\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0464 - mse: 0.0464 - mae: 0.1584 - mape: 13821.4844 - val_loss: 0.0383 - val_mse: 0.0383 - val_mae: 0.1436 - val_mape: 256.1071\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0460 - mse: 0.0460 - mae: 0.1587 - mape: 12700.7607 - val_loss: 0.0374 - val_mse: 0.0374 - val_mae: 0.1504 - val_mape: 485.7086\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0432 - mse: 0.0432 - mae: 0.1551 - mape: 25393.4355 - val_loss: 0.0352 - val_mse: 0.0352 - val_mae: 0.1421 - val_mape: 401.3687\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0427 - mse: 0.0427 - mae: 0.1539 - mape: 8670.4111 - val_loss: 0.0370 - val_mse: 0.0370 - val_mae: 0.1520 - val_mape: 568.0023\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0421 - mse: 0.0421 - mae: 0.1532 - mape: 13561.1602 - val_loss: 0.0344 - val_mse: 0.0344 - val_mae: 0.1425 - val_mape: 471.9623\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0427 - mse: 0.0427 - mae: 0.1543 - mape: 7486.1753 - val_loss: 0.0333 - val_mse: 0.0333 - val_mae: 0.1388 - val_mape: 376.3299\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0407 - mse: 0.0407 - mae: 0.1521 - mape: 20270.6992 - val_loss: 0.0325 - val_mse: 0.0325 - val_mae: 0.1376 - val_mape: 437.7283\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0405 - mse: 0.0405 - mae: 0.1520 - mape: 9324.0186 - val_loss: 0.0315 - val_mse: 0.0315 - val_mae: 0.1361 - val_mape: 394.5872\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0406 - mse: 0.0406 - mae: 0.1510 - mape: 12711.1162 - val_loss: 0.0325 - val_mse: 0.0325 - val_mae: 0.1375 - val_mape: 400.7811\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0396 - mse: 0.0396 - mae: 0.1497 - mape: 10944.4492 - val_loss: 0.0320 - val_mse: 0.0320 - val_mae: 0.1359 - val_mape: 403.6624\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0402 - mse: 0.0402 - mae: 0.1508 - mape: 14260.1182 - val_loss: 0.0334 - val_mse: 0.0334 - val_mae: 0.1406 - val_mape: 445.4251\n",
      "2/2 [==============================] - 0s 52ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:56:34.924906: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_110 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_88 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_89 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_111 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_90 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_112 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_91 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_113 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_114 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_22 (C  (None, 1)                 2         \n",
      " ustomNormalization)                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 5s 27ms/step - loss: 0.1266 - mse: 0.1266 - mae: 0.2585 - mape: 57535.0508 - val_loss: 0.0675 - val_mse: 0.0675 - val_mae: 0.2002 - val_mape: 482.4877\n",
      "Epoch 2/20\n",
      " 4/77 [>.............................] - ETA: 1s - loss: 0.0800 - mse: 0.0800 - mae: 0.1891 - mape: 348.5126"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:56:41.188506: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n",
      "2023-11-10 12:56:41.188582: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 422699371556086469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0627 - mse: 0.0627 - mae: 0.1832 - mape: 15678.7295 - val_loss: 0.0654 - val_mse: 0.0654 - val_mae: 0.1946 - val_mape: 450.7902\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0562 - mse: 0.0562 - mae: 0.1709 - mape: 15567.7588 - val_loss: 0.0678 - val_mse: 0.0678 - val_mae: 0.2009 - val_mape: 486.3112\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0547 - mse: 0.0547 - mae: 0.1704 - mape: 16778.3066 - val_loss: 0.0757 - val_mse: 0.0757 - val_mae: 0.2195 - val_mape: 579.3629\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0526 - mse: 0.0526 - mae: 0.1671 - mape: 8791.9727 - val_loss: 0.0909 - val_mse: 0.0909 - val_mae: 0.2495 - val_mape: 709.2432\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0496 - mse: 0.0496 - mae: 0.1618 - mape: 8656.1826 - val_loss: 0.1085 - val_mse: 0.1085 - val_mae: 0.2803 - val_mape: 827.5040\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1624 - mape: 16623.2383 - val_loss: 0.0970 - val_mse: 0.0970 - val_mae: 0.2630 - val_mape: 764.7245\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1591 - mape: 13489.9609 - val_loss: 0.0687 - val_mse: 0.0687 - val_mae: 0.2144 - val_mape: 577.0878\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0458 - mse: 0.0458 - mae: 0.1580 - mape: 25522.8145 - val_loss: 0.0457 - val_mse: 0.0457 - val_mae: 0.1653 - val_mape: 368.3480\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0440 - mse: 0.0440 - mae: 0.1550 - mape: 23064.6387 - val_loss: 0.0344 - val_mse: 0.0344 - val_mae: 0.1417 - val_mape: 244.8449\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0432 - mse: 0.0432 - mae: 0.1545 - mape: 24785.8047 - val_loss: 0.0335 - val_mse: 0.0335 - val_mae: 0.1370 - val_mape: 160.5166\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0441 - mse: 0.0441 - mae: 0.1566 - mape: 20173.3086 - val_loss: 0.0326 - val_mse: 0.0326 - val_mae: 0.1382 - val_mape: 207.7525\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0417 - mse: 0.0417 - mae: 0.1532 - mape: 13841.2617 - val_loss: 0.0317 - val_mse: 0.0317 - val_mae: 0.1401 - val_mape: 246.0324\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0406 - mse: 0.0406 - mae: 0.1499 - mape: 9375.9180 - val_loss: 0.0305 - val_mse: 0.0305 - val_mae: 0.1314 - val_mape: 151.4465\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0395 - mse: 0.0395 - mae: 0.1490 - mape: 19385.5391 - val_loss: 0.0301 - val_mse: 0.0301 - val_mae: 0.1373 - val_mape: 239.5524\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0402 - mse: 0.0402 - mae: 0.1500 - mape: 12450.2539 - val_loss: 0.0346 - val_mse: 0.0346 - val_mae: 0.1513 - val_mape: 329.7117\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0398 - mse: 0.0398 - mae: 0.1499 - mape: 4022.3569 - val_loss: 0.0283 - val_mse: 0.0283 - val_mae: 0.1321 - val_mape: 205.6407\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0399 - mse: 0.0399 - mae: 0.1493 - mape: 5847.8696 - val_loss: 0.0286 - val_mse: 0.0286 - val_mae: 0.1325 - val_mape: 208.5097\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0381 - mse: 0.0381 - mae: 0.1465 - mape: 19959.6289 - val_loss: 0.0298 - val_mse: 0.0298 - val_mae: 0.1319 - val_mape: 161.2506\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0382 - mse: 0.0382 - mae: 0.1463 - mape: 18884.7734 - val_loss: 0.0264 - val_mse: 0.0264 - val_mae: 0.1252 - val_mape: 160.3414\n",
      "2/2 [==============================] - 0s 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:57:18.005958: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_115 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_92 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_93 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_116 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_94 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_117 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_95 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_118 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_23 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_119 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_23 (C  (None, 1)                 2         \n",
      " ustomNormalization)                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 5s 26ms/step - loss: 0.0862 - mse: 0.0862 - mae: 0.2169 - mape: 11208.6104 - val_loss: 0.0625 - val_mse: 0.0625 - val_mae: 0.1707 - val_mape: 236.1424\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0606 - mse: 0.0606 - mae: 0.1782 - mape: 11725.5811 - val_loss: 0.0629 - val_mse: 0.0629 - val_mae: 0.1773 - val_mape: 308.9659\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0566 - mse: 0.0566 - mae: 0.1721 - mape: 3218.2363 - val_loss: 0.0625 - val_mse: 0.0625 - val_mae: 0.1739 - val_mape: 277.3281\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0540 - mse: 0.0540 - mae: 0.1684 - mape: 10822.9844 - val_loss: 0.1001 - val_mse: 0.1001 - val_mae: 0.2642 - val_mape: 746.3276\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0503 - mse: 0.0503 - mae: 0.1640 - mape: 7160.1699 - val_loss: 0.0790 - val_mse: 0.0790 - val_mae: 0.2234 - val_mape: 580.3918\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0488 - mse: 0.0488 - mae: 0.1618 - mape: 4521.9644 - val_loss: 0.0850 - val_mse: 0.0850 - val_mae: 0.2380 - val_mape: 655.1796\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1607 - mape: 8542.5098 - val_loss: 0.0707 - val_mse: 0.0707 - val_mae: 0.2133 - val_mape: 577.5287\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0471 - mse: 0.0471 - mae: 0.1604 - mape: 6471.3887 - val_loss: 0.0493 - val_mse: 0.0493 - val_mae: 0.1593 - val_mape: 295.9347\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0470 - mse: 0.0470 - mae: 0.1600 - mape: 14839.6318 - val_loss: 0.0398 - val_mse: 0.0398 - val_mae: 0.1511 - val_mape: 324.4788\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0447 - mse: 0.0447 - mae: 0.1577 - mape: 3065.8796 - val_loss: 0.0369 - val_mse: 0.0369 - val_mae: 0.1491 - val_mape: 318.6906\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0444 - mse: 0.0444 - mae: 0.1563 - mape: 15609.8096 - val_loss: 0.0376 - val_mse: 0.0376 - val_mae: 0.1466 - val_mape: 250.5727\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0427 - mse: 0.0427 - mae: 0.1550 - mape: 3023.5381 - val_loss: 0.0312 - val_mse: 0.0312 - val_mae: 0.1386 - val_mape: 291.1382\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0423 - mse: 0.0423 - mae: 0.1537 - mape: 9898.2344 - val_loss: 0.0324 - val_mse: 0.0324 - val_mae: 0.1411 - val_mape: 274.0445\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0420 - mse: 0.0420 - mae: 0.1540 - mape: 7199.2827 - val_loss: 0.0331 - val_mse: 0.0331 - val_mae: 0.1438 - val_mape: 300.2900\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0415 - mse: 0.0415 - mae: 0.1535 - mape: 7444.8809 - val_loss: 0.0335 - val_mse: 0.0335 - val_mae: 0.1440 - val_mape: 288.6516\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0412 - mse: 0.0412 - mae: 0.1525 - mape: 6731.3921 - val_loss: 0.0302 - val_mse: 0.0302 - val_mae: 0.1330 - val_mape: 225.3678\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0408 - mse: 0.0408 - mae: 0.1514 - mape: 675.1858 - val_loss: 0.0303 - val_mse: 0.0303 - val_mae: 0.1342 - val_mape: 229.1821\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0405 - mse: 0.0405 - mae: 0.1518 - mape: 5844.2715 - val_loss: 0.0302 - val_mse: 0.0302 - val_mae: 0.1346 - val_mape: 249.2232\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0407 - mse: 0.0407 - mae: 0.1518 - mape: 12942.2832 - val_loss: 0.0313 - val_mse: 0.0313 - val_mae: 0.1393 - val_mape: 273.3312\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0402 - mse: 0.0402 - mae: 0.1513 - mape: 2871.7437 - val_loss: 0.0303 - val_mse: 0.0303 - val_mae: 0.1350 - val_mape: 246.8333\n",
      "2/2 [==============================] - 0s 53ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:58:01.167020: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_25 (InputLayer)       [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_120 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_96 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_97 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_121 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_98 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_122 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_99 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_123 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_24 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_124 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_24 (C  (None, 1)                 2         \n",
      " ustomNormalization)                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     76/Unknown - 4s 22ms/step - loss: 0.1465 - mse: 0.1465 - mae: 0.2723 - mape: 56820.6523"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:58:06.879775: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n",
      "2023-11-10 12:58:06.879882: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 422699371556086469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 5s 28ms/step - loss: 0.1461 - mse: 0.1461 - mae: 0.2719 - mape: 56502.5664 - val_loss: 0.0639 - val_mse: 0.0639 - val_mae: 0.1975 - val_mape: 546.2224\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0635 - mse: 0.0635 - mae: 0.1839 - mape: 44262.1055 - val_loss: 0.0588 - val_mse: 0.0588 - val_mae: 0.1843 - val_mape: 464.7532\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0585 - mse: 0.0585 - mae: 0.1755 - mape: 7211.3638 - val_loss: 0.0621 - val_mse: 0.0621 - val_mae: 0.1929 - val_mape: 519.9112\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0543 - mse: 0.0543 - mae: 0.1692 - mape: 7098.5054 - val_loss: 0.0647 - val_mse: 0.0647 - val_mae: 0.1994 - val_mape: 556.8600\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0521 - mse: 0.0521 - mae: 0.1667 - mape: 4008.6555 - val_loss: 0.0793 - val_mse: 0.0793 - val_mae: 0.2322 - val_mape: 714.5884\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0490 - mse: 0.0490 - mae: 0.1629 - mape: 5854.8423 - val_loss: 0.0809 - val_mse: 0.0809 - val_mae: 0.2362 - val_mape: 735.0803\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 30ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1619 - mape: 8070.7280 - val_loss: 0.0821 - val_mse: 0.0821 - val_mae: 0.2421 - val_mape: 771.4911\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1591 - mape: 23427.1055 - val_loss: 0.0706 - val_mse: 0.0706 - val_mae: 0.2245 - val_mape: 708.7567\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0481 - mse: 0.0481 - mae: 0.1621 - mape: 9668.5996 - val_loss: 0.0412 - val_mse: 0.0412 - val_mae: 0.1592 - val_mape: 395.9575\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 3s 39ms/step - loss: 0.0450 - mse: 0.0450 - mae: 0.1566 - mape: 11243.5020 - val_loss: 0.0315 - val_mse: 0.0315 - val_mae: 0.1365 - val_mape: 267.8882\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0425 - mse: 0.0425 - mae: 0.1533 - mape: 15169.1709 - val_loss: 0.0278 - val_mse: 0.0278 - val_mae: 0.1287 - val_mape: 209.0039\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0435 - mse: 0.0435 - mae: 0.1546 - mape: 11841.4785 - val_loss: 0.0298 - val_mse: 0.0298 - val_mae: 0.1328 - val_mape: 221.1411\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0425 - mse: 0.0425 - mae: 0.1534 - mape: 15664.8838 - val_loss: 0.0327 - val_mse: 0.0327 - val_mae: 0.1367 - val_mape: 148.5125\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0414 - mse: 0.0414 - mae: 0.1519 - mape: 15451.7432 - val_loss: 0.0267 - val_mse: 0.0267 - val_mae: 0.1275 - val_mape: 226.5201\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0399 - mse: 0.0399 - mae: 0.1497 - mape: 24817.3320 - val_loss: 0.0274 - val_mse: 0.0274 - val_mae: 0.1315 - val_mape: 281.2417\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0398 - mse: 0.0398 - mae: 0.1488 - mape: 14897.6016 - val_loss: 0.0287 - val_mse: 0.0287 - val_mae: 0.1300 - val_mape: 181.9385\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0404 - mse: 0.0404 - mae: 0.1507 - mape: 9419.9688 - val_loss: 0.0262 - val_mse: 0.0262 - val_mae: 0.1267 - val_mape: 257.8318\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0390 - mse: 0.0390 - mae: 0.1490 - mape: 6448.1235 - val_loss: 0.0279 - val_mse: 0.0279 - val_mae: 0.1290 - val_mape: 167.9788\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0379 - mse: 0.0379 - mae: 0.1462 - mape: 11758.6162 - val_loss: 0.0244 - val_mse: 0.0244 - val_mae: 0.1203 - val_mape: 182.6851\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0379 - mse: 0.0379 - mae: 0.1468 - mape: 8497.0117 - val_loss: 0.0258 - val_mse: 0.0258 - val_mae: 0.1267 - val_mape: 261.9975\n",
      "2/2 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:58:46.517498: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_125 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_100 (B  (None, 256, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_101 (B  (None, 249, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_126 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_102 (B  (None, 122, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_127 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_103 (B  (None, 121, 100)          400       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_128 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_25 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_129 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_25 (C  (None, 1)                 2         \n",
      " ustomNormalization)                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     76/Unknown - 4s 21ms/step - loss: 0.1031 - mse: 0.1031 - mae: 0.2385 - mape: 116036.7656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 12:58:52.204444: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n",
      "2023-11-10 12:58:52.204532: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 422699371556086469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 5s 27ms/step - loss: 0.1030 - mse: 0.1030 - mae: 0.2384 - mape: 115384.9609 - val_loss: 0.0575 - val_mse: 0.0575 - val_mae: 0.1726 - val_mape: 327.6359\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0613 - mse: 0.0613 - mae: 0.1793 - mape: 24254.2793 - val_loss: 0.0582 - val_mse: 0.0582 - val_mae: 0.1795 - val_mape: 468.0911\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0570 - mse: 0.0570 - mae: 0.1729 - mape: 9591.9873 - val_loss: 0.0606 - val_mse: 0.0606 - val_mae: 0.1882 - val_mape: 567.7629\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0544 - mse: 0.0544 - mae: 0.1705 - mape: 3513.0959 - val_loss: 0.0604 - val_mse: 0.0604 - val_mae: 0.1875 - val_mape: 560.8610\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0519 - mse: 0.0519 - mae: 0.1665 - mape: 7941.7793 - val_loss: 0.0664 - val_mse: 0.0664 - val_mae: 0.2044 - val_mape: 708.0999\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1631 - mape: 733.5734 - val_loss: 0.0672 - val_mse: 0.0672 - val_mae: 0.2078 - val_mape: 743.4000\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0486 - mse: 0.0486 - mae: 0.1609 - mape: 20106.9844 - val_loss: 0.0613 - val_mse: 0.0613 - val_mae: 0.1979 - val_mape: 708.6346\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0449 - mse: 0.0449 - mae: 0.1566 - mape: 3222.7512 - val_loss: 0.0476 - val_mse: 0.0476 - val_mae: 0.1670 - val_mape: 495.9127\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0440 - mse: 0.0440 - mae: 0.1555 - mape: 14590.1816 - val_loss: 0.0435 - val_mse: 0.0435 - val_mae: 0.1518 - val_mape: 224.3095\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0449 - mse: 0.0449 - mae: 0.1567 - mape: 19130.3223 - val_loss: 0.0342 - val_mse: 0.0342 - val_mae: 0.1426 - val_mape: 380.2531\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 28ms/step - loss: 0.0429 - mse: 0.0429 - mae: 0.1539 - mape: 2874.1189 - val_loss: 0.0338 - val_mse: 0.0338 - val_mae: 0.1428 - val_mape: 411.1802\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0419 - mse: 0.0419 - mae: 0.1531 - mape: 10397.0117 - val_loss: 0.0429 - val_mse: 0.0429 - val_mae: 0.1627 - val_mape: 539.8321\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0427 - mse: 0.0427 - mae: 0.1543 - mape: 13709.7979 - val_loss: 0.0320 - val_mse: 0.0320 - val_mae: 0.1388 - val_mape: 368.0201\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0422 - mse: 0.0422 - mae: 0.1526 - mape: 8175.3350 - val_loss: 0.0322 - val_mse: 0.0322 - val_mae: 0.1363 - val_mape: 312.1391\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0404 - mse: 0.0404 - mae: 0.1506 - mape: 8642.3730 - val_loss: 0.0324 - val_mse: 0.0324 - val_mae: 0.1391 - val_mape: 347.9630\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0407 - mse: 0.0407 - mae: 0.1515 - mape: 13221.6143 - val_loss: 0.0322 - val_mse: 0.0322 - val_mae: 0.1373 - val_mape: 300.3419\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0406 - mse: 0.0406 - mae: 0.1514 - mape: 10095.1377 - val_loss: 0.0338 - val_mse: 0.0338 - val_mae: 0.1416 - val_mape: 264.5016\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0404 - mse: 0.0404 - mae: 0.1508 - mape: 8213.2764 - val_loss: 0.0333 - val_mse: 0.0333 - val_mae: 0.1424 - val_mape: 352.3100\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0382 - mse: 0.0382 - mae: 0.1476 - mape: 12504.6064 - val_loss: 0.0316 - val_mse: 0.0316 - val_mae: 0.1388 - val_mape: 336.6740\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0380 - mse: 0.0380 - mae: 0.1467 - mape: 8278.3311 - val_loss: 0.0310 - val_mse: 0.0310 - val_mae: 0.1374 - val_mape: 296.6361\n",
      "2/2 [==============================] - 0s 53ms/step\n",
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_27 (InputLayer)       [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_130 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_104 (B  (None, 256, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_105 (B  (None, 249, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_131 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_106 (B  (None, 122, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_132 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_107 (B  (None, 121, 100)          400       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_133 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_26 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_134 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_26 (C  (None, 1)                 2         \n",
      " ustomNormalization)                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 6s 26ms/step - loss: 0.1475 - mse: 0.1475 - mae: 0.2732 - mape: 104770.7969 - val_loss: 0.0675 - val_mse: 0.0675 - val_mae: 0.2113 - val_mape: 708.4976\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0646 - mse: 0.0646 - mae: 0.1862 - mape: 26594.1328 - val_loss: 0.0763 - val_mse: 0.0763 - val_mae: 0.2295 - val_mape: 816.4318\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0572 - mse: 0.0572 - mae: 0.1729 - mape: 24100.8164 - val_loss: 0.0774 - val_mse: 0.0774 - val_mae: 0.2316 - val_mape: 827.9020\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0539 - mse: 0.0539 - mae: 0.1694 - mape: 23605.8750 - val_loss: 0.0799 - val_mse: 0.0799 - val_mae: 0.2366 - val_mape: 854.8089\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0519 - mse: 0.0519 - mae: 0.1663 - mape: 20173.1953 - val_loss: 0.0722 - val_mse: 0.0722 - val_mae: 0.2213 - val_mape: 770.6013\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0497 - mse: 0.0497 - mae: 0.1633 - mape: 18207.7031 - val_loss: 0.0891 - val_mse: 0.0891 - val_mae: 0.2544 - val_mape: 949.4062\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0485 - mse: 0.0485 - mae: 0.1619 - mape: 13251.6904 - val_loss: 0.0824 - val_mse: 0.0824 - val_mae: 0.2447 - val_mape: 901.1053\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0475 - mse: 0.0475 - mae: 0.1599 - mape: 12948.8877 - val_loss: 0.0542 - val_mse: 0.0542 - val_mae: 0.1904 - val_mape: 611.1653\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0465 - mse: 0.0465 - mae: 0.1595 - mape: 29016.4434 - val_loss: 0.0456 - val_mse: 0.0456 - val_mae: 0.1744 - val_mape: 525.8792\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0458 - mse: 0.0458 - mae: 0.1594 - mape: 13084.9277 - val_loss: 0.0307 - val_mse: 0.0307 - val_mae: 0.1376 - val_mape: 302.0542\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0445 - mse: 0.0445 - mae: 0.1581 - mape: 4943.8755 - val_loss: 0.0319 - val_mse: 0.0319 - val_mae: 0.1426 - val_mape: 355.6603\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0432 - mse: 0.0432 - mae: 0.1549 - mape: 11797.4473 - val_loss: 0.0335 - val_mse: 0.0335 - val_mae: 0.1466 - val_mape: 363.1866\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0424 - mse: 0.0424 - mae: 0.1535 - mape: 13304.9912 - val_loss: 0.0301 - val_mse: 0.0301 - val_mae: 0.1356 - val_mape: 233.6093\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0409 - mse: 0.0409 - mae: 0.1520 - mape: 12551.0039 - val_loss: 0.0299 - val_mse: 0.0299 - val_mae: 0.1354 - val_mape: 255.6942\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 3s 38ms/step - loss: 0.0411 - mse: 0.0411 - mae: 0.1522 - mape: 19448.2480 - val_loss: 0.0294 - val_mse: 0.0294 - val_mae: 0.1311 - val_mape: 177.7946\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0403 - mse: 0.0403 - mae: 0.1511 - mape: 10936.3359 - val_loss: 0.0300 - val_mse: 0.0300 - val_mae: 0.1341 - val_mape: 235.0743\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 4s 51ms/step - loss: 0.0419 - mse: 0.0419 - mae: 0.1538 - mape: 14801.8262 - val_loss: 0.0301 - val_mse: 0.0301 - val_mae: 0.1324 - val_mape: 179.4970\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0392 - mse: 0.0392 - mae: 0.1491 - mape: 4809.1714 - val_loss: 0.0305 - val_mse: 0.0305 - val_mae: 0.1322 - val_mape: 124.8242\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 25ms/step - loss: 0.0388 - mse: 0.0388 - mae: 0.1479 - mape: 5942.7925 - val_loss: 0.0266 - val_mse: 0.0266 - val_mae: 0.1285 - val_mape: 230.1035\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0383 - mse: 0.0383 - mae: 0.1475 - mape: 28202.8984 - val_loss: 0.0272 - val_mse: 0.0272 - val_mae: 0.1274 - val_mape: 181.3532\n",
      "2/2 [==============================] - 0s 58ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 13:00:18.042705: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_28 (InputLayer)       [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_135 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_108 (B  (None, 256, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_109 (B  (None, 249, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_136 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_110 (B  (None, 122, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_137 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_111 (B  (None, 121, 100)          400       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_138 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_139 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_83 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_27 (C  (None, 1)                 2         \n",
      " ustomNormalization)                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     76/Unknown - 4s 20ms/step - loss: 0.1099 - mse: 0.1099 - mae: 0.2450 - mape: 24867.5039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 13:00:23.666764: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n",
      "2023-11-10 13:00:23.666864: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 422699371556086469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 5s 25ms/step - loss: 0.1096 - mse: 0.1096 - mae: 0.2448 - mape: 24728.7832 - val_loss: 0.0600 - val_mse: 0.0600 - val_mae: 0.1793 - val_mape: 454.8930\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0634 - mse: 0.0634 - mae: 0.1823 - mape: 17873.0742 - val_loss: 0.0599 - val_mse: 0.0599 - val_mae: 0.1787 - val_mape: 445.6925\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0569 - mse: 0.0569 - mae: 0.1723 - mape: 12633.8525 - val_loss: 0.0627 - val_mse: 0.0627 - val_mae: 0.1879 - val_mape: 564.1794\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0542 - mse: 0.0542 - mae: 0.1695 - mape: 3998.9282 - val_loss: 0.0622 - val_mse: 0.0622 - val_mae: 0.1865 - val_mape: 549.5057\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0521 - mse: 0.0521 - mae: 0.1669 - mape: 2201.4797 - val_loss: 0.0836 - val_mse: 0.0836 - val_mae: 0.2354 - val_mape: 920.9362\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0484 - mse: 0.0484 - mae: 0.1610 - mape: 14132.4922 - val_loss: 0.1059 - val_mse: 0.1059 - val_mae: 0.2765 - val_mape: 1139.1458\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1581 - mape: 10745.3438 - val_loss: 0.0896 - val_mse: 0.0896 - val_mae: 0.2511 - val_mape: 1006.6955\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 21ms/step - loss: 0.0462 - mse: 0.0462 - mae: 0.1579 - mape: 9291.1211 - val_loss: 0.0522 - val_mse: 0.0522 - val_mae: 0.1746 - val_mape: 512.3521\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0450 - mse: 0.0450 - mae: 0.1562 - mape: 12025.2646 - val_loss: 0.0396 - val_mse: 0.0396 - val_mae: 0.1527 - val_mape: 426.8528\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0430 - mse: 0.0430 - mae: 0.1544 - mape: 3309.3762 - val_loss: 0.0442 - val_mse: 0.0442 - val_mae: 0.1684 - val_mape: 497.1983\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0438 - mse: 0.0438 - mae: 0.1550 - mape: 9845.3174 - val_loss: 0.0379 - val_mse: 0.0379 - val_mae: 0.1462 - val_mape: 217.4725\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0419 - mse: 0.0419 - mae: 0.1525 - mape: 12011.2451 - val_loss: 0.0334 - val_mse: 0.0334 - val_mae: 0.1384 - val_mape: 214.2717\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0416 - mse: 0.0416 - mae: 0.1518 - mape: 2180.7454 - val_loss: 0.0330 - val_mse: 0.0330 - val_mae: 0.1396 - val_mape: 315.8480\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0414 - mse: 0.0414 - mae: 0.1523 - mape: 12874.4434 - val_loss: 0.0329 - val_mse: 0.0329 - val_mae: 0.1381 - val_mape: 221.5668\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0396 - mse: 0.0396 - mae: 0.1494 - mape: 1764.8402 - val_loss: 0.0304 - val_mse: 0.0304 - val_mae: 0.1329 - val_mape: 218.8441\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0403 - mse: 0.0403 - mae: 0.1509 - mape: 3855.9541 - val_loss: 0.0319 - val_mse: 0.0319 - val_mae: 0.1378 - val_mape: 201.4289\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0392 - mse: 0.0392 - mae: 0.1485 - mape: 4854.3188 - val_loss: 0.0301 - val_mse: 0.0301 - val_mae: 0.1336 - val_mape: 270.5706\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0385 - mse: 0.0385 - mae: 0.1472 - mape: 1431.8291 - val_loss: 0.0280 - val_mse: 0.0280 - val_mae: 0.1277 - val_mape: 215.3759\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0371 - mse: 0.0371 - mae: 0.1453 - mape: 16437.1113 - val_loss: 0.0296 - val_mse: 0.0296 - val_mae: 0.1338 - val_mape: 359.6862\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0374 - mse: 0.0374 - mae: 0.1466 - mape: 16213.0322 - val_loss: 0.0304 - val_mse: 0.0304 - val_mae: 0.1355 - val_mape: 375.2886\n",
      "2/2 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 13:00:58.982183: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_29 (InputLayer)       [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_140 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_112 (B  (None, 256, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_113 (B  (None, 249, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_141 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_114 (B  (None, 122, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_142 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_115 (B  (None, 121, 100)          400       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_143 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_144 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_28 (C  (None, 1)                 2         \n",
      " ustomNormalization)                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "77/77 [==============================] - 4s 26ms/step - loss: 0.0817 - mse: 0.0817 - mae: 0.2139 - mape: 10660.9111 - val_loss: 0.0482 - val_mse: 0.0482 - val_mae: 0.1624 - val_mape: 346.3157\n",
      "Epoch 2/20\n",
      " 4/77 [>.............................] - ETA: 1s - loss: 0.0784 - mse: 0.0784 - mae: 0.1983 - mape: 365.9761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 13:01:04.703712: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n",
      "2023-11-10 13:01:04.703787: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 422699371556086469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0595 - mse: 0.0595 - mae: 0.1773 - mape: 31674.5410 - val_loss: 0.0483 - val_mse: 0.0483 - val_mae: 0.1617 - val_mape: 322.6002\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0559 - mse: 0.0559 - mae: 0.1718 - mape: 18921.9355 - val_loss: 0.0486 - val_mse: 0.0486 - val_mae: 0.1607 - val_mape: 275.6092\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0530 - mse: 0.0530 - mae: 0.1677 - mape: 30039.4512 - val_loss: 0.0760 - val_mse: 0.0760 - val_mae: 0.2347 - val_mape: 1134.0214\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1636 - mape: 12088.1367 - val_loss: 0.0728 - val_mse: 0.0728 - val_mae: 0.2284 - val_mape: 1087.3951\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 6s 54ms/step - loss: 0.0495 - mse: 0.0495 - mae: 0.1624 - mape: 8105.0400 - val_loss: 0.0643 - val_mse: 0.0643 - val_mae: 0.2114 - val_mape: 956.4069\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0475 - mse: 0.0475 - mae: 0.1597 - mape: 15857.3545 - val_loss: 0.0611 - val_mse: 0.0611 - val_mae: 0.2071 - val_mape: 939.6434\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0466 - mse: 0.0466 - mae: 0.1585 - mape: 8179.2803 - val_loss: 0.0382 - val_mse: 0.0382 - val_mae: 0.1491 - val_mape: 354.5048\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0460 - mse: 0.0460 - mae: 0.1572 - mape: 3890.7590 - val_loss: 0.0352 - val_mse: 0.0352 - val_mae: 0.1445 - val_mape: 331.4290\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 24ms/step - loss: 0.0437 - mse: 0.0437 - mae: 0.1556 - mape: 7874.3901 - val_loss: 0.0353 - val_mse: 0.0353 - val_mae: 0.1492 - val_mape: 468.7281\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0439 - mse: 0.0439 - mae: 0.1555 - mape: 13926.4355 - val_loss: 0.0487 - val_mse: 0.0487 - val_mae: 0.1808 - val_mape: 843.9274\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 28ms/step - loss: 0.0435 - mse: 0.0435 - mae: 0.1556 - mape: 11377.6357 - val_loss: 0.0353 - val_mse: 0.0353 - val_mae: 0.1482 - val_mape: 498.0741\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0430 - mse: 0.0430 - mae: 0.1538 - mape: 5569.4966 - val_loss: 0.0357 - val_mse: 0.0357 - val_mae: 0.1494 - val_mape: 471.1699\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0418 - mse: 0.0418 - mae: 0.1525 - mape: 16360.0537 - val_loss: 0.0355 - val_mse: 0.0355 - val_mae: 0.1510 - val_mape: 472.3738\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0411 - mse: 0.0411 - mae: 0.1509 - mape: 2923.0881 - val_loss: 0.0420 - val_mse: 0.0420 - val_mae: 0.1669 - val_mape: 562.9100\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0410 - mse: 0.0410 - mae: 0.1518 - mape: 3991.2117 - val_loss: 0.0349 - val_mse: 0.0349 - val_mae: 0.1503 - val_mape: 451.8624\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0394 - mse: 0.0394 - mae: 0.1491 - mape: 20467.1172 - val_loss: 0.0366 - val_mse: 0.0366 - val_mae: 0.1548 - val_mape: 534.5103\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0399 - mse: 0.0399 - mae: 0.1504 - mape: 4881.4453 - val_loss: 0.0296 - val_mse: 0.0296 - val_mae: 0.1328 - val_mape: 323.9462\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0403 - mse: 0.0403 - mae: 0.1514 - mape: 9129.5713 - val_loss: 0.0356 - val_mse: 0.0356 - val_mae: 0.1513 - val_mape: 615.9501\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0390 - mse: 0.0390 - mae: 0.1487 - mape: 22890.8438 - val_loss: 0.0411 - val_mse: 0.0411 - val_mae: 0.1672 - val_mape: 745.3504\n",
      "2/2 [==============================] - 0s 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 13:01:45.418587: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_30 (InputLayer)       [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_145 (Dropout)       (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_116 (B  (None, 256, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_117 (B  (None, 249, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_146 (Dropout)       (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_118 (B  (None, 122, 250)          1000      \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " dropout_147 (Dropout)       (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_119 (B  (None, 121, 100)          400       \n",
      " atchNormalization)                                              \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_148 (Dropout)       (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_29 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_149 (Dropout)       (None, 300)               0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      " custom_normalization_29 (C  (None, 1)                 2         \n",
      " ustomNormalization)                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439453 (16.94 MB)\n",
      "Trainable params: 4437753 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "     76/Unknown - 4s 20ms/step - loss: 0.0838 - mse: 0.0838 - mae: 0.2151 - mape: 7897.7866"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 13:01:50.777771: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12619460392470034905\n",
      "2023-11-10 13:01:50.777862: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 422699371556086469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 5s 25ms/step - loss: 0.0837 - mse: 0.0837 - mae: 0.2150 - mape: 7854.4434 - val_loss: 0.0635 - val_mse: 0.0635 - val_mae: 0.1782 - val_mape: 133832.3438\n",
      "Epoch 2/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0607 - mse: 0.0607 - mae: 0.1798 - mape: 11520.8125 - val_loss: 0.0658 - val_mse: 0.0658 - val_mae: 0.1743 - val_mape: 53489.1016\n",
      "Epoch 3/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0567 - mse: 0.0567 - mae: 0.1729 - mape: 19120.9727 - val_loss: 0.0632 - val_mse: 0.0632 - val_mae: 0.1745 - val_mape: 105358.1797\n",
      "Epoch 4/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0529 - mse: 0.0529 - mae: 0.1677 - mape: 16290.6797 - val_loss: 0.0897 - val_mse: 0.0897 - val_mae: 0.2433 - val_mape: 306244.3750\n",
      "Epoch 5/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0502 - mse: 0.0502 - mae: 0.1636 - mape: 6612.6816 - val_loss: 0.0979 - val_mse: 0.0979 - val_mae: 0.2594 - val_mape: 334385.2500\n",
      "Epoch 6/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0492 - mse: 0.0492 - mae: 0.1610 - mape: 4137.7100 - val_loss: 0.0765 - val_mse: 0.0765 - val_mae: 0.2179 - val_mape: 254448.2031\n",
      "Epoch 7/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0486 - mse: 0.0486 - mae: 0.1618 - mape: 17355.6992 - val_loss: 0.0590 - val_mse: 0.0590 - val_mae: 0.1820 - val_mape: 152280.0625\n",
      "Epoch 8/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1610 - mape: 18667.8242 - val_loss: 0.0492 - val_mse: 0.0492 - val_mae: 0.1674 - val_mape: 75104.8438\n",
      "Epoch 9/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0478 - mse: 0.0478 - mae: 0.1612 - mape: 17340.5566 - val_loss: 0.0432 - val_mse: 0.0432 - val_mae: 0.1556 - val_mape: 45777.9453\n",
      "Epoch 10/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0457 - mse: 0.0457 - mae: 0.1585 - mape: 4678.5278 - val_loss: 0.0383 - val_mse: 0.0383 - val_mae: 0.1484 - val_mape: 32468.4102\n",
      "Epoch 11/20\n",
      "77/77 [==============================] - 2s 26ms/step - loss: 0.0448 - mse: 0.0448 - mae: 0.1570 - mape: 12057.9170 - val_loss: 0.0367 - val_mse: 0.0367 - val_mae: 0.1459 - val_mape: 15249.4814\n",
      "Epoch 12/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0437 - mse: 0.0437 - mae: 0.1566 - mape: 1085.8324 - val_loss: 0.0402 - val_mse: 0.0402 - val_mae: 0.1607 - val_mape: 121923.2422\n",
      "Epoch 13/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0441 - mse: 0.0441 - mae: 0.1567 - mape: 24902.6094 - val_loss: 0.0375 - val_mse: 0.0375 - val_mae: 0.1487 - val_mape: 104752.9609\n",
      "Epoch 14/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0446 - mse: 0.0446 - mae: 0.1577 - mape: 13598.6172 - val_loss: 0.0397 - val_mse: 0.0397 - val_mae: 0.1570 - val_mape: 106002.6016\n",
      "Epoch 15/20\n",
      "77/77 [==============================] - 3s 37ms/step - loss: 0.0419 - mse: 0.0419 - mae: 0.1529 - mape: 17112.6758 - val_loss: 0.0334 - val_mse: 0.0334 - val_mae: 0.1429 - val_mape: 73393.8906\n",
      "Epoch 16/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0432 - mse: 0.0432 - mae: 0.1560 - mape: 23562.0293 - val_loss: 0.0365 - val_mse: 0.0365 - val_mae: 0.1521 - val_mape: 140893.8750\n",
      "Epoch 17/20\n",
      "77/77 [==============================] - 2s 23ms/step - loss: 0.0423 - mse: 0.0423 - mae: 0.1541 - mape: 10646.6562 - val_loss: 0.0370 - val_mse: 0.0370 - val_mae: 0.1523 - val_mape: 143072.2031\n",
      "Epoch 18/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0409 - mse: 0.0409 - mae: 0.1525 - mape: 32987.0898 - val_loss: 0.0318 - val_mse: 0.0318 - val_mae: 0.1376 - val_mape: 80115.8984\n",
      "Epoch 19/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0411 - mse: 0.0411 - mae: 0.1525 - mape: 11132.7324 - val_loss: 0.0296 - val_mse: 0.0296 - val_mae: 0.1337 - val_mape: 84129.9141\n",
      "Epoch 20/20\n",
      "77/77 [==============================] - 2s 22ms/step - loss: 0.0398 - mse: 0.0398 - mae: 0.1506 - mape: 15361.8613 - val_loss: 0.0305 - val_mse: 0.0305 - val_mae: 0.1343 - val_mape: 43653.6602\n",
      "2/2 [==============================] - 0s 58ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_3E</th>\n",
       "      <th>seq</th>\n",
       "      <th>prediction</th>\n",
       "      <th>CRS</th>\n",
       "      <th>fold</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005304</td>\n",
       "      <td>aggaccggatcaactaaacaactcaaacaagggctaatataaccca...</td>\n",
       "      <td>-0.019658</td>\n",
       "      <td>LibA.Seq7829</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.236881</td>\n",
       "      <td>aggaccggatcaactaaacactagtcatacttaaaaattgcaagga...</td>\n",
       "      <td>-0.019426</td>\n",
       "      <td>LibA.Seq271</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.086491</td>\n",
       "      <td>aggaccggatcaactaaacaggttctgacgtatgctcctctatgga...</td>\n",
       "      <td>-0.019860</td>\n",
       "      <td>LibA.Seq4548</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.087684</td>\n",
       "      <td>aggaccggatcaactaaacccgagcctgcctagccctagcttctct...</td>\n",
       "      <td>-0.019592</td>\n",
       "      <td>LibA.Seq4582</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.371111</td>\n",
       "      <td>aggaccggatcaactaaacggagcagagttagtgtcaggtcaaaaa...</td>\n",
       "      <td>-0.019807</td>\n",
       "      <td>LibA.Seq2863</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25471</th>\n",
       "      <td>-0.076574</td>\n",
       "      <td>aggaccggatcaacttttggtcggttgacggtcgccttgattattc...</td>\n",
       "      <td>0.089834</td>\n",
       "      <td>LibA.Seq4154</td>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25472</th>\n",
       "      <td>0.369648</td>\n",
       "      <td>aggaccggatcaactttttcagtgaaagatcaccgcgggatctcac...</td>\n",
       "      <td>0.256202</td>\n",
       "      <td>LibA.Seq8531</td>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25473</th>\n",
       "      <td>-0.098525</td>\n",
       "      <td>aggaccggatcaacttttttagtaaaactcttaaacagtgattaca...</td>\n",
       "      <td>0.125644</td>\n",
       "      <td>LibA.Seq6744</td>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25474</th>\n",
       "      <td>0.164442</td>\n",
       "      <td>aggaccggatcaacttttttatctggttatcattctagtctagtgc...</td>\n",
       "      <td>0.023373</td>\n",
       "      <td>LibA.Seq1298</td>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25475</th>\n",
       "      <td>0.352354</td>\n",
       "      <td>aggaccggatcaacttttttccccgtctgccaacttcgtggctatc...</td>\n",
       "      <td>0.152025</td>\n",
       "      <td>LibA.Seq908</td>\n",
       "      <td>10</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25476 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       State_3E                                                seq  \\\n",
       "0     -0.005304  aggaccggatcaactaaacaactcaaacaagggctaatataaccca...   \n",
       "1      0.236881  aggaccggatcaactaaacactagtcatacttaaaaattgcaagga...   \n",
       "2     -0.086491  aggaccggatcaactaaacaggttctgacgtatgctcctctatgga...   \n",
       "3     -0.087684  aggaccggatcaactaaacccgagcctgcctagccctagcttctct...   \n",
       "4      0.371111  aggaccggatcaactaaacggagcagagttagtgtcaggtcaaaaa...   \n",
       "...         ...                                                ...   \n",
       "25471 -0.076574  aggaccggatcaacttttggtcggttgacggtcgccttgattattc...   \n",
       "25472  0.369648  aggaccggatcaactttttcagtgaaagatcaccgcgggatctcac...   \n",
       "25473 -0.098525  aggaccggatcaacttttttagtaaaactcttaaacagtgattaca...   \n",
       "25474  0.164442  aggaccggatcaacttttttatctggttatcattctagtctagtgc...   \n",
       "25475  0.352354  aggaccggatcaacttttttccccgtctgccaacttcgtggctatc...   \n",
       "\n",
       "       prediction           CRS fold partition  \n",
       "0       -0.019658  LibA.Seq7829    1      test  \n",
       "1       -0.019426   LibA.Seq271    1      test  \n",
       "2       -0.019860  LibA.Seq4548    1      test  \n",
       "3       -0.019592  LibA.Seq4582    1      test  \n",
       "4       -0.019807  LibA.Seq2863    1      test  \n",
       "...           ...           ...  ...       ...  \n",
       "25471    0.089834  LibA.Seq4154   10      test  \n",
       "25472    0.256202  LibA.Seq8531   10      test  \n",
       "25473    0.125644  LibA.Seq6744   10      test  \n",
       "25474    0.023373  LibA.Seq1298   10      test  \n",
       "25475    0.152025   LibA.Seq908   10      test  \n",
       "\n",
       "[25476 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We iterate through each of the train folds to train, test and validate the model\n",
    "for i in range(1,11):\n",
    "    \n",
    "    #Define inputs\n",
    "    input_path_train = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/background_CV\"+str(i)+\"_LibA_wide_pivot_state3_train.csv\"\n",
    "    input_path_valid = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/background_CV\"+str(i)+\"_LibA_wide_pivot_state3_validation.csv\"\n",
    "    input_path_test = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/background_CV\"+str(i)+\"_LibA_wide_pivot_state3_test.csv\"\n",
    "    \n",
    "    # Read test data to then predict\n",
    "    df_test = pd.read_csv(input_path_test)\n",
    "\n",
    "    # Get first item of the dataset to get the shape of the input data\n",
    "    for element in data_reader(input_path_train):\n",
    "        input_shape = element[0].shape\n",
    "\n",
    "    # Define and compile model\n",
    "    inputs = Input(shape=(input_shape[1],input_shape[2]), name=\"inputs\")\n",
    "    inputs = Masking()(inputs)\n",
    "    layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "    predictions = Dense(1, activation='linear')(layer)\n",
    "    norm_predictions = CustomNormalization()(predictions)  # Assuming \"predictions\" is your existing output\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=norm_predictions)\n",
    "    model.summary()\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "                )\n",
    "\n",
    "    # Run model\n",
    "    history=model.fit(data_reader(input_path_train, batch_size=100),\n",
    "                            epochs=20,\n",
    "                            validation_data=data_reader(input_path_valid,batch_size=500),\n",
    "                            callbacks=None,\n",
    "                            verbose=1)\n",
    "    \n",
    "    #After training we save the model weights to then run the contribution scores\n",
    "    model_path = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/test_background.h5\"\n",
    "    model.save_weights(model_path, save_format='h5') \n",
    "    \n",
    "    # We predict the test data\n",
    "    predicted = model.predict(data_reader(input_path_test, batch_size=500))\n",
    "\n",
    "    # We reed the data in the same order to compute the correlation score\n",
    "    test_data = data_reader(input_path_test,batch_size=500)\n",
    "    test_tensor = np.empty(shape=[0,1])\n",
    "    for batch in test_data:\n",
    "        test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "    # We fill the dataframe with predictions and fold annotation\n",
    "    df_test[\"prediction\"] = predicted\n",
    "    df_test[\"fold\"] = str(i)\n",
    "    df_test[\"partition\"] = \"test\"\n",
    "    \n",
    "    # Append fold to previous folds\n",
    "    df_test_10folds = pd.concat([df_test_10folds, df_test], ignore_index=True)    \n",
    "    # Append correlation coefficient and append to previous\n",
    "    corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)\n",
    "    corr_list.append(corr_coefficient)\n",
    "\n",
    "# Save the results for all folds\n",
    "df_test_10folds.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/background_LibA_wide_pivot_state3_test_predicted_cv10fold.csv\", index=False)\n",
    "\n",
    "df_test_10folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56615853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7772ea68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_plots(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
