{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c1f9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import getopt\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math \n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Lambda, concatenate, Bidirectional, Dense, Dropout, Flatten, Conv1D,BatchNormalization,  MaxPooling1D, Bidirectional, GRU, TimeDistributed\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "np.random.seed(1337) # for reproducibility\n",
    "vocab = [\"A\", \"G\", \"C\", \"T\"]\n",
    "indices = tf.range(len(vocab), dtype = tf.int64)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab,indices)\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, 1)\n",
    "defs = [0.] * 1 + [tf.constant([], dtype = \"string\")]\n",
    "\n",
    "# Nadav dataset\n",
    "\n",
    "def data_reader(file, batch_size=100, n_parse_threads = 4):\n",
    "    dataset = tf.data.TextLineDataset(file).skip(1)\n",
    "    dataset=dataset.map(preprocess, num_parallel_calls = n_parse_threads)\n",
    "    return dataset.batch(batch_size).prefetch(1)\n",
    "\n",
    "def preprocess(record):\n",
    "    fields = tf.io.decode_csv(record, record_defaults=defs)\n",
    "    chars = tf.strings.bytes_split(fields[1])\n",
    "    chars_indeces = table.lookup(chars)\n",
    "    X = tf.one_hot(chars_indeces, depth = len(vocab))\n",
    "    Y = fields[0]\n",
    "    return X,Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6395a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION (10 fold)\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# Split the data in three partitions\n",
    "file=\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3.csv\"\n",
    "whole_data = pd.read_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/LibA_wide_pivot_state3.csv\")\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 2008)\n",
    "result = next(kf.split(whole_data), None)\n",
    "\n",
    "o=1\n",
    "for i in kf.split(whole_data):\n",
    "    train = whole_data.iloc[i[0]]\n",
    "    test =  whole_data.iloc[i[1]]\n",
    "    \n",
    "    train, validation = train_test_split(whole_data, test_size=0.10, random_state=42)\n",
    "    \n",
    "    train.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_train.csv\", index=False)\n",
    "    test.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_test.csv\", index=False)\n",
    "    validation.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(o)+\"_LibA_wide_pivot_state3_validation.csv\", index=False)\n",
    "    o+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d1457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [State_3E, seq, prediction]\n",
      "Index: []\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_40 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_41 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_42 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_43 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "8/8 [==============================] - 4s 161ms/step - loss: 0.5259 - mse: 0.5259 - mae: 0.6322 - mape: 95735.8281 - val_loss: 0.0210 - val_mse: 0.0210 - val_mae: 0.1132 - val_mape: 618.6030\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.1219 - mse: 0.1219 - mae: 0.2867 - mape: 30644.5645 - val_loss: 0.0611 - val_mse: 0.0611 - val_mae: 0.2249 - val_mape: 1513.6063\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.0624 - mse: 0.0624 - mae: 0.2023 - mape: 70051.9453 - val_loss: 0.0325 - val_mse: 0.0325 - val_mae: 0.1358 - val_mape: 525.9249\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 0.0418 - mse: 0.0418 - mae: 0.1600 - mape: 16076.2559 - val_loss: 0.0226 - val_mse: 0.0226 - val_mae: 0.1193 - val_mape: 689.5038\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.0313 - mse: 0.0313 - mae: 0.1362 - mape: 1973.0414 - val_loss: 0.0185 - val_mse: 0.0185 - val_mae: 0.1017 - val_mape: 458.7569\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.0282 - mse: 0.0282 - mae: 0.1320 - mape: 28074.2598 - val_loss: 0.0183 - val_mse: 0.0183 - val_mae: 0.0941 - val_mape: 143.0497\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.0257 - mse: 0.0257 - mae: 0.1250 - mape: 11284.4102 - val_loss: 0.0180 - val_mse: 0.0180 - val_mae: 0.0991 - val_mape: 408.8880\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.0230 - mse: 0.0230 - mae: 0.1174 - mape: 14223.3691 - val_loss: 0.0181 - val_mse: 0.0181 - val_mae: 0.0999 - val_mape: 425.2171\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.0218 - mse: 0.0218 - mae: 0.1155 - mape: 8320.5518 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0941 - val_mape: 262.0804\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.0199 - mse: 0.0199 - mae: 0.1103 - mape: 5003.6353 - val_loss: 0.0174 - val_mse: 0.0174 - val_mae: 0.0948 - val_mape: 295.5009\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.0187 - mse: 0.0187 - mae: 0.1069 - mape: 7527.1528 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0970 - val_mape: 360.7922\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.0183 - mse: 0.0183 - mae: 0.1055 - mape: 1997.7490 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0962 - val_mape: 341.5328\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.0169 - mse: 0.0169 - mae: 0.1013 - mape: 7903.0098 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0961 - val_mape: 336.6879\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.0164 - mse: 0.0164 - mae: 0.1003 - mape: 3030.4224 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0969 - val_mape: 359.3343\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 1s 126ms/step - loss: 0.0154 - mse: 0.0154 - mae: 0.0969 - mape: 6598.6328 - val_loss: 0.0177 - val_mse: 0.0177 - val_mae: 0.0972 - val_mape: 367.5097\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.0142 - mse: 0.0142 - mae: 0.0937 - mape: 2990.4045 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0955 - val_mape: 319.6122\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.0138 - mse: 0.0138 - mae: 0.0918 - mape: 16245.9971 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0963 - val_mape: 342.5597\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 1s 126ms/step - loss: 0.0127 - mse: 0.0127 - mae: 0.0882 - mape: 11746.3096 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0953 - val_mape: 311.4805\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.0117 - mse: 0.0117 - mae: 0.0845 - mape: 3690.9800 - val_loss: 0.0174 - val_mse: 0.0174 - val_mae: 0.0950 - val_mape: 301.7142\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.0113 - mse: 0.0113 - mae: 0.0831 - mape: 2555.4890 - val_loss: 0.0175 - val_mse: 0.0175 - val_mae: 0.0951 - val_mape: 307.1341\n",
      "9/9 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:46:25.808644: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 15565383368236152796\n",
      "/tmp/ipykernel_738500/3063777414.py:61: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 262, 4)]          0         \n",
      "                                                                 \n",
      " conv1 (Conv1D)              (None, 256, 250)          7250      \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 256, 250)          0         \n",
      "                                                                 \n",
      " batch_normalization_44 (Ba  (None, 256, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2 (Conv1D)              (None, 249, 250)          500250    \n",
      "                                                                 \n",
      " batch_normalization_45 (Ba  (None, 249, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool1 (MaxPooling1D)     (None, 124, 250)          0         \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 124, 250)          0         \n",
      "                                                                 \n",
      " conv3 (Conv1D)              (None, 122, 250)          187750    \n",
      "                                                                 \n",
      " batch_normalization_46 (Ba  (None, 122, 250)          1000      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 122, 250)          0         \n",
      "                                                                 \n",
      " conv4 (Conv1D)              (None, 121, 100)          50100     \n",
      "                                                                 \n",
      " batch_normalization_47 (Ba  (None, 121, 100)          400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " maxpool2 (MaxPooling1D)     (None, 121, 100)          0         \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 121, 100)          0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 12100)             0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 300)               3630300   \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4439451 (16.94 MB)\n",
      "Trainable params: 4437751 (16.93 MB)\n",
      "Non-trainable params: 1700 (6.64 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "      8/Unknown - 3s 106ms/step - loss: 0.3010 - mse: 0.3010 - mae: 0.4616 - mape: 17143.4004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-17 15:46:30.452854: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 15565383368236152796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 164ms/step - loss: 0.3010 - mse: 0.3010 - mae: 0.4616 - mape: 17143.4004 - val_loss: 0.1331 - val_mse: 0.1331 - val_mae: 0.3402 - val_mape: 1845.5779\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.1093 - mse: 0.1093 - mae: 0.2755 - mape: 29714.6484 - val_loss: 0.0595 - val_mse: 0.0595 - val_mae: 0.2216 - val_mape: 1490.9836\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.0501 - mse: 0.0501 - mae: 0.1750 - mape: 34788.1602 - val_loss: 0.0174 - val_mse: 0.0174 - val_mae: 0.0944 - val_mape: 276.1026\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.0369 - mse: 0.0369 - mae: 0.1509 - mape: 12661.4443 - val_loss: 0.0198 - val_mse: 0.0198 - val_mae: 0.0978 - val_mape: 127.2694\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.0324 - mse: 0.0324 - mae: 0.1374 - mape: 12875.6025 - val_loss: 0.0241 - val_mse: 0.0241 - val_mae: 0.1248 - val_mape: 745.7087\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.0276 - mse: 0.0276 - mae: 0.1274 - mape: 38320.5234 - val_loss: 0.0182 - val_mse: 0.0182 - val_mae: 0.1004 - val_mape: 435.4517\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.0238 - mse: 0.0238 - mae: 0.1203 - mape: 6613.3379 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0936 - val_mape: 225.7601\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.0227 - mse: 0.0227 - mae: 0.1165 - mape: 12184.0078 - val_loss: 0.0178 - val_mse: 0.0178 - val_mae: 0.0978 - val_mape: 381.4470\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.0205 - mse: 0.0205 - mae: 0.1108 - mape: 12795.7207 - val_loss: 0.0180 - val_mse: 0.0180 - val_mae: 0.0993 - val_mape: 413.5985\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0192 - mse: 0.0192 - mae: 0.1075 - mape: 17089.4160"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/cv_simple_regression.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/cv_simple_regression.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/cv_simple_regression.ipynb#W2sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/cv_simple_regression.ipynb#W2sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m             loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/cv_simple_regression.ipynb#W2sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m             metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmape\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/cv_simple_regression.ipynb#W2sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m             )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/cv_simple_regression.ipynb#W2sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m history\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mfit(data_reader(input_path_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m1024\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/cv_simple_regression.ipynb#W2sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m                         epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/cv_simple_regression.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m                         validation_data\u001b[39m=\u001b[39;49mdata_reader(input_path_valid,batch_size\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/cv_simple_regression.ipynb#W2sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m                         callbacks\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/cv_simple_regression.ipynb#W2sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m                         verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/cv_simple_regression.ipynb#W2sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m predicted \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(data_reader(input_path_test,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/cv_simple_regression.ipynb#W2sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m                                             batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/felix/cluster/fpacheco/CNN_RNN/MPRA_prediction/regression/cv_simple_regression.ipynb#W2sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m test_data \u001b[39m=\u001b[39m data_reader(input_path_test,batch_size\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/keras/src/engine/training.py:1832\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1817\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1818\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1819\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1830\u001b[0m         pss_evaluation_shards\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1831\u001b[0m     )\n\u001b[0;32m-> 1832\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1833\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1834\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1835\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1836\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1837\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1838\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1839\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1840\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1841\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1842\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1843\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1844\u001b[0m )\n\u001b[1;32m   1845\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1846\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1847\u001b[0m }\n\u001b[1;32m   1848\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/keras/src/engine/training.py:2272\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2268\u001b[0m             \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2269\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2270\u001b[0m             ):\n\u001b[1;32m   2271\u001b[0m                 callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2272\u001b[0m                 logs \u001b[39m=\u001b[39m test_function_runner\u001b[39m.\u001b[39;49mrun_step(\n\u001b[1;32m   2273\u001b[0m                     dataset_or_iterator,\n\u001b[1;32m   2274\u001b[0m                     data_handler,\n\u001b[1;32m   2275\u001b[0m                     step,\n\u001b[1;32m   2276\u001b[0m                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pss_evaluation_shards,\n\u001b[1;32m   2277\u001b[0m                 )\n\u001b[1;32m   2279\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2280\u001b[0m \u001b[39m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/keras/src/engine/training.py:4079\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4078\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(\u001b[39mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4079\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function(dataset_or_iterator)\n\u001b[1;32m   4080\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   4081\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:876\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    874\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 876\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    877\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    878\u001b[0m )\n\u001b[1;32m    879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    880\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m   \u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow_2_gpu/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_test_overall  = pd.DataFrame(columns=['State_3E', \"seq\", \"prediction\"])\n",
    "print(df_test_overall)\n",
    "corr_list = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    \n",
    "    input_path_train = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_train.csv\"\n",
    "    input_path_valid = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_validation.csv\"\n",
    "    input_path_test = \"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/CV\"+str(i)+\"_LibA_wide_pivot_state3_test.csv\"\n",
    "    \n",
    "    df_test = pd.read_csv(input_path_test)\n",
    "\n",
    "    # Get first item of the dataset to get the shape of the input data\n",
    "    for element in data_reader(input_path_train):\n",
    "        input_shape = element[0].shape\n",
    "\n",
    "    inputs = Input(shape=(input_shape[1],input_shape[2]), name=\"inputs\")\n",
    "    layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "    predictions = Dense(1, activation='linear')(layer)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "                )\n",
    "\n",
    "    history=model.fit(data_reader(input_path_train, batch_size=100),\n",
    "                            epochs=20,\n",
    "                            validation_data=data_reader(input_path_valid,batch_size=100),\n",
    "                            callbacks=None,\n",
    "                            verbose=1)\n",
    "\n",
    "    predicted = model.predict(data_reader(input_path_test,\n",
    "                                                batch_size=100))\n",
    "\n",
    "    test_data = data_reader(input_path_test,batch_size=100)\n",
    "    test_tensor = X = np.empty(shape=[0,1])\n",
    "    for batch in test_data:\n",
    "        test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "    df_test[\"prediction\"] = predicted\n",
    "    df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n",
    "    \n",
    "    def pearson_correlation(x, y):\n",
    "        n = len(x)\n",
    "        # Calculate the mean of x and y\n",
    "        mean_x = sum(x) / n\n",
    "        mean_y = sum(y) / n\n",
    "        \n",
    "        # Calculate the numerator and denominators of the correlation coefficient\n",
    "        numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "        denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "        denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "        \n",
    "        # Calculate the correlation coefficient\n",
    "        correlation = numerator / (denominator_x * denominator_y)\n",
    "        return correlation\n",
    "        \n",
    "    corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)\n",
    "    corr_list.append(corr_coefficient)\n",
    "\n",
    "df_test_overall.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/LibA_wide_pivot_state3_test_predicted_cv10fold.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7951a63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_3E</th>\n",
       "      <th>seq</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007714</td>\n",
       "      <td>AGGACCGGATCAACTAAACAACTCAAACAAGGGCTAATATAACCCA...</td>\n",
       "      <td>0.005275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.137953</td>\n",
       "      <td>AGGACCGGATCAACTAAACACTAGTCATACTTAAAAATTGCAAGGA...</td>\n",
       "      <td>0.005275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.048706</td>\n",
       "      <td>AGGACCGGATCAACTAAACAGGTTCTGACGTATGCTCCTCTATGGA...</td>\n",
       "      <td>0.005274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052804</td>\n",
       "      <td>AGGACCGGATCAACTAAACCCGAGCCTGCCTAGCCCTAGCTTCTCT...</td>\n",
       "      <td>0.005274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.213652</td>\n",
       "      <td>AGGACCGGATCAACTAAACGGAGCAGAGTTAGTGTCAGGTCAAAAA...</td>\n",
       "      <td>0.005275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8473</th>\n",
       "      <td>0.167100</td>\n",
       "      <td>AGGACCGGATCAACTTTTCCGCCTTTTATTATCAGGACTTCACGGG...</td>\n",
       "      <td>-0.049231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8474</th>\n",
       "      <td>0.099489</td>\n",
       "      <td>AGGACCGGATCAACTTTTCGCTCATTAGTACAGGGTATAACGGAAG...</td>\n",
       "      <td>-0.049231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8475</th>\n",
       "      <td>-0.046939</td>\n",
       "      <td>AGGACCGGATCAACTTTTGGTCGGTTGACGGTCGCCTTGATTATTC...</td>\n",
       "      <td>-0.049233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>0.093662</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTATCTGGTTATCATTCTAGTCTAGTGC...</td>\n",
       "      <td>-0.049234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8477</th>\n",
       "      <td>0.199862</td>\n",
       "      <td>AGGACCGGATCAACTTTTTTCCCCGTCTGCCAACTTCGTGGCTATC...</td>\n",
       "      <td>-0.049232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8478 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      State_3E                                                seq  prediction\n",
       "0    -0.007714  AGGACCGGATCAACTAAACAACTCAAACAAGGGCTAATATAACCCA...    0.005275\n",
       "1     0.137953  AGGACCGGATCAACTAAACACTAGTCATACTTAAAAATTGCAAGGA...    0.005275\n",
       "2    -0.048706  AGGACCGGATCAACTAAACAGGTTCTGACGTATGCTCCTCTATGGA...    0.005274\n",
       "3    -0.052804  AGGACCGGATCAACTAAACCCGAGCCTGCCTAGCCCTAGCTTCTCT...    0.005274\n",
       "4     0.213652  AGGACCGGATCAACTAAACGGAGCAGAGTTAGTGTCAGGTCAAAAA...    0.005275\n",
       "...        ...                                                ...         ...\n",
       "8473  0.167100  AGGACCGGATCAACTTTTCCGCCTTTTATTATCAGGACTTCACGGG...   -0.049231\n",
       "8474  0.099489  AGGACCGGATCAACTTTTCGCTCATTAGTACAGGGTATAACGGAAG...   -0.049231\n",
       "8475 -0.046939  AGGACCGGATCAACTTTTGGTCGGTTGACGGTCGCCTTGATTATTC...   -0.049233\n",
       "8476  0.093662  AGGACCGGATCAACTTTTTTATCTGGTTATCATTCTAGTCTAGTGC...   -0.049234\n",
       "8477  0.199862  AGGACCGGATCAACTTTTTTCCCCGTCTGCCAACTTCGTGGCTATC...   -0.049232\n",
       "\n",
       "[8478 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_overall.to_csv(\"/home/felix/cluster/fpacheco/Data/Robert_data/processed_data/10fold_cv/LibA_wide_pivot_state3_test_predicted_cv10fold.csv\", index=False)\n",
    "df_test_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3096cd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6109516526851736,\n",
       " 0.5577751589096964,\n",
       " 0.5824317832428231,\n",
       " 0.646415735678849,\n",
       " 0.6531711700731101,\n",
       " 0.6220736243472968,\n",
       " 0.5739929657529798,\n",
       " 0.5967556394910829,\n",
       " 0.6648464327652903,\n",
       " 0.6024677659508967]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7571493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# Split the data in three partitions\n",
    "whole_data=pd.read_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/mean_with_sequence_ENCFF616IAQ.csv\")\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle = True, random_state = 2008)\n",
    "result = next(kf.split(whole_data), None)\n",
    "\n",
    "o=1\n",
    "for i in kf.split(whole_data):\n",
    "    train = whole_data.iloc[i[0]]\n",
    "    test =  whole_data.iloc[i[1]]\n",
    "    \n",
    "    train, validation = train_test_split(whole_data, test_size=0.10, random_state=42)\n",
    "    \n",
    "    train[[\"meanVal\", \"sequence\"]].to_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/10fold_cv/CV\"+str(o)+\"_mean_with_sequence_ENCFF616IAQ_train.csv\", index=False)\n",
    "    test[[\"meanVal\", \"sequence\"]].to_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/10fold_cv/CV\"+str(o)+\"_mean_with_sequence_ENCFF616IAQ_test.csv\", index=False)\n",
    "    validation[[\"meanVal\", \"sequence\"]].to_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/10fold_cv/CV\"+str(o)+\"_mean_with_sequence_ENCFF616IAQ_validation.csv\", index=False)\n",
    "    o+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71949262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_overall  = pd.DataFrame(columns=[\"meanVal\", \"Sequence\"])\n",
    "print(df_test_overall)\n",
    "corr_list = []\n",
    "\n",
    "for i in range(1,10):\n",
    "    \n",
    "    input_path_train = \"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/10fold_cv/CV\"+str(i)+\"_mean_with_sequence_ENCFF616IAQ_train.csv\"\n",
    "    input_path_valid = \"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/10fold_cv/CV\"+str(i)+\"_mean_with_sequence_ENCFF616IAQ_validation.csv\"\n",
    "    input_path_test = \"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/10fold_cv/CV\"+str(i)+\"_mean_with_sequence_ENCFF616IAQ_test.csv\"\n",
    "   \n",
    "    df_test = pd.read_csv(input_path_test)\n",
    "\n",
    "    # Get first item of the dataset to get the shape of the input data\n",
    "    for element in data_reader(input_path_train):\n",
    "        input_shape = element[0].shape\n",
    "\n",
    "    inputs = Input(shape=(input_shape[1],input_shape[2]), name=\"inputs\")\n",
    "    layer = Conv1D(250, kernel_size=7, strides=1, activation='relu', name=\"conv1\")(inputs)  # 250 7 relu\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Conv1D(250, 8, strides=1, activation='softmax', name=\"conv2\")(layer)  # 250 8 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=2, strides=None, name=\"maxpool1\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(250, 3, strides=1, activation='softmax', name=\"conv3\")(layer)  # 250 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv1D(100, 2, strides=1, activation='softmax', name=\"conv4\")(layer)  # 100 3 softmax\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = MaxPooling1D(pool_size=1, strides=None, name=\"maxpool2\")(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    layer = Dense(300, activation='sigmoid')(layer)  # 300\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Dense(200, activation='sigmoid')(layer)  # 300\n",
    "    predictions = Dense(1, activation='linear')(layer)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[\"mse\", \"mae\", \"mape\"],\n",
    "                )\n",
    "\n",
    "    history=model.fit(data_reader(input_path_train, batch_size=1024),\n",
    "                            epochs=20,\n",
    "                            validation_data=data_reader(input_path_valid,batch_size=100),\n",
    "                            callbacks=None,\n",
    "                            verbose=1)\n",
    "\n",
    "    predicted = model.predict(data_reader(input_path_test,\n",
    "                                                batch_size=100))\n",
    "\n",
    "    test_data = data_reader(input_path_test,batch_size=100)\n",
    "    test_tensor = X = np.empty(shape=[0,1])\n",
    "    for batch in test_data:\n",
    "        test_tensor = np.append(test_tensor, batch[1])\n",
    "\n",
    "    df_test[\"prediction\"] = predicted\n",
    "    df_test_overall = df_test_overall.append(df_test, ignore_index=True)\n",
    "    \n",
    "    def pearson_correlation(x, y):\n",
    "        n = len(x)\n",
    "        # Calculate the mean of x and y\n",
    "        mean_x = sum(x) / n\n",
    "        mean_y = sum(y) / n\n",
    "        \n",
    "        # Calculate the numerator and denominators of the correlation coefficient\n",
    "        numerator = sum((xi - mean_x) * (yi - mean_y) for xi, yi in zip(x, y))\n",
    "        denominator_x = math.sqrt(sum((xi - mean_x) ** 2 for xi in x))\n",
    "        denominator_y = math.sqrt(sum((yi - mean_y) ** 2 for yi in y))\n",
    "        \n",
    "        # Calculate the correlation coefficient\n",
    "        correlation = numerator / (denominator_x * denominator_y)\n",
    "        return correlation\n",
    "        \n",
    "    corr_coefficient = pearson_correlation(predicted.flatten(), test_tensor)\n",
    "    corr_list.append(corr_coefficient)\n",
    "\n",
    "df_test_overall.to_csv(\"/home/felix/cluster/fpacheco/Data/Nadav_lab/K562/10fold_cv/mean_with_sequence_ENCFF616IAQ_test_predicted_cv10fold.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
